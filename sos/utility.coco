# Copyright Arne Bachmann
# This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/.

# Utiliy functions
import hashlib, logging, os, sys, time; START_TIME = time.time()  # early time tracking

try: from typing import Any, AnyStr, Dict, FrozenSet, Generic, IO, Iterable, Iterator, List, Optional, Sequence, Set, Tuple, Type, TypeVar, Union   # we cannot delay this import, since we need to type-check the Coconut version-detection, which again is required to know if we actually can type-check...
except: pass

try: import sos.pure as pure; from sos.values import *
except: import pure; from values import *


# Lazy imports for quicker initialization TODO make mypy pass
bz2:Any; codecs:Any; difflib:Any
class bz2: def __getattribute__(_, key):
  global bz2
  import bz2
  return bz2.__getattribute__(key)
bz2:object = bz2()

class codecs: def __getattribute__(_, key):
  global codecs
  import codecs
  return codecs.__getattribute__(key)
codecs:object = codecs()

class difflib: def __getattribute__(_, key):
  global difflib
  import difflib
  return difflib.__getattribute__(key)
difflib:object = difflib()


verbose:bool = '--verbose' in sys.argv or '-v' in sys.argv
debug_:bool = os.environ.get("DEBUG", "False").lower() == "true" or '--debug' in sys.argv


# Classes
class Accessor(dict):
  ''' Dictionary with attribute access. '''
  def __init__(_, mapping:Dict[str,Any]) -> None: dict.__init__(_, mapping)  # TODO remove -> None when fixed in Coconut stub
  def __getattribute__(_, name:str) -> Any:  # or simply class C(dict): __getattr__ = dict.__getitem__
    try: return _[name]
    except: return dict.__getattribute__(_, name)
  def __setattribute__(_, name:str, value: Any) -> None:
    try: _[name] = value
    except: dict.__setattribute__(_, name, value)

if TYPE_CHECKING:  # available since coconut 1.3.1.21 (?)
  Number = TypeVar("Number", int, float)
  class Counter(Generic[Number]):
    ''' A simple counter. Can be augmented to return the last value instead. '''
    def __init__(_, initial:Number = 0) -> None: _.value:Number = initial
    def inc(_, by:Number = 1) -> Number: _.value += by; return _.value
else:
  class Counter:
    def __init__(_, initial = 0) -> None: _.value = initial
    def inc(_, by = 1): _.value += by; return _.value

class ProgressIndicator(Counter):
  ''' Manages a rotating progress indicator. '''
  def __init__(_, symbols:str, callback:Optional[(str) -> None] = None) -> None: super(ProgressIndicator, _).__init__(-1); _.symbols = symbols; _.timer:float = time.time(); _.callback:Optional[(str) -> None] = callback
  def getIndicator(_) -> str? =
    ''' Returns a value only if a certain time has passed. '''
    newtime:float = time.time()
    if newtime - _.timer < .1: return None
    _.timer = newtime
    sign:str = _.symbols[int(_.inc() % len(_.symbols))]
    if _.callback: _.callback(sign)
    sign

class Logger:
  ''' Logger that supports joining many items. '''
  def __init__(_, log) -> None: _._log = log
  def debug(_, *s): _._log.debug(pure.sjoin(*s))
  def info(_, *s): _._log.info(pure.sjoin(*s))
  def warn(_, *s): _._log.warning(pure.sjoin(*s))
  def error(_, *s): _._log.error(pure.sjoin(*s))


# Constants
_log = Logger(logging.getLogger(__name__)); debug, info, warn, error = _log.debug, _log.info, _log.warn, _log.error
CONFIGURABLE_FLAGS:List[str] = ["strict", "track", "picky", "compress", "useChangesCommand", "useUnicodeFont"]
CONFIGURABLE_LISTS:List[str] = ["texttype", "bintype", "ignores", "ignoreDirs", "ignoresWhitelist", "ignoreDirsWhitelist"]
CONFIGURABLE_INTS:List[str] = ["logLines"]
GLOBAL_LISTS:List[str] = ["ignores", "ignoreDirs", "ignoresWhitelist", "ignoreDirsWhitelist"]
TRUTH_VALUES:List[str] = ["true", "yes", "on", "1", "enable", "enabled"]  # all lower-case normalized
FALSE_VALUES:List[str] = ["false", "no", "off", "0", "disable", "disabled"]
PROGRESS_MARKER:List[str] =  ["|/-\\", "\u2581\u2582\u2583\u2584\u2585\u2586\u2587\u2588\u2587\u2586\u2585\u2584\u2583\u2582", "\U0001f55b\U0001f550\U0001f551\U0001f552\U0001f553\U0001f554\U0001f555\U0001f556\U0001f557\U0001f558\U0001f559\U0001f55a\U0001f559\U0001f558\U0001f557\U0001f556\U0001f555\U0001f554\U0001f553\U0001f552\U0001f551\U0001f550"]
BACKUP_SUFFIX:str = "_last"
metaFolder:str = ".sos"
DUMP_FILE:str = metaFolder + ".zip"
metaFile:str = ".meta"
metaBack:str = metaFile + BACKUP_SUFFIX
KIBI:int = 1 << 10; MEBI:int = 1 << 20; GIBI:int = 1 << 30
bufSize:int = MEBI
UTF8:str = "utf_8"  # early used constant, not defined in standard library
SVN:str = "svn"
SLASH:str = "/"
DOT_SYMBOL:str = "\u00b7"
MULT_SYMBOL:str = "\u00d7"
CROSS_SYMBOL:str = "\u2716"
CHECKMARK_SYMBOL:str = "\u2714"
PLUSMINUS_SYMBOL:str = "\u00b1"  # alternative for "~"
ARROW_SYMBOL:str = "\u2799"  # alternative for "*" in "this revision"
MOVE_SYMBOL:str = "\u21cc"  # alternative for "#". or use \U0001F5C0", which is very unlikely to be in any console font
METADATA_FORMAT:int = 1  # counter for incompatible consecutive formats (was undefined, "1" is the first versioned version after that)
vcsFolders:Dict[str,str] = {".svn": SVN, ".git": "git", ".bzr": "bzr", ".hg": "hg", ".fslckout": "fossil", "_FOSSIL_": "fossil", ".CVS": "cvs", "_darcs": "darcs", "_MTN": "monotone", ".git/GL_COMMIT_EDIT_MSG": "gl"}
vcsBranches:Dict[str,str?] = {SVN: "trunk", "git": "master", "bzr": "trunk", "hg": "default", "fossil": None, "cvs": None, "darcs": None, "monotone": None}
vcsCommits:Dict[str,Tuple[bool,str?]] = {SVN: (True, None), "git": (False, None), "bzr": (True, None), "hg": (True, None), "fossil": (True, "--no-warnings"), "cvs": (True, None), "darcs": (False, "--all"), "monotone": (False, None)}  # bool: tracked? (otherwise picky), str:arguments to "commit" TODO CVS, RCS have probably different per-file operation
vcsNames:Dict[str,str] = {SVN: "Subversion", "git": "Git", "bzr": "Bazaar", "hg": "Mercurial", "fossil": "Fossil", "cvs": "CVS", "darcs": "darcs", "monotone": "monotone"}#  from cmd to long name
NL_NAMES:Dict[bytes,str] = {None: "<No newline>", b"\r\n": "<CR+LF>", b"\n\r": "<LF+CR>", b"\n": "<LF>", b"\r": "<CR>"}
MAX_COMMAND_LINE:Dict[str,int] = {"win32": 8191, "linux2": 4096, None: 1023}  # may be much longer on posix. https://stackoverflow.com/questions/3205027/maximum-length-of-command-line-string
defaults:Accessor = Accessor({
    "strict": False, "track": False, "picky": False, "compress": False, "useChangesCommand": False, "useUnicodeFont": sys.platform != "win32",
    "logLines": 20,
    "texttype": ["*.md", "*.coco", "*.py", "*.pyi", "*.pth"],
    "bintype": [],
    "ignoreDirs": [".*", "__pycache__", ".mypy_cache"],  # already includes metaFolder
    "ignoreDirsWhitelist": [],
    "ignores": ["__coconut__.py", "*.bak", "*.py[cdo]", "*.class", ".fslckout", "_FOSSIL_", "*%s" % DUMP_FILE],
    "ignoresWhitelist": [],
  })


# Functions
def printo(s:str = "", nl:str = "\n"): tryOrDefault(-> sys.stdout.buffer ?? sys.stdout, sys.stdout).write((s + nl).encode(sys.stdout.encoding, 'backslashreplace')); sys.stdout.flush()  # PEP528 compatibility
def printe(s:str = "", nl:str = "\n"): tryOrDefault(-> sys.stderr.buffer ?? sys.stderr, sys.stderr).write((s + nl).encode(sys.stderr.encoding, 'backslashreplace')); sys.stderr.flush()
def encode(s:str) -> bytes: return os.fsencode(s)  # for py->os access of writing filenames  # PEP 529 compatibility
def decode(b:bytes) -> str: return os.fsdecode(b)  # for os->py access of reading filenames
try:
  import chardet  # https://github.com/chardet/chardet
  def detectEncoding(binary:bytes) -> str = chardet.detect(binary)["encoding"]
except: def detectEncoding(binary:bytes) -> str =  # Guess the encoding
  ''' Fallback if chardet library missing. '''
  try: binary.decode(UTF8); return UTF8
  except UnicodeError: pass
  try: binary.decode("utf_16"); return "utf_16"
  except UnicodeError: pass
  try: binary.decode("cp1252"); return "cp1252"
  except UnicodeError: pass
  "ascii"  # this code will never be reached, as above is an 8-bit charset that always matches

def tryOrDefault(func:-> Any, default:Any) -> Any:
  try: return func()
  except: return default

def tryOrIgnore(func:-> Any, onError:(Exception) -> None = -> None) -> Any:
  try: return func()
  except Exception as E: onError(E)

def removePath(key:str, value:str) -> str =
  ''' Cleanup of user-specified global file patterns. '''  # TODO improve
  value if value in GLOBAL_LISTS or SLASH not in value else value[value.rindex(SLASH)+1:]

def dictUpdate(dikt:Dict[Any,Any], by:Dict[Any,Any]) -> Dict[Any,Any]: d:Dict[Any,Any] = {}; d.update(dikt); d.update(by); return d

def openIt(file:str, mode:str, compress:bool = False) -> IO[bytes] = bz2.BZ2File(encode(file), mode) if compress else open(encode(file), mode + "b")  # Abstraction for opening both compressed and plain files

def eoldet(file:bytes) -> bytes? =
  ''' Determine EOL style from a binary string. '''
  lf:int = file.count(b"\n")
  cr:int = file.count(b"\r")
  crlf:int = file.count(b"\r\n")
  if crlf > 0:  # DOS/Windows/Symbian etc.
    if lf != crlf or cr != crlf: warn("Inconsistent CR/NL count with CR+NL. Mixed EOL style detected, may cause problems during merge")
    return b"\r\n"
  if lf != 0 and cr != 0: warn("Inconsistent CR/NL count without CR+NL. Mixed EOL style detected, may cause problems during merge")
  if lf > cr: return b"\n"  # Linux/Unix
  if cr > lf: return b"\r"  # older 8-bit machines
  None  # no new line contained, cannot determine

if TYPE_CHECKING:
  Splittable = TypeVar("Splittable", AnyStr)
  def safeSplit(s:Splittable, d:Splittable? = None) -> List[Splittable]: return s.split(d ?? ("\n" if isinstance(s, str) else b"\n")) if len(s) > 0 else []
else:
  def safeSplit(s, d = None): return s.split(d ?? ("\n" if isinstance(s, str) else b"\n")) if len(s) > 0 else []

def hashStr(datas:str) -> str = hashlib.sha256(datas.encode(UTF8)).hexdigest()

def modified(changes:ChangeSet, onlyBinary:bool = False) -> bool = len(changes.additions) > 0 or len(changes.deletions) > 0 or len(changes.modifications) > 0 or len(changes.moves) > 0

def listindex(lizt:Sequence[Any], what:Any, index:int = 0) -> int = lizt[index:].index(what) + index

def branchFolder(branch:int, base:str? = None, file:str? = None) -> str = os.path.join(base ?? os.getcwd(), metaFolder, "b%d" % branch) + ((os.sep + file) if file else "")

def revisionFolder(branch:int, revision:int, base:str? = None, file:str? = None) -> str = os.path.join(branchFolder(branch, base), "r%d" % revision) + ((os.sep + file) if file else "")

def Exit(message:str = "", code = 1): printe("[EXIT%s]" % (" %.1fs" % (time.time() - START_TIME) if verbose else "") + (" " + message + "." if message != "" else "")); sys.exit(code)

def fitStrings(strings:str[], prefix:str, length:int = MAX_COMMAND_LINE.get(sys.platform, MAX_COMMAND_LINE[None]), separator:str = " ", process: -> str = -> '"%s"' % _) -> str =
  ''' Returns a packed string, destructively consuming entries from the provided list. Does similar as xargs. getconf ARG_MAX or xargs --show-limits. '''
  if len(prefix + separator + (strings[0] |> process)) > length: raise Exception("Cannot possibly strings pack into specified length")
  while len(strings) > 0 and len(prefix + separator + (strings[0] |> process)) <= length: prefix += separator + (strings.pop(0) |> process)
  prefix

def exception(E):
  ''' Report an exception to the user to enable useful bug reporting. '''
  printo(str(E))
  import traceback
  traceback.print_exc()
  traceback.print_stack()

def hashFile(path:str, compress:bool, saveTo:str? = None, callback:Optional[(str) -> None] = None, symbols:str = PROGRESS_MARKER[0]) -> Tuple[str,int] =
  ''' Calculate hash of file contents, and return compressed sized, if in write mode, or zero. '''
  indicator:ProgressIndicator? = ProgressIndicator(symbols, callback) if callback else None
  _hash = hashlib.sha256()
  wsize:int = 0
  if saveTo and os.path.exists(encode(saveTo)):
    Exit("Hash collision detected. Leaving repository in inconsistent state.", 1)  # HINT this exits immediately
  to = openIt(saveTo, "w", compress) if saveTo else None
  with open(encode(path), "rb") as fd:
    while True:
      buffer:bytes = fd.read(bufSize)
      _hash.update(buffer)
      if to: to.write(buffer)
      if len(buffer) < bufSize: break
      if indicator: indicator.getIndicator()
    if to:
      to.close()
      wsize = os.stat(encode(saveTo)).st_size
  (_hash.hexdigest(), wsize)

def getAnyOfMap(map:Dict[str,Any], params:str[], default:Any = None) -> Any =
  ''' Utility to find any entries of a dictionary in a list to return the dictionaries value. '''
  for k, v in map.items(): if k in params: return v
  default

def strftime(timestamp:int? = None) -> str = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(timestamp / 1000. if timestamp is not None else None))

def detectAndLoad(filename:str? = None, content:bytes? = None, ignoreWhitespace:bool = False) -> Tuple[str,bytes,str[]] =
  lines:str[] = []
  if filename is not None: with open(encode(filename), "rb") as fd: content = fd.read()
  encoding:str = detectEncoding(content) ?? sys.getdefaultencoding()
  eol:bytes? = eoldet(content)
  if filename is not None: with codecs.open(encode(filename), encoding = encoding) as fd2: lines = safeSplit(fd2.read(), (eol ?? b"\n").decode(encoding))
  elif content is not None: lines = safeSplit(content.decode(encoding), (eol ?? b"\n").decode(encoding))
  else: return (sys.getdefaultencoding(), b"\n", [])
  if ignoreWhitespace: lines[:] = [line.replace("\t", "  ").strip() for line in lines]
  (encoding, eol, lines)

if TYPE_CHECKING:
  DataType = TypeVar("DataType", BranchInfo, ChangeSet, MergeBlock, PathInfo)
  def dataCopy(_tipe:Type[DataType], _old:DataType, *_args, byValue:bool = False, **_kwargs) -> DataType =
    ''' A better makedata() version. '''
    r:Dict[str,Any] = _old._asdict()
    r.update({k: ([e for e in v] if byValue and isinstance(v, (list, tuple, set)) else v) for k, v in _kwargs.items()})  # copy by value if required
    makedata(_tipe, *(list(_args) + [r[field] for field in _old._fields]))  # TODO also offer copy-by-value here
else:
  def dataCopy(_tipe, _old, *_args, byValue = False, **_kwargs) -> DataType =
    ''' A better makedata() version. '''
    r = _old._asdict()
    r.update({k: ([e for e in v] if byValue and isinstance(v, (list, tuple, set)) else v) for k, v in _kwargs.items()})  # copy by value if required
    makedata(_tipe, *(list(_args) + [r[field] for field in _old._fields]))  # TODO also offer copy-by-value here

def detectMoves(changes:ChangeSet, strict:bool) -> Dict[str,Tuple[str,PathInfo]] =
  ''' Compute renames/removes for a changeset, returning new targetpath -> (old source path, new info). '''
  moves:Dict[str,Tuple[str,PathInfo]] = {}
  for path, info in changes.additions.items(): for dpath, dinfo in changes.deletions.items():
      if info.size == dinfo.size and ((info.hash == dinfo.hash) if strict else (info.mtime == dinfo.mtime)):  # was moved
        if dpath not in moves or path.split(SLASH)[-1] == dpath.split(SLASH)[-1]:  # only override previously stored arbitrary move, when name match perfectly this time TODO compare even more parent folders when matching
          moves[dpath] = (path, info)  # store new data and original name, but don't remove add/del
        break  # deletions loop, continue with next addition
  {path: (dpath, info) for dpath, (path, info) in moves.items()}  # sort by target (by moved-to)

def user_input(text:str, choices:Iterable[str], default:str = None, selection:str = "") -> str =
  ''' Default can be a selection from choice and allows empty input. '''
  while True:
    selection = input(text).strip().lower()
    if selection != "" and selection in choices: break
    if selection == "" and default is not None: selection = default; break
  selection

def user_block_input(output:List[str]):
  ''' Side-effect appending to input list. '''
  sep:str = input("Enter end-of-text marker (default: <empty line>: "); line:str = sep
  while True:
    line = input("> ")
    if line == sep: break
    output.append(line)  # writes to caller-provided list reference

def merge(
      file:bytes? = None, into:bytes? = None,
      filename:str? = None, intoname:str? = None,
      mergeOperation:MergeOperation = MergeOperation.BOTH,
      charMergeOperation:MergeOperation = MergeOperation.BOTH,
      diffOnly:bool = False,
      eol:bool = False,
      ignoreWhitespace:bool = False
    ) -> Tuple[Union[bytes,List[MergeBlock]],bytes?] =
  ''' Merges other binary text contents 'file' (or reads file 'filename') into current text contents 'into' (or reads file 'intoname'), returning merged result.
      For 'sos update', the other version is assumed to be the "new/added" one, while for diff, the 'file' with changes is the one shown as "added".
      However, change direction markers are insert ("+") for elements only in into, and remove ("-") for elements only in other file (just like the diff marks +/-)
      diffOnly: if True, return detected change blocks only, no actual text merging
      eol: if True, will use the other file's EOL marks
      in case of replace block and INSERT strategy, the change will be added **behind** the original. HINT could be configurable
  '''
  encoding:str; othr:str[]; othreol:bytes?; curr:str[]; curreol:bytes?
  try:  # load files line-wise and normalize line endings (keep the one of the current file) TODO document
    encoding, othreol, othr = detectAndLoad(filename = filename, content = file, ignoreWhitespace = ignoreWhitespace)
    encoding, curreol, curr = detectAndLoad(filename = intoname, content = into, ignoreWhitespace = ignoreWhitespace)
  except Exception as E: Exit("Cannot merge '%s' into '%s': %r" % (filename, intoname, E))
  if None not in [othreol, curreol] and othreol != curreol: warn("Differing EOL-styles detected during merge. Using current file's style for merged output")
  output:List[str] = list(difflib.Differ().compare(othr, curr))  # from generator expression
  blocks:List[MergeBlock] = []  # merged result in blocks
  tmp:List[str] = []  # block lines
  last:str = " "; no:int; line:str; offset:int = 0  # "into"-file offset for remark lines
  for no, line in enumerate(output + ["X"]):  # EOF marker (difflib's output will never be "X" alone)
    if line[0] == last: tmp.append(line[2:]); continue  # continue filling current block, no matter what type of block it is
    if line == "X" and len(tmp) == 0: break  # break if nothing left to do, otherwise perform operation for stored block
    if last == " ":  # block is same in both files
      if len(tmp) > 0: blocks.append(MergeBlock(MergeBlockType.KEEP, [line for line in tmp], line = no - offset - len(tmp)))  # avoid adding empty keep block
    elif last == "-":  # may be a pure deletion or part of a replacement (with next block being "+")
      blocks.append(MergeBlock(MergeBlockType.REMOVE, [line for line in tmp], line = no - offset - len(tmp)))
      if len(blocks) >= 2 and blocks[-2].tipe == MergeBlockType.INSERT:
        offset += len(blocks[-2].lines)
        blocks[-2] = dataCopy(MergeBlock, blocks[-1], tipe = MergeBlockType.REPLACE, replaces = dataCopy(MergeBlock, blocks[-2], line = blocks[-1].line))  # remember replaced stuff with reference to other merge block TODO why -1 necessary?
        blocks.pop()
    elif last == "+":  # may be insertion or replacement (with previous - block)
      blocks.append(MergeBlock(MergeBlockType.INSERT, [line for line in tmp], line = no - offset - len(tmp)))  # first, assume simple insertion, then check for replacement
      if len(blocks) >= 2 and blocks[-2].tipe == MergeBlockType.REMOVE:  #  and len(blocks[-1].lines) == len(blocks[-2].lines):  # requires previous block and same number of lines TODO allow multiple intra-line merge for same-length blocks
        offset += len(blocks[-1].lines)
        blocks[-2] = dataCopy(MergeBlock, blocks[-2], tipe = MergeBlockType.REPLACE, replaces = dataCopy(MergeBlock, blocks[-1], line = blocks[-2].line))  # remember replaced stuff with reference to other merge block TODO why -1 necessary?
        blocks.pop()  # remove TOS due to merging two blocks into replace or modify
    elif last == "?": offset += 1  # marker for intra-line change comment HINT was earlier part of the MergeBlock
    last = line[0]
    tmp[:] = [line[2:]]  # only keep current line for next block
  # TODO add code to detect moved blocks here
  nl:bytes = othreol if eol else (curreol ?? othreol)  # no default newline, to mark "no newline"
  debug("Diff blocks: " + repr(blocks))
  if diffOnly: return (blocks, nl)

  # now perform merge operations depending on detected blocks
  output[:] = []; add_all:str?; del_all:str?; selection:str  # clean list of strings
  for block in blocks:
    if block.tipe == MergeBlockType.KEEP: output.extend(block.lines)
    elif (block.tipe == MergeBlockType.INSERT and not(mergeOperation.value & MergeOperation.REMOVE.value))\
      or (block.tipe == MergeBlockType.REMOVE and    (mergeOperation.value & MergeOperation.INSERT.value)):  # will add line despite remove if --add-line was selected
      output.extend(block.lines)
    elif block.tipe == MergeBlockType.REPLACE:  # complete block replacement
      if len(block.lines) == len(block.replaces.lines) == 1:  # one-liner
        output.append(lineMerge(block.lines[0], block.replaces.lines[0], mergeOperation = charMergeOperation))
      elif mergeOperation == MergeOperation.ASK:  # more than one line: needs user input
        printo(pure.ajoin("- ", block.lines, nl = "\n"))  # TODO check +/- in update mode, could be swapped
        printo(pure.ajoin("+ ", block.replaces.lines, nl = "\n"))
        while True:
          op:str = input(" Line replacement: *M[I]ne (+), [T]heirs (-), [B]oth, [U]ser input: ").strip().lower()[:1]
          if op in "tb": output.extend(block.lines)
          if op in "ib": output.extend(block.replaces.lines)
          if op == "u": user_block_input(output)
          if op in "tbiu": break
      else:  # more than one line and not ask
        if   mergeOperation == MergeOperation.REMOVE: pass
        elif mergeOperation == MergeOperation.BOTH: output.extend(block.lines)
        elif mergeOperation == MergeOperation.INSERT: output.extend(list(block.replaces.lines) + list(block.lines))  # TODO optionally allow insertion BEFORE or AFTER original (order of these both lines)
    elif block.tipe in (MergeBlockType.INSERT, MergeBlockType.REMOVE) and mergeOperation == MergeOperation.ASK:  # user - interactive insert/remove section
      if (block.tipe == MergeBlockType.INSERT and add_all is None)\
      or (block.tipe == MergeOperation.REMOVE and del_all is None):  # condition for asking
        selection = user_input(pure.ajoin("+ " if block.tipe == MergeBlockType.INSERT else "- ", block.lines) + "\n  Accept? *[Y]es, [N]o, yes to [A]ll %s, n[O] to all: " % "insertions" if block.tipe == MergeBlockType.INSERT else "deletions", "ynao", "y")
        if selection in "ao":
          if block.tipe == MergeBlockType.INSERT: add_all = "y" if selection == "a" else "n"; selection = add_all
          else:                                   del_all = "y" if selection == "a" else "n"; selection = del_all  # REMOVE case
      if (block.tipe == MergeBlockType.INSERT and "y" in (add_all, selection))\
      or (                                        "n" in (del_all, selection)):  # REMOVE case
        output.extend(block.lines)
  debug("Merge output: " + "; ".join(output))
  ((nl ?? b"\n").join([line.encode(encoding) for line in output]), nl)  # returning bytes
  # TODO handle check for more/less lines in found -/+ blocks to find common section and splitting prefix/suffix out

def lineMerge(othr:str, into:str, mergeOperation:MergeOperation = MergeOperation.BOTH, diffOnly:bool = False) -> Union[str,List[MergeBlock]]:
  ''' Merges string 'othr' into current string 'into'.
      change direction mark is insert for elements only in into, and remove for elements only in file (according to diff marks +/-)
  '''
  out:List[str] = list(difflib.Differ().compare(othr, into))
  blocks:List[MergeBlock] = []
  for i, line in enumerate(out):
    if line[0] == "+":
      if i + 1 < len(out) and out[i + 1][0] == "+":  # block will continue
        if i > 0 and blocks[-1].tipe == MergeBlockType.INSERT:  # middle of + block
          blocks[-1].lines.append(line[2])  # add one more character to the accumulating list
        else:  # first + in block
          blocks.append(MergeBlock(MergeBlockType.INSERT, [line[2]], i))
      else:  # last line of + block
        if i > 0 and blocks[-1].tipe == MergeBlockType.INSERT:  # end of a block
          blocks[-1].lines.append(line[2])
        else:  # single line
          blocks.append(MergeBlock(MergeBlockType.INSERT, [line[2]], i))
        if i >= 1 and blocks[-2].tipe == MergeBlockType.REMOVE:  # previous - and now last in + block creates a replacement block
          blocks[-2] = MergeBlock(MergeBlockType.REPLACE, blocks[-2].lines, i, replaces = blocks[-1]); blocks.pop()
    elif line[0] == "-":
      if i > 0 and blocks[-1].tipe == MergeBlockType.REMOVE:  # part of - block
        blocks[-1].lines.append(line[2])
      else:  # first in block
        blocks.append(MergeBlock(MergeBlockType.REMOVE, [line[2]], i))
    elif line[0] == " ":
      if i > 0 and blocks[-1].tipe == MergeBlockType.KEEP:  # part of block
        blocks[-1].lines.append(line[2])
      else:  # first in block
        blocks.append(MergeBlock(MergeBlockType.KEEP, [line[2]], i))
    else: raise Exception("Cannot parse diff line %r" % line)
  blocks[:] = [dataCopy(MergeBlock, block, lines = ["".join(block.lines)], replaces = dataCopy(MergeBlock, block.replaces, lines = ["".join(block.replaces.lines)]) if block.replaces else None) for block in blocks]
  if diffOnly: return blocks
  out[:] = []
  for i, block in enumerate(blocks):
    if   block.tipe == MergeBlockType.KEEP: out.extend(block.lines)
    elif block.tipe == MergeBlockType.REPLACE:
      if mergeOperation == MergeOperation.ASK:
        printo(pure.ajoin("- ", othr))
        printo("- " + (" " * i) + block.replaces.lines[0])
        printo("+ " + (" " * i) + block.lines[0])
        printo(pure.ajoin("+ ", into))
        op:str = user_input(" Character replacement: *M[I]ne (+), [T]heirs (-), [B]oth, [U]ser input: ", "tbim")
        if op in "tb": out.extend(block.lines); break
        if op in "ib": out.extend(block.replaces.lines); break
        if op == "m":  user_block_input(out); break
      else:  # non-interactive
        if   mergeOperation == MergeOperation.REMOVE: pass
        elif mergeOperation == MergeOperation.BOTH: out.extend(block.lines)
        elif mergeOperation == MergeOperation.INSERT: out.extend(list(block.replaces.lines) + list(block.lines))
    elif block.tipe == MergeBlockType.INSERT and not (mergeOperation.value & MergeOperation.REMOVE.value): out.extend(block.lines)
    elif block.tipe == MergeBlockType.REMOVE and      mergeOperation.value & MergeOperation.INSERT.value:  out.extend(block.lines)
    # TODO ask for insert or remove as well
  return "".join(out)

def findSosVcsBase() -> Tuple[str?,str?,str?] =
  ''' Attempts to find sos and legacy VCS base folders.
      Returns (SOS-repo root, VCS-repo root, VCS command)
  '''
  debug("Detecting root folders...")
  path:str = os.getcwd()  # start in current folder, check parent until found or stopped
  vcs:Tuple[str?,str?] = (None, None)
  while not os.path.exists(encode(os.path.join(path, metaFolder))):
    contents:Set[str] = set(os.listdir(path))
    vcss:str[] = [executable for folder, executable in vcsFolders.items() if folder in contents or (SLASH in folder and os.path.exists(os.path.join(os.getcwd(), folder.replace(SLASH, os.sep))))]  # determine VCS type from existence of dot folder TODO use encode?
    choice:str? = None
    if len(vcss) > 1:
      choice = SVN if SVN in vcss else vcss[0]  # SVN is preferred
      warn("Detected more than one parallel VCS checkouts %r. Falling back to '%s'" % (vcss, choice))
    elif len(vcss) > 0: choice = vcss[0]
    if not vcs[0] and choice: vcs = (path, choice)  # memorize current repo root
    new = os.path.dirname(path)  # get parent path
    if new == path: break  # avoid infinite loop
    path = new
  if os.path.exists(encode(os.path.join(path, metaFolder))):  # found something
    if vcs[0]: return (path, vcs[0], vcs[1])  # already detected vcs base and command
    sos = path
    while True:  # continue search for VCS base
      contents = set(os.listdir(path))
      vcss = [executable for folder, executable in vcsFolders.items() if folder in contents]  # determine VCS type
      choice = None
      if len(vcss) > 1:
        choice = SVN if SVN in vcss else vcss[0]
        warn("Detected more than one parallel VCS checkouts %r. Falling back to '%s'" % (vcss, choice))
      elif len(vcss) > 0: choice = vcss[0]
      if choice: return (sos, path, choice)
      new = os.path.dirname(path)  # get parent path
      if new == path: return (sos, None, None)  # no VCS folder found
      path = new
  (None, vcs[0], vcs[1])

def tokenizeGlobPattern(pattern:str) -> List[GlobBlock] =
  index:int = 0
  out:List[GlobBlock] = []  # literal = True, first index
  while index < len(pattern):
    if pattern[index:index + 3] in ("[?]", "[*]", "[[]", "[]]"): out.append(GlobBlock(False, pattern[index:index + 3], index)); continue
    if pattern[index] in "*?":
      count:int = 1
      while index + count < len(pattern) and pattern[index] == "?" and pattern[index + count] == "?": count += 1
      out.append(GlobBlock(False, pattern[index:index + count], index)); index += count; continue
    if pattern[index:index + 2] == "[!": out.append(GlobBlock(False, pattern[index:pattern.index("]", index + 2) + 1], index)); index += len(out[-1][1]); continue
    count = 1
    while index + count < len(pattern) and pattern[index + count] not in "*?[": count += 1
    out.append(GlobBlock(True, pattern[index:index + count], index)); index += count
  out

def tokenizeGlobPatterns(oldPattern:str, newPattern:str) -> Tuple[GlobBlock[], GlobBlock[]] =
  ot:List[GlobBlock] = tokenizeGlobPattern(oldPattern)
  nt:List[GlobBlock] = tokenizeGlobPattern(newPattern)
#  if len(ot) != len(nt): Exit("Source and target patterns can't be translated due to differing number of parsed glob markers and literal strings")
  if len([o for o in ot if not o.isLiteral]) < len([n for n in nt if not n.isLiteral]): Exit("Source and target file patterns contain differing number of glob markers and can't be translated")
  if any(O.content != N.content for O, N in zip([o for o in ot if not o.isLiteral], [n for n in nt if not n.isLiteral])): Exit("Source and target file patterns differ in semantics")
  (ot, nt)

def convertGlobFiles(filenames:str[], oldPattern:GlobBlock[], newPattern:GlobBlock[]) -> Tuple[str,str][] =
  ''' Converts given filename according to specified file patterns. No support for adjacent glob markers currently. '''
  pairs:List[Tuple[str,str]] = []
  for filename in filenames:
    literals:List[GlobBlock] = [l for l in oldPattern if l.isLiteral]  # source literals
    nextliteral:int = 0; index:int = 0
    parsedOld:List[GlobBlock2] = []
    for part in oldPattern:  # match everything in the old filename
      if part.isLiteral: parsedOld.append(GlobBlock2(True, part.content, part.content)); index += len(part.content); nextliteral += 1
      elif part.content.startswith("?"): parsedOld.append(GlobBlock2(False, part.content, filename[index:index + len(part.content)])); index += len(part.content)
      elif part.content.startswith("["): parsedOld.append(GlobBlock2(False, part.content, filename[index])); index += 1
      elif part.content == "*":
        if nextliteral >= len(literals): parsedOld.append(GlobBlock2(False, part.content, filename[index:])); break
        nxt:int = filename.index(literals[nextliteral].content, index)  # also matches empty string
        parsedOld.append(GlobBlock2(False, part.content, filename[index:nxt])); index = nxt
      else: Exit("Invalid file pattern specified for move/rename")
    globs:List[GlobBlock2] = [g for g in parsedOld if not g.isLiteral]
    literals = [l for l in newPattern if l.isLiteral]  # target literals
    nextliteral = 0; nextglob:int = 0
    outname:List[str] = []
    for part in newPattern:  # generate new filename
      if part.isLiteral: outname.append(literals[nextliteral].content); nextliteral += 1
      else: outname.append(globs[nextglob].matches); nextglob += 1
    pairs.append((filename, "".join(outname)))
  pairs

def reorderRenameActions(actions:Tuple[str,str][], exitOnConflict:bool = True) -> Tuple[str,str][] =
  ''' Attempt to put all rename actions into an order that avoids target == source names.
      Note, that it's currently not really possible to specify patterns that make this work (swapping "*" elements with a reference).
      An alternative would be to always have one (or all) files renamed to a temporary name before renaming to target filename.
  '''
  if not actions: return []
  sources:List[str]; targets:List[str]
  sources, targets = [list(l) for l in zip(*actions)]
  last:int = len(actions)
  while last > 1:
    clean:bool = True
    for i in range(1, last):
      try:
        index:int = targets[:i].index(sources[i])
        sources.insert(index, sources.pop(i))  # bubble up the action right before conflict
        targets.insert(index, targets.pop(i))
        clean = False
      except: continue  # target not found in sources: good!
    if clean: break
    last -= 1  # we know that the last entry in the list has the least conflicts, so we can disregard it in the next iteration
  if exitOnConflict: for i in range(1, len(actions)): if sources[i] in targets[:i]: Exit("There is no order of renaming actions that avoids copying over not-yet renamed files: '%s' is contained in matching source filenames" % (targets[i]))
  list(zip(sources, targets))  # convert to list to avoid generators

def relativize(root:str, filepath:str) -> Tuple[str,str] =
  ''' Determine OS-independent relative folder path, and relative pattern path. Always expects a file and determines its folder's relative path. '''
  relpath = os.path.relpath(os.path.dirname(os.path.abspath(filepath)), root).replace(os.sep, SLASH)
  relpath, os.path.join(relpath, os.path.basename(filepath)).replace(os.sep, SLASH)

def parseOnlyOptions(cwd:str, options:List[str]) -> Tuple[FrozenSet[str]?, FrozenSet[str]?] =
  ''' Returns (root-normalized) set of --only arguments, and set or --except arguments. '''
  root:str = os.getcwd()
  onlys:List[str] = []; excps:List[str] = []; index:int = 0  # zero necessary as last start position
  while True:
    try:
      index = 1 + listindex(options, "--only", index)
      onlys.append(options[index])
      del options[index]
      del options[index - 1]
    except: break
  index = 0
  while True:
    try:
      index = 1 + listindex(options, "--except", index)
      excps.append(options[index])
      del options[index]
      del options[index - 1]
    except: break
  ( frozenset(oo for oo in (relativize(root, os.path.normpath(os.path.join(cwd, o)))[1] for o in onlys) if not oo.startswith(".." + SLASH)) if onlys else None,
    frozenset(ee for ee in (relativize(root, os.path.normpath(os.path.join(cwd, e)))[1] for e in excps) if not ee.startswith(".." + SLASH)) if excps else None )  # avoids out-of-repo paths
