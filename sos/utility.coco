# Copyright Arne Bachmann
# This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/.

import hashlib, itertools, logging, os, shutil, sys, time; START_TIME = time.time()  # early time tracking

if TYPE_CHECKING: from typing import Any, AnyStr, Dict, FrozenSet, Generic, IO, Iterable, Iterator, NoReturn, List, Optional, Sequence, Set, Tuple, Type, TypeVar, Union   # we cannot delay this import, since we need to type-check the Coconut version-detection, which again is required to know if we actually can type-check...

from sos import pure
from sos.values import *
from sos import usage


# Lazy imports for quicker initialization TODO make mypy accept this
bz2:Any; codecs:Any; difflib:Any
class bz2: def __getattribute__(_, key):
  global bz2; import bz2; return bz2.__getattribute__(key)
bz2:object = bz2()

class codecs: def __getattribute__(_, key):
  global codecs; import codecs; return codecs.__getattribute__(key)
codecs:object = codecs()

class difflib: def __getattribute__(_, key):
  global difflib; import difflib; return difflib.__getattribute__(key)
difflib:object = difflib()


verbose:List[None] = [None] if '--verbose' in sys.argv or '-v' in sys.argv else []
debug_:List[None] =  [None] if os.environ.get("DEBUG", "False").lower() == "true" or '--debug' in sys.argv else []


# Classes
class Accessor(dict):
  ''' Dictionary with attribute access. '''
  def __init__(_, mapping:Dict[str,Any] = {}) -> None: dict.__init__(_, mapping)
  def __getattribute__(_, name:str) -> Any:  # or simply class C(dict): __getattr__ = dict.__getitem__
    try: return _[name]
    except: return dict.__getattribute__(_, name)
  def __setattr__(_, name:str, value: Any) -> None: _[name] = value
  def __bool__(_) -> bool: return bool(int(_[None]))
  def __str__(_) -> str: return str(_[None])
  def __add__(_, b:Any) -> str: return _.value + b

useColor:List[bool?] = [None]
def enableColor(enable:bool = True, force:bool = False):
  ''' This piece of code only became necessary to enable enabling/disabling of the colored terminal output after initialization.
      enable: target state
      force: for testing only
  '''
  if not force and (useColor[0] if enable else not useColor[0]): return  # nothing to do since already set
  MARKER.value = MARKER_COLOR if enable and sys.platform != "win32" else usage.MARKER_TEXT  # HINT because it doesn't work with the loggers yet
  try:
    if useColor[0] is None:  # very initial, do some monkey-patching
      colorama.init(wrap = False)
      sys.stdout = colorama.AnsiToWin32(sys.stdout).stream  # TODO replace by "better-exceptions" code
      sys.stderr = colorama.AnsiToWin32(sys.stderr).stream
  except: pass
  useColor[0] = enable

# fallbacks in case there is no colorama library present
Fore:Dict[str,str]  = Accessor({k: "" for k in ["RESET", "BLUE", "CYAN", "GREEN", "MAGENTA", "RED", "YELLOW", "WHITE"]})
Style:Dict[str,str] = Accessor({k: "" for k in ["NORMAL", "BRIGHT", "RESET_ALL"]})
Back:Dict[str,str]  = Fore
MARKER:str = Accessor({"value": usage.MARKER_TEXT})  # assume default text-only
try:
  import colorama, colorama.ansitowin32
  if sys.stderr.isatty:  # list of ansi codes: http://bluesock.org/~willkg/dev/ansi.html
    from colorama import Back, Fore, Style
    MARKER_COLOR:str = Fore.WHITE + usage.MARKER_TEXT + Fore.RESET
    if sys.platform == "win32": Style.BRIGHT = ""  # sadly this would modify background color as well in the Windows console to make it appear brighter
    enableColor()
except: MARKER_COLOR = usage.MARKER_TEXT  # if library not installed, use fallback even for colored texts

if TYPE_CHECKING:  # available since coconut 1.3.1.21 (?)
  Number = TypeVar("Number", int, float)
  class Counter(Generic[Number]):
    ''' A simple counter. Can be augmented to return the last value instead. '''
    def __init__(_, initial:Number = 0) -> None: _.value:Number = initial
    def inc(_, by:Number = 1) -> Number: _.value += by; return _.value
else:
  class Counter:
    def __init__(_, initial = 0) -> None: _.value = initial
    def inc(_, by = 1): _.value += by; return _.value

class ProgressIndicator(Counter):
  ''' Manages a rotating progress indicator. '''
  def __init__(_, symbols:str, callback:Optional[(str) -> None] = None) -> None: super(ProgressIndicator, _).__init__(-1); _.symbols = symbols; _.timer:float = time.time(); _.callback:Optional[(str) -> None] = callback
  def getIndicator(_) -> str? =
    ''' Returns a value only if a certain time has passed. '''
    newtime:float = time.time()
    if newtime - _.timer < .1: return None
    _.timer = newtime
    sign:str = _.symbols[int(_.inc() % len(_.symbols))]
    if _.callback: _.callback(sign)
    sign

class Logger:
  ''' Logger that supports joining many items. '''
  def __init__(_, log) -> None: _._log = log
  def debug(_, *s): _._log.debug(pure.sjoin(*s))
  def info(_, *s): _._log.info(pure.sjoin(*s))
  def warn(_, *s): _._log.warning(pure.sjoin(*s))
  def error(_, *s): _._log.error(pure.sjoin(*s))


# Constants
_log = Logger(logging.getLogger(__name__)); debug, info, warn, error = _log.debug, _log.info, _log.warn, _log.error
ONLY_GLOBAL_FLAGS:List[str] = ["strict", "track", "picky", "compress"]
CONFIGURABLE_FLAGS:List[str] = ["useChangesCommand", "useUnicodeFont", "useColorOutput"]
CONFIGURABLE_LISTS:List[str] = ["texttype", "bintype", "ignores", "ignoreDirs", "ignoresWhitelist", "ignoreDirsWhitelist"]
CONFIGURABLE_INTS:List[str] = ["logLines", "diffLines"]
GLOBAL_LISTS:List[str] = ["ignores", "ignoreDirs", "ignoresWhitelist", "ignoreDirsWhitelist"]  # lists that don't allow folders with their file patterns
TRUTH_VALUES:List[str] = ["true", "yes", "on", "1", "enable", "enabled"]  # all lower-case normalized
FALSE_VALUES:List[str] = ["false", "no", "off", "0", "disable", "disabled"]
PROGRESS_MARKER:List[str] =  ["|/-\\", "\u2581\u2582\u2583\u2584\u2585\u2586\u2587\u2588\u2587\u2586\u2585\u2584\u2583\u2582", "\U0001f55b\U0001f550\U0001f551\U0001f552\U0001f553\U0001f554\U0001f555\U0001f556\U0001f557\U0001f558\U0001f559\U0001f55a\U0001f559\U0001f558\U0001f557\U0001f556\U0001f555\U0001f554\U0001f553\U0001f552\U0001f551\U0001f550"]
BACKUP_SUFFIX:str = "_last"
metaFolder:str = ".sos"
DUMP_FILE:str = metaFolder + ".zip"
metaFile:str = ".meta"
metaBack:str = metaFile + BACKUP_SUFFIX
bufSize:int = pure.MEBI
UTF8:str = "utf-8"  # early used constant, not defined in standard library
SVN:str = "svn"
SLASH:str = "/"
PARENT:str = ".."
DOT_SYMBOL:str = "\u00b7"
MULT_SYMBOL:str = "\u00d7"
CROSS_SYMBOL:str = "\u2716"
CHECKMARK_SYMBOL:str = "\u2714"
PLUSMINUS_SYMBOL:str = "\u00b1"  # alternative for "~"
ARROW_SYMBOL:str = "\u2799"  # alternative for "*" in "this revision"
MOVE_SYMBOL:str = "\u21cc"  # alternative for "#". or use \U0001F5C0", which is very unlikely to be in any console font
METADATA_FORMAT:int = 2  # counter for (partially incompatible) consecutive formats (was undefined, "1" is the first numbered format version after that)
vcsFolders:Dict[str,str] = {".svn": SVN, ".git": "git", ".bzr": "bzr", ".hg": "hg", ".fslckout": "fossil", "_FOSSIL_": "fossil", ".CVS": "cvs", "_darcs": "darcs", "_MTN": "monotone", ".git/GL_COMMIT_EDIT_MSG": "gl"}
vcsBranches:Dict[str,str?] = {SVN: "trunk", "git": "master", "bzr": "trunk", "hg": "default", "fossil": None, "cvs": None, "darcs": None, "monotone": None}
vcsCommits:Dict[str,Tuple[bool,str?]] = {SVN: (True, None), "git": (False, None), "bzr": (True, None), "hg": (True, None), "fossil": (True, "--no-warnings"), "cvs": (True, None), "darcs": (False, "--all"), "monotone": (False, None)}  # 2-tuple(is_tracked? (otherwise picky), str-arguments to "commit") TODO CVS, RCS have probably different per-file operation
vcsNames:Dict[str,str] = {SVN: "Subversion", "git": "Git", "bzr": "Bazaar", "hg": "Mercurial", "fossil": "Fossil", "cvs": "CVS", "darcs": "darcs", "monotone": "monotone"}#  from cmd to long name
NL_NAMES:Dict[bytes?,str] = {None: "<No newline>", b"\r\n": "<CR+LF>", b"\n\r": "<LF+CR>", b"\n": "<LF>", b"\r": "<CR>"}
MAX_COMMAND_LINE:Dict[str?,int] = {"win32": 8191, "linux2": 4096, None: 1023}  # may be much longer on posix. https://stackoverflow.com/questions/3205027/maximum-length-of-command-line-string
defaults:Accessor = Accessor({
    "strict": False, "track": False, "picky": False, "compress": False,  # these cannot be modified by the user interface
    "useChangesCommand": False,  # for Git likeness
    "useUnicodeFont": sys.platform != "win32",
    "useColorOutput": True,  # TODO make this depend on colorama present, which isn't loaded here yet (lazy eval?)
    "diffLines": 2,
    "logLines": 20,
    "texttype": ["*.md", "*.coco", "*.py", "*.pyi", "*.pth", "*.ps1", "*.bat"],
    "bintype": [],
    "ignoreDirs": [".*", "__pycache__", ".mypy_cache"],  # already includes metaFolder
    "ignoreDirsWhitelist": [],
    "ignores": ["__coconut__.py", "*.bak", "*.py[cdo]", "*.class", ".fslckout", "_FOSSIL_", "*%s" % DUMP_FILE] + ["~*"] if sys.platform == "win32" else [],
    "ignoresWhitelist": []
  })
RETRY_NUM:int = 3
RETRY_WAIT:int = 1.5
CODEC_FUNCTIONS:List[str] = ['utf_32_be', 'utf_32_le', 'utf_32', 'utf_16_be', 'utf_16_le', 'utf_16', 'utf_7', 'utf_8_sig', 'utf_8']


# Functions
def printo(s:str = "", nl:str = "\n", color:str? = None):
  color = useColor[0] and color or ""
  reset = Fore.RESET if useColor[0] and color else ""
  tryOrIgnore(( ) -> sys.stdout.write(color + s + reset + nl) and False,
              (E) -> sys.stdout.buffer.write((s + nl).encode(sys.stdout.encoding, 'backslashreplace')) and False); sys.stdout.flush()  # PEP528 compatibility

def printe(s:str = "", nl:str = "\n", color:str? = None):
  color = useColor[0] and color or ""
  reset = Fore.RESET if useColor[0] and color else ""
  tryOrIgnore(( ) -> sys.stderr.write(color + s + reset + nl) and False,
              (E) -> sys.stderr.buffer.write((s + nl).encode(sys.stderr.encoding, 'backslashreplace')) and False); sys.stderr.flush()

def encode(s:str) -> bytes: return os.fsencode(s)  # for py->os access of writing filenames  # PEP 529 compatibility

def decode(b:bytes) -> str: return os.fsdecode(b)  # for os->py access of reading filenames

def guessEncoding(binary:bytes) -> List[str] =
  ''' If encoding cannot be determined automatically, attempt a guess. Usually it's not unambiguous, though.
  >>> print(guessEncoding(b"abcd0234"))
  ['ascii']
  >>> print(guessEncoding(bytes([0b00100100, 0b11000010, 0b10100010, 0b11100010, 0b10000010, 0b10101100, 0b11110000, 0b10011010, 0b10110011, 0b10011001])))  # utf_8  1:$ 2:cent 3:€, 4:? -> gives 5 options, but it's UTF-8
  ['utf_16_be', 'utf_16_le', 'utf_8']
  >>> print(guessEncoding(bytes([0b00000000, 0b00100100, 0b11011000, 0b01010010, 0b11011111, 0b01100010])))  # utf_16 $ ? -> gives 3 options, on is correct
  ['utf_16_be', 'utf_16_le']
  >>> print(guessEncoding(bytes([0b00100100, 0b11000010, 0b10100010])))  # utf_8  1:$ 2:cent 3:€, 4:? -> gives 2 UTF-8 options
  ['utf_8']
  '''
  if all(bite < 128 for bite in binary): return ["ascii"]  # TODO move as first detection step
  decoded:List[str] = list(filter(-> tryOrDefault(() -> codecs.encode(codecs.decode(binary, _), _) == binary, None), CODEC_FUNCTIONS))
  if (len(binary) >> 1) << 1 != len(binary): decoded[:] = list(filter(-> "8" in _, decoded))  # only utf-8 variants possible here
  decoded

# Optional dependency: https://github.com/chardet/chardet
try:
  import chardet
  def detectEncoding(binary:bytes) -> str? = chardet.detect(binary)["encoding"]  # returns None if nothing useful detected
except:
  def detectEncoding(binary:bytes) -> str? =
    ''' Fallback function definition if no chardet library installed. '''
    encodings:List[str] = guessEncoding(binary)
    if len(encodings) == 1: return encodings[0]
    if len(encodings) == 0: return None  # or cp1252 or cp850
    encodings[-1]

def tryOrDefault(func:Callable[[], Any], default:Any) -> Any:
  try: return func()
  except: return default

def tryOrIgnore(func:Callable[[], Any], onError:Callable[[Exception], None] = (e) -> None) -> Any:
  try: return func()
  except Exception as E: onError(E)

def removePath(key:str, value:str) -> str =
  ''' Cleanup of user-specified *global* file patterns, used in config. '''
  value if value in GLOBAL_LISTS or SLASH not in value else value[value.rindex(SLASH)+1:]

def dictUpdate(dikt:Dict[Any,Any], by:Dict[Any,Any]) -> Dict[Any,Any]:
  ''' Updates a dictionary by another one, returning a new copy without touching any of the passed dictionaries. '''
  d:Dict[Any,Any] = dict(dikt); d.update(by); return d

def openIt(file:str, mode:str, compress:bool = False) -> IO[bytes] =
  ''' Abstraction for opening both compressed and plain files. '''
  bz2.BZ2File(encode(file), mode) if compress else open(encode(file), mode + "b")

def eoldet(file:bytes) -> bytes? =
  ''' Determine EOL style from a binary string. '''
  lf:int = file.count(b"\n")
  cr:int = file.count(b"\r")
  crlf:int = file.count(b"\r\n")
  if crlf > 0:  # DOS/Windows/Symbian etc.
    if lf != crlf or cr != crlf: warn("Inconsistent CR/NL count with CR+NL. Mixed EOL style detected, may cause problems during merge")
    return b"\r\n"
  if lf != 0 and cr != 0: warn("Inconsistent CR/NL count without CR+NL. Mixed EOL style detected, may cause problems during merge")
  if lf > cr: return b"\n"  # Linux/Unix
  if cr > lf: return b"\r"  # older 8-bit machines
  None  # no new line contained, cannot determine

if TYPE_CHECKING:
  def safeSplit(s:AnyStr, d:AnyStr? = None) -> List[AnyStr]: return s.split(d ?? ("\n" if isinstance(s, str) else b"\n")) if len(s) > 0 else []
else:
  def safeSplit(s, d = None): return s.split(d ?? ("\n" if isinstance(s, str) else b"\n")) if len(s) > 0 else []

def hashStr(datas:str) -> str = hashlib.sha256(datas.encode(UTF8)).hexdigest()

def modified(changes:ChangeSet, onlyBinary:bool = False) -> bool = len(changes.additions) > 0 or len(changes.deletions) > 0 or len(changes.modifications) > 0 or len(changes.moves) > 0

def listindex(lizt:Sequence[Any], what:Any, index:int = 0) -> int = lizt[index:].index(what) + index

def branchFolder(branch:int, base:str? = None, file:str? = None) -> str = os.path.join(base ?? os.getcwd(), metaFolder, "b%d" % branch) + ((os.sep + file) if file else "")

def revisionFolder(branch:int, revision:int, base:str? = None, file:str? = None) -> str = os.path.join(branchFolder(branch, base), "r%d" % revision) + ((os.sep + file) if file else "")

def Exit(message:str = "", code:int = 1, excp:Any = None):
  if not '--quiet' in sys.argv:
    lines:List[str] = (message + ("" if excp is None else ("\n" + exception(excp)))).replace("\r", "\n").split("\n")
    printe("[", nl = "")
    printe("EXIT", color = Fore.YELLOW if code else Fore.GREEN, nl ="")
    printe("%s%s]" % (
      " %.1fs" % (time.time() - START_TIME) if verbose else "",
      (" " +lines[0] + ".") if lines[0] != "" else "")
    )
    if len(lines) > 1: printe("\n".join(lines[1:]))
  if '--wait' in sys.argv: input("Hit Enter to finish." if not '--quiet' in sys.argv else "")
  sys.exit(code)

def fitStrings(strings:str[], prefix:str, length:int = MAX_COMMAND_LINE.get(sys.platform, MAX_COMMAND_LINE[None]), separator:str = " ", process: -> str = -> '"%s"' % _) -> str =
  ''' Returns a packed string, destructively consuming entries from the provided list. Does similar as xargs. getconf ARG_MAX or xargs --show-limits. '''
  if len(prefix + separator + (strings[0] |> process)) > length: raise Exception("Cannot possibly strings pack into specified length")
  while len(strings) > 0 and len(prefix + separator + (strings[0] |> process)) <= length: prefix += separator + (strings.pop(0) |> process)
  prefix

def exception(E) -> str =
  ''' Report an exception to the user to allow useful bug reporting. '''
  import traceback
  str(E) + "\n" + traceback.format_exc() + "\n" + "".join(traceback.format_list(traceback.extract_stack()))

def hashFile(path:str, compress:bool, saveTo:List[str] = [], callback:Optional[(str) -> None] = None, symbols:str = PROGRESS_MARKER[0]) -> Tuple[str,int] =
  ''' Calculate and return (hash of file contents, compressed sized (if writing) else 0). '''
  indicator:ProgressIndicator? = ProgressIndicator(symbols, callback) if callback else None
  _hash = hashlib.sha256()
  wsize:int = 0
  if saveTo and os.path.exists(encode(saveTo[0])):
    Exit("Hash collision detected. Leaving repository in inconsistent state", 1)  # HINT this exits immediately
  to = openIt(saveTo[0], "w", compress) if saveTo else None
  retry:int = RETRY_NUM
  while True:
    try:
      with open(encode(path), "rb") as fd:
        while True:
          buffer:bytes = fd.read(bufSize)
          _hash.update(buffer)
          if to: to.write(buffer)
          if len(buffer) < bufSize: break
          if indicator: indicator.getIndicator()
        if to:
          to.close()
          wsize = os.stat(encode(saveTo[0])).st_size
          for remote in saveTo[1:]: tryOrDefault(() -> shutil.copy2(encode(saveTo[0]), encode(remote)), (e) -> error("Error creating remote copy %r" % remote))
      break
    except Exception as E:  # (IsADirectoryError, PermissionError)
      retry -= 1
      if retry == 0: raise E
      error("Cannot open %r - retrying %d more times in %.1d seconds" % (path, RETRY_WAIT))
      time.sleep(RETRY_WAIT)
  (_hash.hexdigest(), wsize)

def getAnyOfMap(map:Dict[str,Any], params:str[], default:Any = None) -> Any =
  ''' Utility to find any entries of a dictionary in a list to return the dictionaries value. '''
  for k, v in map.items(): if k in params: return v
  default

def strftime(timestamp:int? = None) -> str = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(timestamp / 1000. if timestamp is not None else None))

def detectAndLoad(filename:str? = None, content:bytes? = None, ignoreWhitespace:bool = False) -> Tuple[str,bytes?,str[]] =
  ''' Detects a (text) file's encoding, detects the end of line markers, loads the file and splits it into lines.
      returns: 3-tuple (encoding-string, end-of-line bytes, [lines])
  '''
  lines:List[str] = []
  if filename is not None: with open(encode(filename), "rb") as fd: content = fd.read()
  encoding:str = detectEncoding(content) ?? sys.getdefaultencoding()
  eol:bytes? = eoldet(content)
  if filename is not None: with codecs.open(encode(filename), encoding = encoding) as fd2: lines = safeSplit(fd2.read(), (eol ?? b"\n").decode(encoding))
  elif content is not None: lines = safeSplit(content.decode(encoding), (eol ?? b"\n").decode(encoding))
  else: return (sys.getdefaultencoding(), b"\n", [])
  if ignoreWhitespace: lines[:] = [line.replace("\t", "  ").strip() for line in lines]
  (encoding, eol, lines)

if TYPE_CHECKING:
  DataType = TypeVar("DataType", BranchInfo, ChangeSet, MergeBlock, PathInfo)
  def dataCopy(_tipe:Type[DataType], _old:DataType, *_args, byValue:bool = False, **_kwargs) -> DataType =
    ''' A better makedata() version. '''
    r:Dict[str,Any] = _old._asdict()
    r.update({k: ([e for e in v] if byValue and isinstance(v, (list, tuple, set)) else v) for k, v in _kwargs.items()})  # copy by value if required
    makedata(_tipe, *(list(_args) + [r[field] for field in _old._fields]))  # TODO also offer copy-by-value here
else:
  def dataCopy(_tipe, _old, *_args, byValue = False, **_kwargs) -> DataType =
    ''' A better makedata() version. '''
    r = _old._asdict()
    r.update({k: ([e for e in v] if byValue and isinstance(v, (list, tuple, set)) else v) for k, v in _kwargs.items()})  # copy by value if required
    makedata(_tipe, *(list(_args) + [r[field] for field in _old._fields]))  # TODO also offer copy-by-value here

def detectMoves(changes:ChangeSet, strict:bool) -> Dict[str,Tuple[str,PathInfo]] =
  ''' Compute renames/removes for a changeset, returning new targetpath -> (old source path, new info). '''
  moves:Dict[str,Tuple[str,PathInfo]] = {}
  for path, info in changes.additions.items(): for dpath, dinfo in changes.deletions.items():
      if info.size == dinfo.size and ((info.hash == dinfo.hash) if strict else (info.mtime == dinfo.mtime)):  # was moved
        if dpath not in moves or path.split(SLASH)[-1] == dpath.split(SLASH)[-1]:  # only override previously stored arbitrary move, when name match perfectly this time TODO compare even more parent folders when matching
          moves[dpath] = (path, info)  # store new data and original name, but don't remove add/del
        break  # deletions loop, continue with next addition
  {path: (dpath, info) for dpath, (path, info) in moves.items()}  # sort by target (by moved-to)

def user_input(text:str, choices:Iterable[str], default:str = None, selection:str = "") -> str =
  ''' Default can be a selection from choice and allows empty input. '''
  while True:
    selection = input(text).strip().lower()
    if selection != "" and selection in choices: break
    if selection == "" and default is not None: selection = default; break
  selection

def user_block_input(output:List[str]):
  ''' Side-effect appending to input list. '''
  sep:str = input("Enter end-of-text marker (default: <empty line>: "); line:str = sep
  while True:
    line = input("> ")
    if line == sep: break
    output.append(line)  # writes to caller-provided list reference

def mergeClassic(file:bytes, intofile:str, fromname:str, intoname:str, totimestamp:int, context:int, ignoreWhitespace:bool = False):
  encoding:str; othreol:bytes?; othr:str[]; curreol:bytes?; curr:str[]  # typing
  try:
    encoding, othreol, othr = detectAndLoad(content = file, ignoreWhitespace = ignoreWhitespace)
    encoding, curreol, curr = detectAndLoad(filename = intofile, ignoreWhitespace = ignoreWhitespace)
  except Exception as E: Exit("Cannot diff '%s' vs '%s': %r" % (fromname ?? "<bytes>", intoname ?? "<bytes>"), excp = E)  # in case of binary files
  for line in difflib.context_diff(othr, curr, fromname, intoname, time.ctime(int(totimestamp / 1000))): printo(line)  # from generator expression

def merge(
      file:bytes? = None, into:bytes? = None,
      filename:str? = None, intoname:str? = None,
      mergeOperation:MergeOperation = MergeOperation.BOTH,
      charMergeOperation:MergeOperation = MergeOperation.BOTH,
      diffOnly:bool = False,
      eol:bool = False,
      ignoreWhitespace:bool = False
    ) -> Tuple[Union[bytes,List[MergeBlock]],bytes?] =
  ''' Merges other binary text contents in 'file' (or reads from file 'filename') into current text contents 'into' (or reads from file 'intoname'), returning merged result.
      For 'sos update', the other version is assumed to be the "new/added" one, while for diff, the 'file' with changes is the one shown as "added".
      However, change direction markers are insert ("+") for elements only in into, and remove ("-") for elements only in other file (just like the diff marks +/-)
      diffOnly: if True, return detected change blocks only, don't perform the actual text merging
      eol: if True, will use the other file's EOL marks instead of current file's
      in case of a replace block and INSERT strategy, the change will be added **behind** the original. HINT this could be made configurable
  '''
  encoding:str; othreol:bytes?; othr:str[]; curreol:bytes?; curr:str[]  # typing
  try:  # load files line-wise and normalize line endings (keep the one of the current file) TODO document
    encoding, othreol, othr = detectAndLoad(filename = filename, content = file, ignoreWhitespace = ignoreWhitespace)
    encoding, curreol, curr = detectAndLoad(filename = intoname, content = into, ignoreWhitespace = ignoreWhitespace)
  except Exception as E: Exit("Cannot merge '%s' into '%s': %r" % (filename ?? "<bytes>", intoname ?? "<bytes>"), excp = E)
  if None not in (othreol, curreol) and othreol != curreol: warn("Differing EOL-styles detected during merge. Using current file's style for merged output")
  output:Union[Iterable[str], List[str]] = difflib.Differ().compare(othr, curr)
  blocks:List[MergeBlock] = []  # merged result in blocks
  tmp:List[str] = []  # block of consecutive lines
  last:str = " "; no:int; line:str; offset:int = 0  # "into"-file offset for remark lines

  for no, line in pure.appendEndmarkerIterator(enumerate(output), endValue = "X"):  # EOF marker (difflib's output will never be "X" alone)
    if line[0] == last: tmp.append(line[2:]); continue  # continue filling current block, no matter what type of block it is
    if line == "X" and len(tmp) == 0: break  # break if nothing left to do, otherwise perform operation for stored block
    if last == " " and len(tmp) > 0: blocks.append(MergeBlock(MergeBlockType.KEEP, [line for line in tmp], line = no - offset - len(tmp)))  # same in both files. avoid adding empty keep block
    elif last == "-":  # may be a pure deletion or part of a replacement (with previous or next block being "+")
      blocks.append(MergeBlock(MergeBlockType.REMOVE, [line for line in tmp], line = no - offset - len(tmp)))
      if len(blocks) >= 2 and blocks[-2].tipe == MergeBlockType.INSERT:  # is a +/- replacement
        offset += len(blocks[-2].lines)
        blocks[-2] = dataCopy(MergeBlock, blocks[-1], tipe = MergeBlockType.REPLACE, replaces = dataCopy(MergeBlock, blocks[-2], line = blocks[-1].line))  # remember replaced stuff with reference to insert merge block TODO why -1 necessary?
        blocks.pop()
    elif last == "+":  # may be a pure insertion or part of a replacement (with previous or next block being "-")
      blocks.append(MergeBlock(MergeBlockType.INSERT, [line for line in tmp], line = no - offset - len(tmp)))
      if len(blocks) >= 2 and blocks[-2].tipe == MergeBlockType.REMOVE:  #  and len(blocks[-1].lines) == len(blocks[-2].lines):  # requires previous block and same number of lines TODO allow multiple intra-line merge for same-length blocks
        offset += len(blocks[-1].lines)
        blocks[-2] = dataCopy(MergeBlock, blocks[-2], tipe = MergeBlockType.REPLACE, replaces = dataCopy(MergeBlock, blocks[-1], line = blocks[-2].line))  # remember replaced stuff with reference to other merge block TODO why -1 necessary?
        blocks.pop()  # remove TOS due to merging two blocks into replace or modify
    elif last == "?": offset += 1  # marker for intra-line change comment HINT was earlier part of the MergeBlock
    last = line[0]  # remember for comparison once next block comes around
    tmp[:] = [line[2:]]  # only remember current line as fresh next block
  # TODO add code to detect and mark moved blocks here
  nl:bytes = othreol if eol else (curreol ?? othreol)  # no default newline, to mark "no newline"
  debug("Diff blocks: " + repr(blocks))
  if diffOnly: return (blocks, nl)

  # now perform merge operations depending on detected blocks and selected merge options
  output = []; add_all:str?; del_all:str?; selection:str = ""  # clean list of strings
  for block in blocks:
    if    block.tipe == MergeBlockType.KEEP: output.extend(block.lines)
    elif (block.tipe == MergeBlockType.INSERT and not(mergeOperation.value & MergeOperation.REMOVE.value))\
      or (block.tipe == MergeBlockType.REMOVE and    (mergeOperation.value & MergeOperation.INSERT.value)):  # will add line despite remove if --add-line was selected
      output.extend(block.lines)
    elif block.tipe == MergeBlockType.REPLACE:  # complete block replacement
      if len(block.lines) == len(block.replaces.lines) == 1:  # both sides are one-liners: apply next sub-level merge
        output.append(lineMerge(block.lines[0], block.replaces.lines[0], mergeOperation = charMergeOperation))
      elif mergeOperation == MergeOperation.ASK:  # more than one line: needs user input
#      if mergeOperation == MergeOperation.ASK:  # more than one line: needs user input
        printo(pure.ajoin("- ", block.lines, nl = "\n"))  # TODO check +/- in update mode, could be swapped
        printo(pure.ajoin("+ ", block.replaces.lines, nl = "\n"))
        while True:
          op:str = input(" Line replacement: *M[I]ne (+), [T]heirs (-), [B]oth, [U]ser input: ").strip().lower()[:1]
          if op in "tb": output.extend(block.lines)  # order for both determined here - TODO make configurable
          if op in "ib": output.extend(block.replaces.lines)
          if op == "u": user_block_input(output)
          if op in "tbiu": break  # was valid user input
      else:  # more than one line and not ask
        if   mergeOperation == MergeOperation.REMOVE: pass
        elif mergeOperation == MergeOperation.BOTH: output.extend(block.lines)
        elif mergeOperation == MergeOperation.INSERT: output.extend(list(block.replaces.lines) + list(block.lines))  # TODO optionally allow insertion BEFORE or AFTER original (order of these both lines)
    elif block.tipe in (MergeBlockType.INSERT, MergeBlockType.REMOVE) and mergeOperation == MergeOperation.ASK:  # user - interactive insert/remove section
      if (block.tipe == MergeBlockType.INSERT and add_all is None)\
      or (block.tipe == MergeOperation.REMOVE and del_all is None):  # condition for asking
        selection = user_input(pure.ajoin("+ " if block.tipe == MergeBlockType.INSERT else "- ", block.lines) + "\n  Accept? *[Y]es, [N]o, yes to [A]ll %s, n[O] to all: " % "insertions" if block.tipe == MergeBlockType.INSERT else "deletions", "ynao", "y")
        if selection in "ao":
          if block.tipe == MergeBlockType.INSERT: add_all = "y" if selection == "a" else "n"; selection = add_all
          else:                                   del_all = "y" if selection == "a" else "n"; selection = del_all  # REMOVE case
      if (block.tipe == MergeBlockType.INSERT and "y" in (add_all, selection))\
      or (                                        "n" in (del_all, selection)):  # REMOVE case
        output.extend(block.lines)
  debug("Merge output: " + "\n".join(output))
  ((nl ?? b"\n").join([line.encode(encoding) for line in output]), nl)  # returning bytes
  # TODO handle check for more/less lines in found -/+ blocks to find common section and splitting prefix/suffix out

def lineMerge(othr:str, into:str, mergeOperation:MergeOperation = MergeOperation.BOTH, diffOnly:bool = False) -> Union[str,List[MergeBlock]]:
  ''' Merges string 'othr' into current string 'into'.
      change direction mark is insert for elements only in into, and remove for elements only in file (according to diff marks +/-)
      returns: merged line
      raises: Exception in case of unparseable marker
  '''
  out:List[str] = list(difflib.Differ().compare(othr, into))
  blocks:List[MergeBlock] = []
  for i, charline in enumerate(out):
    if charline[0] == "+":
      if i + 1 < len(out) and out[i + 1][0] == "+":  # look-ahead: block will continue
        if i > 0 and blocks[-1].tipe == MergeBlockType.INSERT:  # middle of + block
          blocks[-1].lines.append(charline[2])  # add one more character to the accumulating list
        else:  # first + in block
          blocks.append(MergeBlock(MergeBlockType.INSERT, [charline[2]], i))
      else:  # last charline of + block
        if i > 0 and blocks[-1].tipe == MergeBlockType.INSERT:  # end of a block
          blocks[-1].lines.append(charline[2])
        else:  # single charline
          blocks.append(MergeBlock(MergeBlockType.INSERT, [charline[2]], i))
        if i >= 1 and blocks[-2].tipe == MergeBlockType.REMOVE:  # previous - and now last in + block creates a replacement block
          blocks[-2] = MergeBlock(MergeBlockType.REPLACE, blocks[-2].lines, i, replaces = blocks[-1]); blocks.pop()
    elif charline[0] == "-":
      if i > 0 and blocks[-1].tipe == MergeBlockType.REMOVE:  # part of - block
        blocks[-1].lines.append(charline[2])
      else:  # first in block
        blocks.append(MergeBlock(MergeBlockType.REMOVE, [charline[2]], i))
    elif charline[0] == " ":  # keep area
      if i > 0 and blocks[-1].tipe == MergeBlockType.KEEP:  # part of block
        blocks[-1].lines.append(charline[2])
      else:  # first in block
        blocks.append(MergeBlock(MergeBlockType.KEEP, [charline[2]], i))
    else: raise Exception("Cannot parse diff charline %r" % charline)
  blocks[:] = [dataCopy(MergeBlock, block, lines = ["".join(block.lines)], replaces = dataCopy(MergeBlock, block.replaces, lines = ["".join(block.replaces.lines)]) if block.replaces else None) for block in blocks]  # update blocks
  if diffOnly: return blocks  # debug interrupt - only return blocks

  out = []
  for i, block in enumerate(blocks):
    if   block.tipe == MergeBlockType.KEEP: out.extend(block.lines)
    elif block.tipe == MergeBlockType.REPLACE:
      if mergeOperation == MergeOperation.ASK:  # TODO add loop here like in merge
        printo(pure.ajoin("- ", othr))
        printo("- " + (" " * i) + block.replaces.lines[0])
        printo("+ " + (" " * i) + block.lines[0])
        printo(pure.ajoin("+ ", into))
        op:str = user_input(" Character replacement: *M[I]ne (+), [T]heirs (-), [B]oth, [U]ser input: ", "tbim")
        if op in "tb": out.extend(block.lines); break
        if op in "ib": out.extend(block.replaces.lines); break
        if op == "m":  user_block_input(out); break
      else:  # non-interactive
        if   mergeOperation == MergeOperation.REMOVE: pass  # neither keep old nor insert new
        elif mergeOperation == MergeOperation.BOTH: out.extend(block.lines)  # remove old and insert new
        elif mergeOperation == MergeOperation.INSERT: out.extend(block.replaces.lines + block.lines)  # keep old an insert new
    elif block.tipe == MergeBlockType.INSERT and not (mergeOperation.value & MergeOperation.REMOVE.value): out.extend(block.lines)
    elif block.tipe == MergeBlockType.REMOVE and      mergeOperation.value & MergeOperation.INSERT.value:  out.extend(block.lines)
    # TODO ask for insert or remove as well
  return "".join(out)

def findSosVcsBase() -> Tuple[str?,str?,str?] =
  ''' Attempts to find sos and legacy VCS base folders.
      Returns (SOS-repo root, VCS-repo root, VCS command)
  '''
  debug("Detecting root folders...")
  path:str = os.getcwd()  # start in current folder, check parent until found or stopped
  vcs:Tuple[str?,str?] = (None, None)
  while not os.path.exists(encode(os.path.join(path, metaFolder))):
    contents:Set[str] = set(os.listdir(path))
    vcss:str[] = [executable for folder, executable in vcsFolders.items() if folder in contents or (SLASH in folder and os.path.exists(os.path.join(os.getcwd(), folder.replace(SLASH, os.sep))))]  # determine VCS type from existence of dot folder TODO use encode?
    choice:str? = None
    if len(vcss) > 1:
      choice = SVN if SVN in vcss else vcss[0]  # SVN is preferred
      warn("Detected more than one parallel VCS checkouts %r. Falling back to '%s'" % (vcss, choice))
    elif len(vcss) > 0: choice = vcss[0]
    if not vcs[0] and choice: vcs = (path, choice)  # memorize current repo root
    new = os.path.dirname(path)  # get parent path
    if new == path: break  # avoid infinite loop
    path = new
  if os.path.exists(encode(os.path.join(path, metaFolder))):  # found something
    if vcs[0]: return (path, vcs[0], vcs[1])  # already detected vcs base and command
    sos = path
    while True:  # continue search for VCS base
      contents = set(os.listdir(path))
      vcss = [executable for folder, executable in vcsFolders.items() if folder in contents]  # determine VCS type
      choice = None
      if len(vcss) > 1:
        choice = SVN if SVN in vcss else vcss[0]
        warn("Detected more than one parallel VCS checkouts %r. Falling back to '%s'" % (vcss, choice))
      elif len(vcss) > 0: choice = vcss[0]
      if choice: return (sos, path, choice)
      new = os.path.dirname(path)  # get parent path
      if new == path: return (sos, None, None)  # no VCS folder found
      path = new
  (None, vcs[0], vcs[1])

def tokenizeGlobPattern(pattern:str) -> List[GlobBlock] =
  index:int = 0
  out:List[GlobBlock] = []  # literal = True, first index
  while index < len(pattern):
    if pattern[index:index + 3] in ("[?]", "[*]", "[[]", "[]]"): out.append(GlobBlock(False, pattern[index:index + 3], index)); continue
    if pattern[index] in "*?":
      count:int = 1
      while index + count < len(pattern) and pattern[index] == "?" and pattern[index + count] == "?": count += 1
      out.append(GlobBlock(False, pattern[index:index + count], index)); index += count; continue
    if pattern[index:index + 2] == "[!": out.append(GlobBlock(False, pattern[index:pattern.index("]", index + 2) + 1], index)); index += len(out[-1][1]); continue
    count = 1
    while index + count < len(pattern) and pattern[index + count] not in "*?[": count += 1
    out.append(GlobBlock(True, pattern[index:index + count], index)); index += count
  out

def tokenizeGlobPatterns(oldPattern:str, newPattern:str) -> Tuple[GlobBlock[], GlobBlock[]] =
  ot:List[GlobBlock] = tokenizeGlobPattern(oldPattern)
  nt:List[GlobBlock] = tokenizeGlobPattern(newPattern)
#  if len(ot) != len(nt): Exit("Source and target patterns can't be translated due to differing number of parsed glob markers and literal strings")
  if len([o for o in ot if not o.isLiteral]) < len([n for n in nt if not n.isLiteral]): Exit("Source and target file patterns contain differing number of glob markers and can't be translated")
  if any(O.content != N.content for O, N in zip([o for o in ot if not o.isLiteral], [n for n in nt if not n.isLiteral])): Exit("Source and target file patterns differ in semantics")
  (ot, nt)

def convertGlobFiles(filenames:str[], oldPattern:GlobBlock[], newPattern:GlobBlock[]) -> Tuple[str,str][] =
  ''' Converts given filename according to specified file patterns. No support for adjacent glob markers currently. '''
  pairs:List[Tuple[str,str]] = []
  for filename in filenames:
    literals:List[GlobBlock] = [l for l in oldPattern if l.isLiteral]  # source literals
    nextliteral:int = 0; index:int = 0
    parsedOld:List[GlobBlock2] = []
    for part in oldPattern:  # match everything in the old filename
      if part.isLiteral: parsedOld.append(GlobBlock2(True, part.content, part.content)); index += len(part.content); nextliteral += 1
      elif part.content.startswith("?"): parsedOld.append(GlobBlock2(False, part.content, filename[index:index + len(part.content)])); index += len(part.content)
      elif part.content.startswith("["): parsedOld.append(GlobBlock2(False, part.content, filename[index])); index += 1
      elif part.content == "*":
        if nextliteral >= len(literals): parsedOld.append(GlobBlock2(False, part.content, filename[index:])); break
        nxt:int = filename.index(literals[nextliteral].content, index)  # also matches empty string
        parsedOld.append(GlobBlock2(False, part.content, filename[index:nxt])); index = nxt
      else: Exit("Invalid file pattern specified for move/rename")
    globs:List[GlobBlock2] = [g for g in parsedOld if not g.isLiteral]
    literals = [l for l in newPattern if l.isLiteral]  # target literals
    nextliteral = 0; nextglob:int = 0
    outname:List[str] = []
    for part in newPattern:  # generate new filename
      if part.isLiteral: outname.append(literals[nextliteral].content); nextliteral += 1
      else: outname.append(globs[nextglob].matches); nextglob += 1
    pairs.append((filename, "".join(outname)))
  pairs

def reorderRenameActions(actions:Tuple[str,str][], exitOnConflict:bool = True) -> Tuple[str,str][] =
  ''' Attempt to put all rename actions into an order that avoids target == source names.
      Note, that it's currently not really possible to specify patterns that make this work (swapping "*" elements with a reference).
      An alternative would be to always have one (or all) files renamed to a temporary name before renaming to target filename.
  '''
  if not actions: return []
  sources:List[str]; targets:List[str]
  sources, targets = [list(l) for l in zip(*actions)]
  last:int = len(actions)
  while last > 1:
    clean:bool = True
    for i in range(1, last):
      try:
        index:int = targets[:i].index(sources[i])
        sources.insert(index, sources.pop(i))  # bubble up the action right before conflict
        targets.insert(index, targets.pop(i))
        clean = False
      except: continue  # target not found in sources: good!
    if clean: break
    last -= 1  # we know that the last entry in the list has the least conflicts, so we can disregard it in the next iteration
  if exitOnConflict: for i in range(1, len(actions)): if sources[i] in targets[:i]: Exit("There is no order of renaming actions that avoids copying over not-yet renamed files: '%s' is contained in matching source filenames" % (targets[i]))
  list(zip(sources, targets))  # convert to list to avoid generators

def relativize(root:str, filepath:str) -> Tuple[str,str] =
  ''' Determine OS-independent relative folder path, and relative pattern path. Always expects a file and determines its folder's relative path. '''
  relpath = os.path.relpath(os.path.dirname(os.path.abspath(filepath)), root).replace(os.sep, SLASH)
  relpath, os.path.join(relpath, os.path.basename(filepath)).replace(os.sep, SLASH)

def parseArgumentOptions(cwd:str, options:List[str]) -> Tuple[FrozenSet[str]?, FrozenSet[str]?, List[str], List[str]] =
  ''' Returns (root-normalized) Tuple with set of [f{--only], f{--except}, [remotes], [noremotes]] arguments. '''
  root:str = os.getcwd()
  onlys:List[str] = []; excps:List[str] = []; remotes:List[str] = []; noremotes:List[str] = []
  for keys, container in [(("--only", "--include"), onlys), (("--except", "--exclude"), excps), (("--remote", "--remotes", "--only-remote", "--only-remotes", "--include-remote", "--include-remotes"), remotes), (("--except-remote", "--except-remotes", "--exclude-remote", "--exclude-remotes"), noremotes)]:
    founds = [i for i in range(len(options)) if any([options[i].startswith(key + "=") or options[i] == key for key in keys])]  # assuming no more than one = in the string
    for i in reversed(founds):
      if "=" in options[i]:
        container.extend(safeSplit(options[i].split("=")[1], ";"))  # TODO keep semicolon or use comma?
      elif i + 1 < len(options):  # in case last --only has no argument
        container.extend(safeSplit(options[i + 1], ";"))  # TODO test this
        del options[i + 1]
      del options[i]  # reverse removal
  ( frozenset(oo for oo in (relativize(root, os.path.normpath(os.path.join(cwd, o)))[1] for o in onlys) if not oo.startswith(PARENT + SLASH)) if onlys else None,
    frozenset(ee for ee in (relativize(root, os.path.normpath(os.path.join(cwd, e)))[1] for e in excps) if not ee.startswith(PARENT + SLASH)) if excps else None,  # avoids out-of-repo paths
    [os.path.abspath(os.path.normpath(_)) for _ in remotes],
    [os.path.abspath(os.path.normpath(_)) for _ in noremotes])
