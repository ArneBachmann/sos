# Copyright (c) 2017-2018  Arne Bachmann
# This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/.

# Standard modules
import codecs, fnmatch, json, logging, mimetypes, os, sys  # only essential modules
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))  # TODO #243 this looks just wrong, but is currently required (check again, why)
try:  # try needed as paths differ when installed via pip TODO #243 investigate further
  import sos.usage as usage
  import sos.version as version
  import sos.utility as _utility  # WARN necessary because "tests" can only mock "sos.utility.input", because "sos" does "import *" from "utility" and "sos.input" cannot be mocked for some reason
  from sos.utility import *
  from sos.pure import *
except:
  import usage
  import version
  import utility as _utility
  from utility import *
  from pure import *

# Dependencies
try: import configr
except: pass  # TODO this is here to avoid import error when setup.py is called but actually needs to install its dependencies first. enhance this


# Lazy module auto-import for quick tool startup
class shutil: def __getattribute__(_, key):
  global shutil
  import shutil  # overrides global reference
  return shutil.__getattribute__(key)
shutil = shutil()


# Functions
def loadConfig() -> configr.Configr =
  ''' Simplifies loading user-global config from file system or returning application defaults. '''
  config:configr.Configr = configr.Configr(usage.COMMAND, defaults = defaults)  # defaults are used if key is not configured, but won't be saved
  f, g = config.loadSettings(clientCodeLocation = os.path.abspath(__file__), location = os.environ.get("TEST", None))  # required for testing only
  if f is None: debug("Encountered a problem while loading the user configuration: %r" % g)
  config

def saveConfig(config:configr.Configr) -> Tuple[str?, Exception?] =
  config.saveSettings(clientCodeLocation = os.path.abspath(__file__), location = os.environ.get("TEST", None))  # saves global config, not local one


# Main data class
class Metadata:
  ''' This class doesn't represent the entire repository state in memory,
      but serves as a container for different repo operations,
      using only parts of its attributes at any point in time. Use with care.
  '''

  singleton:configr.Configr? = None

  def __init__(_, path:str? = None, offline:bool = False, remotes:List[str] = []) -> None:
    ''' Create empty container object for various repository operations, and import configuration. Offline initializes a repository. '''
    _.root:str = path ?? os.getcwd()
    _.tags:List[str] = []  # list of known (unique) tags
    _.branch:int? = None  # current branch number
    _.branches:Dict[int,BranchInfo] = {}  # branch number zero represents the initial state at branching
    _.repoConf:Dict[str,Any] = {}  # per-repo configuration items
    _.track:bool; _.picky:bool; _.strict:bool; _.compress:bool; _.version:str?; _.format:int?
    _.remotes:List[str] = []  # list of secondary storage locations (in same file system, no other protocols), which will replicate all write operations
    _.loadBranches(offline = offline, remotes = remotes)  # loads above values from repository, or uses application defaults

    _.commits:Dict[int,CommitInfo] = {}  # consecutive numbers per branch, starting at 0
    _.paths:Dict[str,PathInfo] = {}  # utf-8 encoded relative, normalized file system paths
    _.commit:int? = None  # current revision number

    if Metadata.singleton is None:  # load configuration lazily only once per runtime
      Metadata.singleton = configr.Configr(data = _.repoConf, defaults = loadConfig())  # load global configuration backed by defaults, as fallback behind the local configuration
      if "useColorOutput" in Metadata.singleton: enableColor(Metadata.singleton.useColorOutput)  # otherwise keep default
    _.c:configr.Configr = Metadata.singleton

  def isTextType(_, filename:str) -> bool = ((mimetypes.guess_type(filename)[0] ?? "").startswith("text/") or any([fnmatch.fnmatch(filename, pattern) for pattern in _.c.texttype])) and not any([fnmatch.fnmatch(filename, pattern) for pattern in _.c.bintype])

  def correctNegativeIndexing(_, revision:int) -> int =
    ''' As the na_e says, this deter_ines the correct positive revision nu_ber for negative indexing (-1 being last, -2 being second last). '''
    revision = revision if revision >= 0 else (max(_.commits) if _.commits else (_.getHighestRevision(_.branch) ?? -1)) + 1 + revision  # negative indexing
    if revision < 0 or (_.commits and revision > max(_.commits)): Exit("Unknown revision r%02d" % revision)
    revision

  def listChanges(_, changed:ChangeSet, commitTime:float? = None, root:str? = None):
    ''' List changes. If commitTime (in ms) is defined, also check timestamps of modified files for plausibility (if mtime of new file is <= / older than in last commit, note so).
        commitTimne == None in switch and log
        root: current user's working dir to compute relative paths (cwd is usually repository root), otherwise None (repo-relative)
    '''
    relp:(str, str) -> str = (path, root) -> os.path.relpath(path, root).replace(SLASH, os.sep) if root else path  # using relative paths if root is not None, otherwise SOS repo normalized paths
    moves:Dict[str,PathInfo] = dict(changed.moves.values())  # of origin-pathinfo
    realadditions:Dict[str,PathInfo] = {k: v for k, v in changed.additions.items() if k not in changed.moves}  # targets
    realdeletions:Dict[str,PathInfo] = {k: v for k, v in changed.deletions.items() if k not in moves}          # sources
    if len(changed.moves)         > 0: printo(ajoin("MOV ", ["%s  <-  %s" % (relp(path, root), relp(dpath, root)) for path, (dpath, dinfo) in sorted(changed.moves.items())], "\n") + Style.RESET_ALL, color = Fore.BLUE + Style.BRIGHT)
    if len(        realadditions) > 0: printo(ajoin("ADD ", sorted(         ["%s  (%s)" % (relp(p, root), pure.siSize(pinfo.size) if pinfo is not None else "-") for p, pinfo in realadditions.items()]), "\n"), color = Fore.GREEN)
    if len(        realdeletions) > 0: printo(ajoin("DEL ", sorted(         [relp(p, root) for p in realdeletions.keys()]), "\n"), color = Fore.RED)
    if len(changed.modifications) > 0: printo(ajoin("MOD ", [relp(m, root) + (" <binary>" if not _.isTextType(os.path.basename(m)) else "") + ("" if commitTime is None else (" <older than previously committed>" if pi.mtime < _.paths[m].mtime else "")) + ((" [%s%s %s%s]" % (pure.signedNumber(pi.size - _.paths[m].size), siSize(pi.size - _.paths[m].size), pure.signedNumber(pi.mtime - _.paths[m].mtime), pure.timeString(pi.mtime - _.paths[m].mtime)) if verbose else "") if pi is not None else "") for (m, pi) in sorted(changed.modifications.items())], "\n"), color = Fore.YELLOW)

  def loadBranches(_, offline:bool = False, remotes:List[str] = []):
    ''' Load list of branches and current branch info from metadata file. offline = True command avoids message. '''
    try:  # fails if not yet created (on initial branch/commit)
#      branches:List[List]  # deserialized JSON is only list, while the real type of _.branches is a dict number -> BranchInfo (Coconut data type/named tuple)
      with codecs.open(encode(os.path.join(_.root, metaFolder, metaFile)), "r", encoding = UTF8) as fd:
        repo, branches, config = json.load(fd)
      _.tags = repo["tags"]  # list of commit messages to treat as globally unique tags
      _.branch = repo["branch"]  # current branch integer
      _.track, _.picky, _.strict, _.compress, _.version, _.format, _.remotes, remote = [repo.get(r, None) for r in ["track", "picky", "strict", "compress", "version", "format", "remotes", "remote"]]
      if remote: Exit("Cannot access remote SOS repository for local operation. You're attempting to access a backup copy. Consult manual to restore this backup for normal operation")
      upgraded:List[str] = []
      if _.version is None:
        _.version = "0 - pre-1.2"
        upgraded.append("pre-1.2")
      if len(branches[0]) < 6:  # For older versions, see https://pypi.python.org/simple/sos-vcs/
        branches[:] = [branch + [[]] * (6 - len(branch)) for branch in branches]  # add untracking information, if missing
        upgraded.append("2018.1210.3028")
      if _.format is None:  # must be before 1.3.5+
        _.format = 1  # marker for first metadata file format
        branches[:] = [branch + [None] * (8 - len(branch)) for branch in branches]  # adds empty branching point information (branch/revision)
        upgraded.append("1.3.5")
      _.branches = {i.number: i for i in (BranchInfo(*item) for item in branches)}  # re-create type info
      _.repoConf = config  # local configuration stored with repository, not in user-wide configuration
      if _.format == 1 or _.remotes is None:  # before remotes
        _.format = METADATA_FORMAT
        _.remotes = []  # default is no remotes
        upgraded.append("1.7.0")  # remote URLs introduced
      if upgraded:
        for upgrade in upgraded: printo("WARNING  Upgraded repository metadata to match SOS version %r" % upgrade, color = Fore.YELLOW)
        warn("To revert the metadata upgrade%s, restore %s/%s from %s/%s NOW" % ("s" if len(upgraded) > 1 else "", metaFolder, metaFile, metaFolder, metaBack))
        _.saveBranches()
    except Exception as E:  # if not found, create metadata folder with default values
      _.branches = {}
      _.track, _.picky, _.strict, _.compress, _.version, _.remotes, _.format = [defaults[k] for k in ["track", "picky", "strict", "compress"]] + [version.__version__, remotes, METADATA_FORMAT]
      (debug if offline else warn)("Couldn't read branches metadata: %r" % E)  # hide warning only when going offline

  def _saveBranches(_, remote:str?, data:Dikt[str,Any]):
    tryOrIgnore(() -> shutil.copy2(encode(os.path.join(remote ?? _.root, metaFolder, metaFile)), encode(os.path.join(remote ?? _.root, metaFolder, metaBack))))  # backup
    try: with codecs.open(encode(os.path.join(remote ?? _.root, metaFolder, metaFile)), "w", encoding = UTF8) as fd:
      json.dump((data, list(_.branches.values()), _.repoConf), fd, ensure_ascii = False)  # stores using unicode codepoints (instead of ascii encoding), the file descriptor knows how to encode them
    except Exception as E: debug("Error saving branches%s" % ((" to remote path " + remote) if remote else ""))

  def saveBranches(_, also:Dict[str,Any] = {}):
    ''' Save list of branches and current branch info to metadata file. '''
    store:Dict[str,Any] = {
        "tags": _.tags, "branch": _.branch,
        "track": _.track, "picky": _.picky, "strict": _.strict, "compress": _.compress, "version": _.version, "format": METADATA_FORMAT,  # HINT uses _.version instead of constant to allow the upgrade procedure to write a specific version
        "remotes": _.remotes,
        "remote": False
      }  # dictionary of repository settings (while _.repoConf stores user settings)
    store.update(also)  # allows overriding certain values at certain points in time
    for remote in [None] + _.remotes:
      _._saveBranches(remote, store); store["remote"] = True  # mark remote copies as read-only

  def getRevisionByName(_, name:str) -> int? =
    ''' Convenience accessor for named revisions (using commit message as tag name by convention). '''
    if name == "": return -1
    try: return int(name)  # attempt to parse integer string
    except ValueError: pass
    found = [number for number, commit in _.commits.items() if name == commit.message]  # find any revision by commit message (usually used for tags)  # HINT allows finding any message, not only tagged ones
    found[0] if found else None

  def getBranchByName(_, name:str) -> int? =
    ''' Convenience accessor for named branches. '''
    if name == "": return _.branch  # current
    try: return int(name)  # attempt to parse integer string
    except ValueError: pass
    found = [number for number, branch in _.branches.items() if name == branch.name]
    found[0] if found else None

  def loadBranch(_, branch:int):
    ''' Load all commit information from a branch meta data file. '''
    with codecs.open(encode(branchFolder(branch, file = metaFile)), "r", encoding = UTF8) as fd:
      commits:List[List[Any]] = json.load(fd)  # list of CommitInfo that needs to be unmarshalled into value types
    _.commits = {i.number: i for i in (CommitInfo(*item) for item in commits)}  # re-create type info
    _.branch = branch

  def saveBranch(_, branch:int):
    ''' Save all commits to a branch meta data file. '''
    for remote in [None] + _.remotes:
      tryOrIgnore(-> shutil.copy2(encode(branchFolder(branch, file = metaFile, base = remote)), encode(branchFolder(branch, file = metaBack, base = remote))))  # backup
      try: with codecs.open(encode(branchFolder(branch, file = metaFile, base = remote)), "w", encoding = UTF8) as fd:
        json.dump(list(_.commits.values()), fd, ensure_ascii = False)
      except Exception as E: debug("Error saving branch%s" % ((" to remote path " + remote) if remote else ""))

  def duplicateBranch(_, branch:int, name:str? = None, initialMessage:str? = None, full:bool = True):
    ''' Create branch from an existing branch/revision.
        In case of full branching, copy all revisions, otherwise create only reference to originating branch/revision.
        branch: new target branch number (must not exist yet)
        name: optional name of new branch (currently always set by caller)
        initialMessage: message for commit if not last and file tree modified
        full: always create full branch copy, don't use a parent reference
        _.branch: current branch
    '''
    if verbose: info("Duplicating branch '%s' to '%s'..." % (_.branches[_.branch].name ?? ("b%d" % _.branch), (name ?? "b%d" % branch)))
    now:int = int(time.time() * 1000)
    _.loadBranch(_.branch)  # load commits for current (originating) branch
    revision:int = max(_.commits) if _.commits else 0
    _.commits.clear()
    newBranch:BranchInfo = dataCopy(BranchInfo, _.branches[_.branch],
        number = branch, ctime = now, name = name ?? "Branched from '%s'" % (_.branches[_.branch].name ?? "b%d" % _.branch),
        tracked = [t for t in _.branches[_.branch].tracked], untracked = [u for u in _.branches[_.branch].untracked],
        parent = None if full else _.branch, revision = None if full else revision
      )
    for remote in [None] + _.remotes:
      tryOrDefault(() -> os.makedirs(encode(revisionFolder(branch, 0, base = remote ?? _.root) if full else branchFolder(branch, base = remote ?? _.root))), (e) -> error("Duplicating remote branch folder %r" % remote))
    if full:  # not fast branching via reference - copy all current files to new branch
      _.computeSequentialPathSet(_.branch, revision)  # full set of files in latest revision in _.paths
      for path, pinfo in _.paths.items(): _.copyVersionedFile(_.branch, revision, branch, 0, pinfo)  # copy into initial branch revision
      _.commits[0] = CommitInfo(number = 0, ctime = now, message = initialMessage ?? "Branched from '%s'" % (_.branches[_.branch].name ?? "b%d" % _.branch))  # store initial commit
      _.saveCommit(branch, 0)  # save commit meta data to revision folder
    _.saveBranch(branch)  # save branch meta data to branch folder - for fast branching, only empty dict
    _.branches[branch] = newBranch  # save branches meta data, needs to be saved in caller code

  def createBranch(_, branch:int, name:str? = None, initialMessage:str? = None):
    ''' Create a new branch from the current file tree. This clears all known commits and modifies the file system.
        branch: target branch number (must not exist yet)
        name: optional name of new branch
        initialMessage: commit message for revision 0 of the new branch
        _.branch: current branch, must exist already
    '''
    now:int = int(time.time() * 1000)
    simpleMode = not (_.track or _.picky)
    tracked:List[str] =  [t for t in _.branches[_.branch].tracked]   if _.track and len(_.branches) > 0 else []  # in case of initial branch creation
    untracked:List[str] = [t for t in _.branches[_.branch].untracked] if _.track and len(_.branches) > 0 else []
    if verbose: info("Creating branch '%s'..." % name ?? "b%d" % branch)
    _.paths:Dict[str, PathInfo] = {}
    if simpleMode:  # branches from file system state. not necessary to create branch folder, as it is done in findChanges below anyway
      changed, msg = _.findChanges(branch, 0, progress = simpleMode)  # HINT creates revision folder and versioned files!
      _.listChanges(changed)
      if msg: printo(msg)  # display compression factor and time taken
      _.paths.update(changed.additions.items())
    else:  # tracking or picky mode: branch from latest revision
      for remote in [None] + _.remotes:
        tryOrDefault(() -> os.makedirs(encode(revisionFolder(branch, 0, base = remote ?? _.root))), (e) -> error("Creating remote branch folder %r" % remote))
      if _.branch is not None:  # not immediately after "offline" - copy files from current branch
        _.loadBranch(_.branch)
        revision:int = max(_.commits) if _.commits else 0  # TODO #245 what if last switch was to an earlier revision? no persisting of last checkout
        _.computeSequentialPathSet(_.branch, revision)  # full set of files in revision to _.paths
        for path, pinfo in _.paths.items(): _.copyVersionedFile(_.branch, revision, branch, 0, pinfo)
    _.commits = {0: CommitInfo(number = 0, ctime = now, message = initialMessage ?? "Branched on %s" % strftime(now))}  # store initial commit for new branch
    _.saveBranch(branch)  # save branch meta data (revisions) to branch folder
    _.saveCommit(branch, 0)  # save commit meta data to revision folder
    _.branches[branch] = BranchInfo(branch, _.commits[0].ctime, name, True if len(_.branches) == 0 else _.branches[_.branch].inSync, tracked, untracked)  # save branch info, in case it is needed

  def removeBranch(_, branch:int) -> BranchInfo =
    ''' Entirely remove a branch and all its revisions from the file system.
        We currently implement a simplified logic that fully re-creates all revisions for all transitively depending branches instead of only removing the one parent branch.
    '''
    import collections  # used almost only here
    binfo:BranchInfo  # typing info
    deps:List[Tuple[int,int]] = [(binfo.number, binfo.revision) for binfo in _.branches.values() if binfo.parent is not None and branch in _.getParentBranches(binfo.number, 0)]  # all transitively depending branches
    newcommits:Dict[int,Dict[int,CommitInfo]] = collections.defaultdict(dict)  # gathers commit info of re-created branches (branch -> revision -> info)
    if deps:  # need to copy all parent revisions to dependent branches first
      minrev:int = min(e[1] for e in deps)  # minimum revision ever branched from parent: up to this revision we can simply them to all dependant branches
      progress:ProgressIndicator = ProgressIndicator(PROGRESS_MARKER[1 if _.c.useUnicodeFont else 0])
      for rev in range(0, minrev + 1):  # rely on caching by copying revision-wise as long as needed into all depending branches
        for dep, _rev in deps:
          printo("\rIntegrating revision %02d into dependant branch %02d %s" % (rev, dep, progress.getIndicator()))  # TODO #246 align placement of indicator with other uses of progress
          _.loadBranch(_.getParentBranch(branch, rev))  # load commits and set _.branch (in case branch to remove was also fast-branched)
#          if rev in _.commits:  # TODO #247 uncomment? - if not, it was an empty commit? because on non-commit branches there's no revision 0?
          newcommits[dep][rev] = _.commits[rev]
          shutil.copytree(encode(revisionFolder(_.branch, rev, base = _.root)), encode(revisionFolder(dep, rev, base = _.root)))
      for dep, _rev in deps:  # copy remaining revisions by branch instead by revision
        for rev in range(minrev + 1, _rev + 1):
          printo("\rIntegrating revision %02d into dependant branch %02d %s" % (rev, dep, progress.getIndicator()))
          _.loadBranch(_.getParentBranch(dep, rev))  # WARN using dep intead of branch here!
          if rev in _.commits:  # false only if no added or modified files during fast-branch?
            newcommits[dep][rev] = _.commits[rev]
            shutil.copytree(encode(revisionFolder(_.branch, rev, base = _.root)), encode(revisionFolder(dep, rev, base = _.root)))
        _.branches[dep] = dataCopy(BranchInfo, _.branches[dep], parent = None, revision = None)  # delete fast-branching reference information
    printo(pure.ljust() + "\r")  # clean line output
    tryOrIgnore(() -> shutil.rmtree(encode(branchFolder(branch) + BACKUP_SUFFIX)))  # remove previous backup first
    tryOrIgnore(() -> os.rename(encode(branchFolder(branch)), encode(branchFolder(branch) + BACKUP_SUFFIX)), (E) -> Exit("Cannot rename branch metadata to prepare removal. Are there locked or open files?"))
    binfo = _.branches[branch]  # keep reference to removed branch info for caller
    del _.branches[branch]
    _.branch = (branch + 1) if (branch + 1) in _.branches else max(_.branches)  # switch to another valid branch
    _.saveBranches()  # persist modified branches list
    for branch, commits in newcommits.items():  # now store aggregated commit infos
      _.commits = commits
      _.saveBranch(branch)
    _.commits.clear()  # clean memory
    binfo

  def loadCommit(_, branch:int, revision:int):
    ''' Load all file information from a commit meta data; if branched from another branch before specified revision, load correct revision recursively. '''
    _branch:int = _.getParentBranch(branch, revision)
    with codecs.open(encode(revisionFolder(_branch, revision, base = _.root, file = metaFile)), "r", encoding = UTF8) as fd: _.paths = json.load(fd)
    _.paths = {path: PathInfo(*item) for path, item in _.paths.items()}  # re-create type info
    _.branch = branch  # store current branch information = "switch" to loaded branch/commit

  def saveCommit(_, branch:int, revision:int):
    ''' Save all file information to a commit meta data file. '''
    for remote in [None] + _.remotes:
      try:
        target:str = revisionFolder(branch, revision, base = remote ?? _.root)
        tryOrIgnore(-> os.makedirs(encode(target)))
        tryOrIgnore(-> shutil.copy2(encode(os.path.join(target, metaFile)), encode(os.path.join(target, metaBack))))  # ignore error for first backup
        with codecs.open(encode(os.path.join(target, metaFile)), "w", encoding = UTF8) as fd: json.dump(_.paths, fd, ensure_ascii = False)
      except Exception as E: debug("Error saving commit%s" % ((" to remote path " + remote) if remote else ""))

  def findChanges(_, branch:int? = None, revision:int? = None, checkContent:bool = False, inverse:bool = False, considerOnly:FrozenSet[str]? = None, dontConsider:FrozenSet[str]? = None, progress:bool = False) -> Tuple[ChangeSet,str?] =
    ''' Find changes on the file system vs. in-memory paths (which should reflect the latest commit state).
        Only if both branch and revision are *not* None, write modified/added files to the specified revision folder (thus creating a new revision)
        checkContent: also computes file content hashes
        inverse: retain original state (size, mtime, hash) instead of updated one
        considerOnly: set of tracking patterns. None for all (in simple mode). For update operation, consider union of other and current branch
        dontConsider: set of tracking patterns to not consider in changes (always overrides considerOnly!)
        progress: Show file names during processing
        returns: (ChangeSet = the state of file tree *differences*, unless "inverse" is True -> then return original data, message)
    '''
    import collections  # used almost only here
    write = branch is not None and revision is not None  # used for writing commits
    if write: for remote in [None] + _.remotes:
      tryOrIgnore(() -> os.makedirs(encode(revisionFolder(branch, revision, base = remote ?? _.root))))
    changed:ChangeSet = ChangeSet({}, {}, {}, {})  # WARN this code needs explicity argument passing for initialization due to mypy problems with default arguments
    indicator:ProgressIndicator? = ProgressIndicator(PROGRESS_MARKER[1 if _.c.useUnicodeFont else 0]) if progress else None  # optional file list progress indicator
    hashed:str?; written:int; compressed:int = 0; original:int = 0; start_time:float = time.time()
    knownPaths:Dict[str,List[str]] = {}

    # Find relevant folders/files that match specified folder/glob patterns for exclusive inclusion or exclusion
    byFolder:Dict[str,List[str]] =     collections.defaultdict(list)
    onlyByFolder:Dict[str,List[str]] = collections.defaultdict(list)
    dontByFolder:Dict[str,List[str]] = collections.defaultdict(list)
    for path, pinfo in _.paths.items():
      if pinfo is None: continue  # quicker than generator expression above
      slash:int = path.rindex(SLASH)
      byFolder[path[:slash]].append(path[slash + 1:])
    for pattern in considerOnly ?? []: slash = pattern.rindex(SLASH); onlyByFolder[pattern[:slash]].append(pattern[slash + 1:])
    for pattern in dontConsider ?? []: slash = pattern.rindex(SLASH); dontByFolder[pattern[:slash]].append(pattern[slash + 1:])
    for folder, paths in byFolder.items():
      pos:Set[str] = set.union(set(), *[fnmatch.filter(paths, pattern) for pattern in onlyByFolder.get(folder, [])]) if considerOnly is not None else set(paths)
      neg:Set[str] = set.union(set(), *[fnmatch.filter(paths, pattern) for pattern in dontByFolder.get(folder, [])]) if dontConsider is not None else set()
      knownPaths[folder] = list(pos - neg)

    for path, dirnames, filenames in os.walk(_.root):
      path = decode(path)
      dirnames[:] =  [decode(d) for d in dirnames]
      filenames[:] = [decode(f) for f in filenames]
      dirnames[:]  = [d for d in dirnames  if len([n for n in _.c.ignoreDirs if fnmatch.fnmatch(d, n)]) == 0 or len([p for p in _.c.ignoreDirsWhitelist if fnmatch.fnmatch(d, p)]) > 0]  # global ignores
      filenames[:] = [f for f in filenames if len([n for n in _.c.ignores    if fnmatch.fnmatch(f, n)]) == 0 or len([p for p in _.c.ignoresWhitelist    if fnmatch.fnmatch(f, p)]) > 0]
      dirnames.sort(); filenames.sort()
      relPath:str = os.path.relpath(path, _.root).replace(os.sep, SLASH)
      walk:List[str] = list(filenames if considerOnly is None else reduce((last, pattern) -> last | set(fnmatch.filter(filenames, os.path.basename(pattern))), (p for p in considerOnly if os.path.dirname(p).replace(os.sep, SLASH) == relPath), s{}))
      if dontConsider:
        walk[:] = [fn for fn in walk if not any(fnmatch.fnmatch(fn, os.path.basename(p)) for p in dontConsider if os.path.dirname(p).replace(os.sep, SLASH) == relPath)]
      for file in walk:  # if m.track or m.picky: only files that match any path-relevant tracking patterns
        filename = relPath + SLASH + file
        filepath = os.path.join(path, file)
        try: stat = os.stat(encode(filepath))
        except Exception as E: exception(E); continue
        size, mtime = stat.st_size, int(stat.st_mtime * 1000)
        show:str? = indicator.getIndicator() if progress else None
        if show:  # indication character returned
          outstring = "\r%s %s  %s" % ("Preparing" if write else "Checking", show, filename)
          printo(pure.ljust(outstring), nl = "")
        progressSymbols:str = PROGRESS_MARKER[1 if _.c.useUnicodeFont else 0]
        if filename not in _.paths:  # detected file not present (or untracked) in (other) branch
          nameHash = hashStr(filename)
          try:
            hashed, written = hashFile(filepath, _.compress, symbols = progressSymbols, saveTo = [revisionFolder(branch, revision, base = remote ?? _.root, file = nameHash) for remote in [None] + _.remotes] if write else None, callback = ((sign) -> printo(pure.ljust(outstring + " " + sign), nl = "")) if show else None) if size > 0 else (None, 0)
            changed.additions[filename] = PathInfo(nameHash, size, mtime, hashed)
            compressed += written; original += size
          except PermissionError as E: error("File permission error for %s" % filepath)
          except Exception as F: exception(F)  # HINT e.g. FileNotFoundError will not add to additions
          continue  # with next file
        last = _.paths[filename]  # filename is known - check for modifications
        if last.size is None:  # was removed before but is now added back - does not apply for tracking mode (which never marks files for removal in the history)
          try:
            hashed, written = hashFile(filepath, _.compress, symbols = progressSymbols, saveTo = [revisionFolder(branch, revision, base = remote ?? _.root, file = last.nameHash) for remote in [None] + _.remotes] if write else None, callback = None if not progress else (sign) -> printo(pure.ljust(outstring + " " + sign), nl = "")) if size > 0 else (None, 0)
            changed.additions[filename] = PathInfo(last.nameHash, size, mtime, hashed); continue
            compressed += written; original += last.size if inverse else size
          except Exception as E: exception(E)
        elif (size != last.size
            or (not checkContent and mtime != last.mtime)
            or (    checkContent and tryOrDefault(() -> (hashFile(filepath, _.compress, symbols = progressSymbols)[0] != last.hash), default = False))
        ):  # detected a modification TODO invert error = False?
          try:
            hashed, written = hashFile(filepath, _.compress, symbols = progressSymbols,
              saveTo = [revisionFolder(branch, revision, base = remote ?? _.root, file = last.nameHash) for remote in [None] + _.remotes] if write else None,
              callback = None if not progress else (sign) -> printo(pure.ljust(outstring + " " + sign), nl = "")
            ) if (last.size if inverse else size) > 0 else (last.hash if inverse else hashFile(filepath, _.compress, symbols = progressSymbols, callback = None if not progress else (sign) -> printo(pure.ljust(outstring + " " + sign), nl = ""))[0], 0)
            changed.modifications[filename] = PathInfo(last.nameHash, last.size if inverse else size, last.mtime if inverse else mtime, hashed)
            compressed += written; original += last.size if inverse else size
          except Exception as E: exception(E)
        else: continue  # with next file
      if relPath in knownPaths: knownPaths[relPath][:] = list(set(knownPaths[relPath]) - set(walk))  # at least one file is tracked HINT may leave empty lists in dict, but removing them costs more than traversing them silently
    for path, names in knownPaths.items():  # all paths that weren't walked by
      for file in names:
        if len([n for n in _.c.ignores if fnmatch.fnmatch(file, n)]) > 0 and len([p for p in _.c.ignoresWhitelist if fnmatch.fnmatch(file, p)]) == 0: continue  # don't mark ignored files as deleted
        pth:str = path + SLASH + file
        changed.deletions[pth] = _.paths[pth]
    changed = dataCopy(ChangeSet, changed, moves = detectMoves(changed, _.strict))
    if progress: printo("\r" + pure.ljust() + "\r", nl = "")  # forces clean line of progress output
    elif verbose: info("Finished detecting changes")
    tt:float = time.time() - start_time
    speed:float = (original / (KIBI * tt)) if tt > 0. else 0.  # in KiBi
    msg:str = (("Compression advantage is %.1f%%" % (original * 100. / compressed - 100.)) if _.compress and write and compressed > 0 else "")
    msg = (msg + " | " if msg else "") + ("Processing speed was %.2f %siB/s." % (speed if speed < 1500. else speed / KIBI, "k" if speed < 1500. else "M") if original > 0 and tt > 0. else "")
    (changed, msg if msg else None)

  def computeSequentialPathSet(_, branch:int, revision:int):
    ''' Returns nothing, just updates _.paths in place. '''
    next(_.computeSequentialPathSetIterator(branch, revision, incrementally = False))  # simply invoke the generator once to get full results

  def computeSequentialPathSetIterator(_, branch:int, revision:int, incrementally:bool = True, startwith:int = 0) -> Iterator[Dict[str,PathInfo]]?:
    ''' In-memory computation of current list of valid PathInfo entries for specified branch and through specified revision. '''
    try: _.loadCommit(branch, startwith)  # load initial paths
    except: yield {}; return None  # no revisions
    if incrementally: yield _.paths
    m:Metadata = Metadata(_.root); rev:int  # next changes TODO #250 avoid loading all metadata and config
    for rev in range(startwith + 1, revision + 1):
      m.loadCommit(branch, rev)
      for p, info in m.paths.items():
        if info.size == None: del _.paths[p]
        else: _.paths[p] = info
      if incrementally: yield _.paths
    yield None  # for the default case - not incrementally

  def getTrackingPatterns(_, branch:int? = None, negative:bool = False) -> FrozenSet[str] =
    ''' Returns list of tracking patterns (or untracking patterns if negative) for provided branch or current branch. '''
    f{} if not (_.track or _.picky) else frozenset(_.branches[branch ?? _.branch].untracked if negative else _.branches[branch ?? _.branch].tracked)

  def parseRevisionString(_, argument:str) -> Union[Tuple[int?,int?],NoReturn]:
    ''' Commit identifiers can be str or int for branch, and int for revision.
        Revision identifiers can be negative, with -1 being last commit.
        None is returned in case of error
        Code will sys.exit in case of unknown specified branch/revision
    '''
    if argument is None or argument == SLASH: return (_.branch, -1)  # no branch/revision specified
    if argument == "": return (None, None)  # nothing specified by user, raise error in caller
    argument = argument.strip()
    if argument.startswith(SLASH): return (_.branch, _.getRevisionByName(argument[1:]))  # current branch
    if argument.endswith(SLASH):
      try: return (_.getBranchByName(argument[:-1]), -1)
      except ValueError: Exit("Unknown branch label '%s'" % argument)
    if SLASH in argument:
      b, r = argument.split(SLASH)[:2]
      try: return (_.getBranchByName(b), _.getRevisionByName(r))
      except ValueError: Exit("Unknown branch label or wrong number format '%s/%s'" % (b, r))
    branch:int = _.getBranchByName(argument)  # returns number if given (revision) integer
    if branch not in _.branches: branch = None
    try: return (branch ?? _.branch, int(argument if argument else "-1") if branch is None else -1)  # either branch name/number or reverse/absolute revision number
    except: Exit("Unknown branch label or wrong number format")
    Exit("This should never happen. Please create an issue report")

  def findRevision(_, branch:int, revision:int, nameHash:str) -> Tuple[int,str] =
    ''' Find latest revision that contained the file physically, not returning the actual parent branch it is stored on.
        Returns (highest revision <= specified revision containing the file, file path to file on (actual parent) branch).'''
    while True:
      _branch:int = _.getParentBranch(branch, revision)
      source:str = revisionFolder(_branch, revision, base = _.root, file = nameHash)
      if os.path.exists(encode(source)) and os.path.isfile(source): break
      revision -= 1
      if revision < 0: Exit("Cannot determine versioned file '%s' from specified branch '%d'" % (nameHash, branch))
    revision, source

  def getParentBranches(_, branch:int, revision:int) -> List[int] =
    ''' Determine originating branch for a (potentially branched) revision, traversing all branch parents until found. '''
    others:List[int] = [_.branches[branch].parent]  # reference to originating parent branch, or None
    if others[0] is None or revision > _.branches[branch].revision: return [branch]  # found. need to load commit from other branch instead
    while _.branches[others[-1]].parent is not None and revision <= _.branches[others[-1]].revision: others.append(_.branches[others[-1]].parent)  # find true original branch for revision
    others

  def getParentBranch(_, branch:int, revision:int) -> int = _.getParentBranches(branch, revision)[-1]

  def getHighestRevision(_, branch:int) -> int? =
    ''' Find highest revision of a branch, even if current branch has no commits. '''
    m:Metadata = Metadata()
    other:int? = branch
    while other is not None:
      m.loadBranch(other)
      if m.commits: return max(m.commits)
      other = _.branches[branch].parent  # reference to originating parent branch, or None
    None

  def copyVersionedFile(_, branch:int, revision:int, toBranch:int, toRevision:int, pinfo:PathInfo):
    ''' Copy versioned file to other branch/revision. '''
    revision, source = _.findRevision(branch, revision, pinfo.nameHash)
    for remote in [None] + _.remotes:
      try:
        target:str = revisionFolder(toBranch, toRevision, file = pinfo.nameHash, base = remote ?? _.root)
        shutil.copy2(encode(source), encode(target))
      except Exception as E: error("Copying versioned file%s" % ((" to remote path " % remote) if remote else ""))

  def readOrCopyVersionedFile(_, branch:int, revision:int, nameHash:str, toFile:str? = None) -> bytes?:
    ''' Return file contents, or copy contents into file path provided (used in update and restorefile). '''
    source:str = _.findRevision(branch, revision, nameHash)[1]  # revisionFolder(_.getParentBranch(branch, revision), _.findRevision(branch, revision, nameHash)[0], base = _.root, file = nameHash)
    try: with openIt(source, "r", _.compress) as fd:
        if toFile is None: return fd.read()  # read bytes into memory and return
        with open(encode(toFile), "wb") as to:
          while True:
            buffer = fd.read(bufSize)
            to.write(buffer)
            if len(buffer) < bufSize: break
          return None
    except Exception as E: warn("Cannot read versioned file: %r (%d:%d:%s)" % (E, branch, revision, nameHash))
    None

  def restoreFile(_, relPath:str?, branch:int, revision:int, pinfo:PathInfo, ensurePath:bool = False) -> bytes? =
    ''' Recreate file for given revision, or return binary contents if path is None. '''
    if relPath is None: return _.readOrCopyVersionedFile(branch, revision, pinfo.nameHash) if pinfo.size > 0 else b''  # _.findRevision(branch, revision, pinfo.nameHash)[0], pinfo.nameHash) if pinfo.size > 0 else b''  # just return contents
    target:str = os.path.join(_.root, relPath.replace(SLASH, os.sep))
    if ensurePath:  #  and not os.path.exists(encode(os.path.dirname(target))):
      tryOrIgnore(-> os.makedirs(encode(os.path.dirname(target))))
    if pinfo.size == 0:
      with open(encode(target), "wb"): pass
      try: os.utime(encode(target), (pinfo.mtime / 1000., pinfo.mtime / 1000.))  # update access/modification timestamps on file system
      except Exception as E: error("Cannot update file's timestamp after restoration '%r'" % E)
      return None
    _revision, source = _.findRevision(branch, revision, pinfo.nameHash)
    # Restore file by copying buffer-wise
    with (openIt(source, "r", _.compress) as fd, open(encode(target), "wb") as to):  # using Coconut's Enhanced Parenthetical Continuation
      while True:
        buffer = fd.read(bufSize)
        to.write(buffer)
        if len(buffer) < bufSize: break
    try: os.utime(encode(target), (pinfo.mtime / 1000., pinfo.mtime / 1000.))  # update access/modification timestamps on file system
    except Exception as E: error("Cannot update file's timestamp after restoration '%r'" % E)
    None


# Main client operations
def offline(name:str? = None, initialMessage:str? = None, options:str[] = [], remotes:List[str] = []):
  ''' Initial command to start working offline. '''
  if os.path.exists(encode(metaFolder)):
    if '--force' not in options: Exit("Repository folder is either already offline or older branches and commits were left over\nUse 'sos online' to check for out-of-sync branches, or\nWipe existing offline branches with 'sos offline --force'")
    try:  # throw away all previous metadata before going offline
      for entry in os.listdir(metaFolder):  # TODO #251 why not rmtree the metadata alltogether as in "online"? I think removing .sos/ made problems on CI. test again
        resource = metaFolder + os.sep + entry
        if os.path.isdir(resource): shutil.rmtree(encode(resource))
        else: os.unlink(encode(resource))
    except: Exit("Cannot reliably remove previous repository contents. Please remove %s folder manually prior to going offline" % metaFolder)
  for remote in remotes:
    try: os.makedirs(os.path.join(remote, metaFolder))
    except Exception as E: error("Creating remote repository metadata in %s" % remote)
  m:Metadata = Metadata(offline = True, remotes = remotes)
  if '--strict'   in options or m.c.strict:   m.strict =   True   # always hash contents
  if '--compress' in options or m.c.compress: m.compress = True  # plain file copies instead of compressed ones
  if '--picky'    in options or m.c.picky:    m.picky =    True   # Git-like
  elif '--track'  in options or m.c.track:    m.track =    True   # Svn-like
  title:str? = usage.getTitle()
  if title: printo(title)
  if verbose: info(MARKER + "Going offline...")
  m.createBranch(0, name ?? defaults["defaultbranch"], initialMessage ?? "Offline repository created on %s" % strftime())  # main branch's name may be None (e.g. for fossil)
  m.branch = 0
  m.saveBranches(also = {"version": version.__version__})  # stores version info only once. no change immediately after going offline, going back online won't issue a warning
  if verbose or '--verbose' in options: info("%d file%s added to initial branch %r" % (len(m.paths), "s" if len(m.paths) > 1 else "", m.branches[m.branch].name))
  info(MARKER + "Offline repository prepared. Use 'sos online' to finish offline work")

def online(options:str[] = []):
  ''' Finish working offline. '''
  if verbose: info(MARKER + "Going back online...")
  force:bool = '--force' in options
  m:Metadata = Metadata()
  strict:bool = '--strict' in options or m.strict
  m.loadBranches()
  if any([not b.inSync for b in m.branches.values()]) and not force: Exit("There are still unsynchronized (modified) branches\nUse 'sos log' to list them.\nUse 'sos commit' and 'sos switch' to commit out-of-sync branches to your VCS before leaving offline mode.\nUse 'sos online --force' to erase all aggregated offline revisions.")
  m.loadBranch(m.branch)
  maxi:int = max(m.commits) if m.commits else m.branches[m.branch].revision  # one commit guaranteed for first offline branch, for fast-branched branches a revision in branchinfo
  if options.count("--force") < 2:
    m.computeSequentialPathSet(m.branch, maxi)  # load all commits up to specified revision
    changed, msg = m.findChanges(
      checkContent = strict,
      considerOnly = None if not (m.track or m.picky) else m.getTrackingPatterns(),
      dontConsider = None if not (m.track or m.picky) else m.getTrackingPatterns(negative = True),
      progress = '--progress' in options)  # HINT no option for --only/--except here on purpose. No check for picky here, because online is not a command that considers staged files (but we could use --only here, alternatively)
    if modified(changed): Exit("File tree is modified vs. current branch\nUse 'sos online --force --force' to continue with removing the offline repository")
  try: shutil.rmtree(encode(metaFolder)); info("Exited offline mode. Continue working with your traditional VCS.")
  except Exception as E: Exit("Error removing offline repository: %r" % E)
  info(MARKER + "Offline repository removed, you're back online")

def branch(name:str? = None, initialMessage:str? = None, options:str[] = []):
  ''' Create a new branch (from file tree or last revision) and (by default) continue working on it.
      Force not required here, as either branching from last revision anyway, or branching full file tree anyway.
  '''
  last:bool = '--last' in options  # use last revision for branching, not current file tree
  stay:bool = '--stay' in options  # continue on current branch after branching (don't switch)
  fast:bool = '--fast' in options  # branch by referencing TODO #252 move to default and use --full instead for old behavior
  m:Metadata = Metadata()
  m.loadBranch(m.branch)
  maxi:int = max(m.commits) if m.commits else m.branches[m.branch].revision
  if name and m.getBranchByName(name) is not None: Exit("Branch '%s' already exists. Cannot proceed" % name)  # attempted to create a named branch
  branch = max(m.branches.keys()) + 1  # next branch's key - this isn't atomic but we assume single-user non-concurrent use here
  if verbose: info(MARKER + "Branching to %sbranch b%d%s%s..." % ("unnamed " if name is None else "", branch, " '%s'" % name if name is not None else "", " from last revision" if last else ""))
  if last: m.duplicateBranch(branch, name, (initialMessage + " " if initialMessage else "") + "(Branched from b%d/r%02d)" % (m.branch, maxi), not fast)  # branch from last revision
  else: m.createBranch(branch, name, initialMessage ?? "Branched from file tree after b%d/r%02d" % (m.branch, maxi))  # branch from current file tree state
  if not stay: m.branch = branch
  m.saveBranches()  # TODO #253 or indent again?
  info(MARKER + "%s new %sbranch b%d%s" % ("Continue work after branching" if stay else "Switched to", "unnamed " if name is None else "", branch, " '%s'" % name if name else ""))

def changes(argument:str? = None, options:str[] = [], onlys:FrozenSet[str]? = None, excps:FrozenSet[str]? = None, cwd:str? = None) -> ChangeSet =
  ''' Show changes of file tree vs. (last or specified) revision on current or specified branch. '''
  m:Metadata = Metadata(); branch:int?; revision:int?
  strict:bool = '--strict' in options or m.strict
  branch, revision = m.parseRevisionString(argument)
  if branch is None or branch not in m.branches: Exit("Unknown branch")
  m.loadBranch(branch)  # knows commits
  revision = m.correctNegativeIndexing(revision)  # m.branches[branch].revision if not m.commits else (revision if revision >= 0 else max(m.commits) + 1 + revision)  # negative indexing
  if verbose: info(MARKER + "Changes of file tree vs. revision '%s/r%02d'" % (m.branches[branch].name ?? "b%d" % branch, revision))
  m.computeSequentialPathSet(branch, revision)  # load all commits up to specified revision
  changed, msg = m.findChanges(
    checkContent = strict,
    considerOnly = onlys if not (m.track or m.picky) else pure.conditionalIntersection(onlys, m.getTrackingPatterns() | m.getTrackingPatterns(branch)),
    dontConsider = excps if not (m.track or m.picky) else excps ?? (m.getTrackingPatterns(negative = True) | m.getTrackingPatterns(branch, negative = True)),
    progress = '--progress' in options)
  m.listChanges(changed, commitTime = m.commits[max(m.commits)].ctime if m.commits else time.time(), root = os.path.abspath(cwd) if '--relative' in options else None)
  changed  # returning for unit tests only TODO #254 remove?

def _diff(m:Metadata, branch:int, revision:int, changed:ChangeSet, ignoreWhitespace:bool, textWrap:bool = False, classic:bool = False):  # TODO #255 introduce option to diff against committed revision and not only file tree
  ''' The diff display code. '''
  number_:int? = tryOrDefault(-> max(1, int(sys.argv[sys.argv.index("-n") + 1])), m.c.logLines)  # WARN only works because we don't pick a positional argument in parse
  wrap:(str) -> str = ((s) -> s) if textWrap else ((s) -> s[:termWidth])  # HINT since we don't know the actual width of unicode strings, we cannot be sure this is really maximizing horizontal space (like ljust), but probably not worth iteratively finding the right size
  onlyBinaryModifications:ChangeSet = dataCopy(ChangeSet, changed, modifications = {k: v for k, v in changed.modifications.items() if not m.isTextType(os.path.basename(k))})
  m.listChanges(onlyBinaryModifications, commitTime = m.commits[max(m.commits)].ctime)  # only list modified binary files
  for path, pinfo in (c for c in changed.modifications.items() if m.isTextType(os.path.basename(c[0]))):  # only consider modified text files
    content:bytes? = b""  # stored state (old = "curr")
    if pinfo.size != 0: content = m.restoreFile(None, branch, revision, pinfo); assert content is not None  # versioned file
    abspath:str = os.path.normpath(os.path.join(m.root, path.replace(SLASH, os.sep)))  # current state (new = "into")
    if classic: mergeClassic(content, abspath, "b%d/r%02d" % (branch, revision), os.path.basename(abspath), pinfo.mtime, number_); continue
    blocks:List[MergeBlock]; nl:bytes
    blocks, nl = merge(filename = abspath, into = content, diffOnly = True, ignoreWhitespace = ignoreWhitespace)  # only determine change blocks
    printo("DIF %s%s  %s" % (path, " <timestamp or newline>" if len(blocks) == 1 and blocks[0].tipe == MergeBlockType.KEEP else "", NL_NAMES[nl]))
    linemax:int = pure.requiredDecimalDigits(max([block.line for block in blocks]) if len(blocks) > 0 else 1)
    for block in blocks:
#      if block.tipe in [MergeBlockType.INSERT, MergeBlockType.REMOVE]:
#        pass  # TODO print some of previous and following lines - which aren't accessible here anymore
      if block.tipe == MergeBlockType.INSERT:
        for no, line in enumerate(block.lines):          printo(wrap("--- %%0%dd |%%s|" % linemax % (no + block.line, line)), color = Fore.RED)  # SVN diff uses --,++-+- only
      elif block.tipe == MergeBlockType.REMOVE:
        for no, line in enumerate(block.lines):          printo(wrap("+++ %%0%dd |%%s|" % linemax % (no + block.line, line)), color = Fore.GREEN)
      elif block.tipe == MergeBlockType.REPLACE:
        for no, line in enumerate(block.replaces.lines): printo(wrap("old %%0%dd |%%s|" % linemax % (no + block.replaces.line, line)), color = Fore.MAGENTA)
        for no, line in enumerate(block.lines):          printo(wrap("now %%0%dd |%%s|" % linemax % (no + block.line, line)), color = Fore.CYAN)
#      elif block.tipe == MergeBlockType.KEEP: pass  # TODO #257 allow to show kept stuff, or a part of pre-post lines
#      elif block.tipe == MergeBlockType.MOVE:  # intra-line modifications
      if block.tipe != MergeBlockType.KEEP: printo()

def diff(argument:str, options:str[] = [], onlys:FrozenSet[str]? = None, excps:FrozenSet[str]? = None):
  ''' Show text file differences of file tree vs. (last or specified) revision on current or specified branch. '''
  m:Metadata = Metadata(); branch:int?; revision:int?
  strict:bool = '--strict' in options or m.strict
  ignoreWhitespace:bool = '--ignore-whitespace' in options or '--iw' in options
  wrap:bool = '--wrap' in options  # allow text to wrap around
  branch, revision = m.parseRevisionString(argument)  # if nothing given, use last commit
  if branch is None or branch not in m.branches: Exit("Unknown branch")
  m.loadBranch(branch)  # knows commits
  revision = m.correctNegativeIndexing(revision)  #  m.branches[branch].revision if not m.commits else (revision if revision >= 0 else max(m.commits) + 1 + revision)  # negative indexing
  if verbose: info(MARKER + "Textual differences of file tree vs. revision '%s/r%02d'" % (m.branches[branch].name ?? "b%d" % branch, revision))
  m.computeSequentialPathSet(branch, revision)  # load all commits up to specified revision
  changed, msg = m.findChanges(
    checkContent = strict, inverse = True,
    considerOnly = onlys if not (m.track or m.picky) else pure.conditionalIntersection(onlys, m.getTrackingPatterns() | m.getTrackingPatterns(branch)),
    dontConsider = excps if not (m.track or m.picky) else excps ?? (m.getTrackingPatterns(negative = True)            | m.getTrackingPatterns(branch, negative = True)),
    progress = '--progress' in options)
  _diff(m, branch, revision, changed, ignoreWhitespace = ignoreWhitespace, textWrap = wrap, classic = '--classic' in options)

def commit(argument:str? = None, options:str[] = [], onlys:FrozenSet[str]? = None, excps:FrozenSet[str]? = None):
  ''' Create new revision from file tree changes vs. last commit. '''
  m:Metadata = Metadata()
  if argument is not None and argument in m.tags: Exit("Illegal commit message. It was already used as a (unique) tag name and cannot be reused")
  trackingPatterns:FrozenSet[str] = m.getTrackingPatterns()  # SVN-like mode
  # No untracking patterns needed here
  if m.picky and not trackingPatterns: Exit("No file patterns staged for commit in picky mode")
  if verbose: info(MARKER + "Committing changes to branch '%s'..." % m.branches[m.branch].name ?? "b%d" % m.branch)
  m, branch, revision, changed, strict, force, trackingPatterns, untrackingPatterns = exitOnChanges(None, options, check = False, commit = True, onlys = onlys, excps = excps)  # special flag creates new revision for detected changes, but aborts if no changes
  changed = dataCopy(ChangeSet, changed, moves = detectMoves(changed, strict))
  m.paths = {k: v for k, v in changed.additions.items()}  # copy to avoid wrong file numbers report below
  m.paths.update(changed.modifications)  # update pathset to changeset only
  m.paths.update <| {k: dataCopy(PathInfo, v, size = None, hash = None) for k, v in changed.deletions.items()}
  m.saveCommit(m.branch, revision)  # revision has already been incremented
  m.commits[revision] = CommitInfo(number = revision, ctime = int(time.time() * 1000), message = argument)  # comment can be None
  m.saveBranch(m.branch)
  m.loadBranches()  # TODO #258 is it necessary to load again?
  if m.picky: m.branches[m.branch] = dataCopy(BranchInfo, m.branches[m.branch], tracked = [], inSync = False)  # remove tracked patterns
  else: m.branches[m.branch] = dataCopy(BranchInfo, m.branches[m.branch], inSync = False)  # track or simple mode: set branch modified
  if "--tag" in options and argument is not None: m.tags.append(argument); info("Version was tagged with %s" % argument)  # memorize unique tag
  m.saveBranches()
  stored:int = 0; overhead:int = 0; count:int = 0  # now determine new commit size on file system
  commitFolder:str = revisionFolder(m.branch, revision)
  for file in os.listdir(commitFolder):
    try:
      newsize:int = os.stat(encode(os.path.join(commitFolder, file))).st_size
      if file == metaFile: overhead += newsize
      else: stored += newsize; count += 1
    except Exception as E: error(E)
  printo(MARKER_COLOR + "Created new revision r%02d%s (%s+%s%02d/%s-%s%02d/%s%s%s%02d/%s%s%s%02d) summing %s in %d files (%.2f%% SOS overhead)" % (
      revision,
      (" '%s'" % argument) if argument is not None else "",
      Fore.GREEN, Fore.RESET, len(changed.additions) - len(changed.moves),
      Fore.RED, Fore.RESET, len(changed.deletions) - len(changed.moves),
      Fore.YELLOW, PLUSMINUS_SYMBOL if m.c.useUnicodeFont else "~", Fore.RESET, len(changed.modifications),
      Fore.BLUE + Style.BRIGHT, MOVE_SYMBOL if m.c.useUnicodeFont else "#", Style.RESET_ALL, len(changed.moves),
      pure.siSize(stored + overhead),
      count,
      (overhead * 100. / (stored + overhead)) if stored + overhead > 0 else 0.
    ))

def status(argument:str? = None, vcs:str? = None, cmd:str? = None, options:str[] = [], onlys:FrozenSet[str]? = None, excps:FrozenSet[str]? = None):
  ''' Show branches and current repository state. '''
  m:Metadata = Metadata()
  if not (m.c.useChangesCommand or '--repo' in options): changes(argument, options, onlys, excps); return
  current:int = m.branch
  strict:bool = '--strict' in options or m.strict
  printo(MARKER_COLOR + "Offline repository status")
  printo("Repository root:     %s" % os.getcwd())
  printo("Underlying VCS root: %s" % vcs)
  printo("Underlying VCS type: %s" % cmd)
  printo("Installation path:   %s" % os.path.abspath(os.path.dirname(os.path.dirname(__file__))))  # because sos/sos.py
  printo("Current SOS version: %s" % version.__version__)
  printo("At creation version: %s" % m.version)
  printo("Metadata format:     %s" % m.format)
  printo("Content checking:    %s" % (Fore.CYAN + "size, then content" if m.strict else Fore.BLUE + "size & timestamp") + Fore.RESET)  # TODO size then timestamp?
  printo("Data compression:    %sactivated%s" % (Fore.CYAN if m.compress else Fore.BLUE + "de", Fore.RESET))
  printo("Repository mode:     %s%s" % (Fore.CYAN + "track" if m.track else (Fore.MAGENTA + "picky" if m.picky else Fore.GREEN + "simple"), Fore.RESET))
  printo("Number of branches:  %d" % len(m.branches))
  trackingPatterns:FrozenSet[str] = m.getTrackingPatterns()
  untrackingPatterns:FrozenSet[str] = m.getTrackingPatterns(negative = True)
  m.loadBranch(current)
  maxi:int? = max(m.commits) if m.commits else m.branches[m.branch].revision
  if maxi is not None: m.computeSequentialPathSet(current, maxi)  # load all commits up to specified revision, except no commits
  changed, _msg = m.findChanges(
    checkContent = strict,
    considerOnly = onlys if not (m.track or m.picky) else pure.conditionalIntersection(onlys, trackingPatterns),
    dontConsider = excps if not (m.track or m.picky) else excps ?? untrackingPatterns,  # HINT different logic
    progress = True)
  printo("%s File tree %s%s" % (
    Fore.YELLOW + (CROSS_SYMBOL if m.c.useUnicodeFont else "!") if modified(changed) else Fore.GREEN + (CHECKMARK_SYMBOL if m.c.useUnicodeFont else " "),
    "has changes" if modified(changed) else "is unchanged",
    Fore.RESET))  # TODO #259 bad choice of unicode symbols for changed vs. unchanged
  sl:int = max([len(b.name ?? "") for b in m.branches.values()])
  for branch in sorted(m.branches.values(), key = (b) -> b.number):
    payload:int = 0; overhead:int = 0; original:int = 0  # count used storage per branch
    for dn, ds, fs in os.walk(branchFolder(branch.number)):
      for f in fs:  # TODO #260 count all backup folders as overhead instead? check "onlydeveloped" code for that logic
        if f == metaFile or f.endswith(BACKUP_SUFFIX): overhead += tryOrDefault(-> os.stat(encode(os.path.join(dn, f))).st_size, 0)
        else: payload += tryOrDefault(-> os.stat(encode(os.path.join(dn, f))).st_size, 0)
    pl_amount:float = float(payload) / MEBI; oh_amount:float = float(overhead) / MEBI
    # if pl_amount >= 1100.:   convert to string
    m.loadBranch(branch.number)  # knows commit history
    for commit_ in range(1 + max(m.commits) if m.commits else 0):
      m.loadCommit(m.branch, commit_)
      for pinfo in m.paths.values(): original += pinfo.size ?? 0
    maxi = max(m.commits) if m.commits else m.branches[branch.number].revision
    printo("  %s b%d%s @%s (%s%s) with %d commits, using %.2f MiB (+%.3f%% SOS overhead%s)%s" % (
      "*" if current == branch.number else " ",
      branch.number,
      ((" %%%ds" % (sl + 2)) % (("'%s'" % branch.name) if branch.name else "")),
      strftime(branch.ctime),
      (Fore.GREEN + "in sync") if branch.inSync else (Fore.YELLOW + "modified"),
      Fore.RESET,
      len(m.commits),
      pl_amount + oh_amount, oh_amount * 100. / (pl_amount + oh_amount),
      ", %s compression/deduplication" % (("%.2f%s" % (float(original) / float(payload), MULT_SYMBOL if m.c.useUnicodeFont else "x")) if payload > 0 else "full") if m.compress or (len(m.commits) > 0 and len(m.commits) != max(m.commits) + 1) else "",
      (". Last comment: '%s'" % m.commits[maxi].message) if maxi in m.commits and m.commits[maxi].message else ""))
  if m.track or m.picky and (len(m.branches[m.branch].tracked) > 0 or len(m.branches[m.branch].untracked) > 0):
    printo(Fore.GREEN + "Tracked" + Fore.RESET + " file patterns:")  # TODO #261 print matching untracking patterns side-by-side?
    printo(ajoin(Fore.GREEN + "  | " + Fore.RESET, m.branches[m.branch].tracked, "\n"))
    printo(Fore.RED + "Untracked" + Fore.RESET + " file patterns:")
    printo(ajoin(Fore.RED   + "  | " + Fore.RESET, m.branches[m.branch].untracked, "\n"))

def exitOnChanges(argument:str? = None, options:str[] = [], check:bool = True, commit:bool = False, onlys:FrozenSet[str]? = None, excps:FrozenSet[str]? = None) -> Tuple[Metadata,int?,int,ChangeSet,bool,bool,FrozenSet[str],FrozenSet[str]] =
  ''' Common behavior for switch, update, delete, commit.
      Should not be called for picky mode, unless tracking patterns were already added.
      argument: optional branch/revision, used only in switch and update
      check: stop program on detected change (default yes)
      commit: don't stop on changes and write to file system
      Returns (Metadata, (current or target) branch, revision, set of changes vs. last commit on current branch, strict, force flags.
  '''
  assert not (check and commit)
  m:Metadata = Metadata()
  force:bool = '--force' in options
  strict:bool = '--strict' in options or m.strict
  if argument is not None:
    branch, revision = m.parseRevisionString(argument)  # for early abort
    if branch is None: Exit("Branch '%s' doesn't exist. Cannot proceed" % argument)
  m.loadBranch(m.branch)  # knows last commits of *current* branch
  maxi:int = max(m.commits) if m.commits else m.branches[m.branch].revision

  # Determine current changes
  trackingPatterns:FrozenSet[str] =   m.getTrackingPatterns()
  untrackingPatterns:FrozenSet[str] = m.getTrackingPatterns(negative = True)
  m.computeSequentialPathSet(m.branch, maxi)  # load all commits up to specified revision
  changed, msg = m.findChanges(
    m.branch if commit else None, maxi + 1 if commit else None, checkContent = strict,
    considerOnly = onlys if not (m.track or m.picky) else pure.conditionalIntersection(onlys, trackingPatterns),
    dontConsider = excps if not (m.track or m.picky) else excps ?? untrackingPatterns,
    progress = '--progress' in options)
  if check and modified(changed) and not force:
    m.listChanges(changed, commitTime = m.commits[max(m.commits)].ctime if m.commits else 0)
    Exit("File tree contains changes. Use --force to proceed")
  elif commit:
    if not modified(changed) and not force: Exit("Nothing to commit")
    m.listChanges(changed, commitTime = m.commits[max(m.commits)].ctime if m.commits else 0)
    if msg: printo(msg)

  if argument is not None:  # branch/revision specified
    m.loadBranch(branch)  # knows commits of target branch
    maxi = max(m.commits) if m.commits else m.branches[m.branch].revision
    revision = m.correctNegativeIndexing(revision)
    return (m, branch, revision, changed, strict, force, m.getTrackingPatterns(branch), m.getTrackingPatterns(branch, negative = True))
  (m, m.branch, maxi + (1 if commit else 0), changed, strict, force, trackingPatterns, untrackingPatterns)

def switch(argument:str, options:List[str] = [], onlys:FrozenSet[str]? = None, excps:FrozenSet[str]? = None, cwd:str? = None):
  ''' Continue work on another branch, replacing file tree changes. '''
  m, branch, revision, changed, strict, _force, trackingPatterns, untrackingPatterns = exitOnChanges(argument, ["--force"] + options)  # force continuation to delay check to this function
  force:bool = '--force' in options  # needed as we fake force in above access

  # Determine file changes from other branch to current file tree
  if '--meta' in options:  # only switch meta data
    m.branches[m.branch] = dataCopy(BranchInfo, m.branches[m.branch], tracked = m.branches[branch].tracked, untracked = m.branches[branch].untracked)
  else:  # full file switch
    m.computeSequentialPathSet(branch, revision)  # load all commits up to specified revision for target branch into memory
    todos, _msg = m.findChanges(
      checkContent = strict, inverse = True,
      considerOnly = onlys if not (m.track or m.picky) else pure.conditionalIntersection(onlys, trackingPatterns | m.getTrackingPatterns(branch)),
      dontConsider = excps if not (m.track or m.picky) else excps ?? (untrackingPatterns | m.getTrackingPatterns(branch, negative = True)),
      progress = '--progress' in options)  # determine difference of other branch vs. file tree (forced or in sync with current branch; "addition" means exists now and should be removed)

    # Now check for potential conflicts
    changed.deletions.clear()  # local deletions never create conflicts, modifications always
    rms:str[] = []  # local additions can be ignored if restoration from switch would be same
    for a, pinfo in changed.additions.items():  # has potential corresponding re-add in switch operation:
      if a in todos.deletions and pinfo.size == todos.deletions[a].size and (pinfo.hash == todos.deletions[a].hash if m.strict else pinfo.mtime == todos.deletions[a].mtime): rms.append(a)
    for rm in rms: del changed.additions[rm]  # TODO could also silently accept remote DEL for local ADD
    if modified(changed) and not force: m.listChanges(changed, cwd); Exit("File tree contains changes. Use --force to proceed")
    if verbose: info(MARKER + "Switching to branch %sb%d/r%02d..." % ("'%s' " % m.branches[branch].name if m.branches[branch].name else "", branch, revision))
    if not modified(todos):
      info("No changes to current file tree")
    else:  # integration required
      for path, pinfo in todos.deletions.items():
        m.restoreFile(path, branch, revision, pinfo, ensurePath = True)  # is deleted in current file tree: restore from branch to reach target state
        printo("ADD " + path, color = Fore.GREEN)
      for path, pinfo in todos.additions.items():
        os.unlink(encode(os.path.join(m.root, path.replace(SLASH, os.sep))))  # is added in current file tree: remove from branch to reach target state
        printo("DEL " + path, color = Fore.RED)
      for path, pinfo in todos.modifications.items():
        m.restoreFile(path, branch, revision, pinfo)  # is modified in current file tree: restore from branch to reach target
        printo("MOD " + path, color = Fore.YELLOW)
  m.branch = branch
  m.saveBranches()  # store switched path info
  info(MARKER + "Switched to branch %sb%d/r%02d" % ("'%s' " % (m.branches[branch].name if m.branches[branch].name else ""), branch, revision))

def update(argument:str, options:str[] = [], onlys:FrozenSet[str]? = None, excps:FrozenSet[str]? = None):
  ''' Load and integrate a specified other branch/revision into current life file tree.
      In tracking mode, this also updates the set of tracked patterns.
      User options for merge operation: --add/--rm/--ask --add-lines/--rm-lines/--ask-lines (inside each file), --add-chars/--rm-chars/--ask-chars
  '''
  mrg:MergeOperation =     getAnyOfMap({"--add":       MergeOperation.INSERT, "--rm":       MergeOperation.REMOVE, "--ask":       MergeOperation.ASK}, options, MergeOperation.BOTH)  # default operation is replicate remote state
  mrgline:MergeOperation = getAnyOfMap({'--add-lines': MergeOperation.INSERT, '--rm-lines': MergeOperation.REMOVE, "--ask-lines": MergeOperation.ASK}, options, mrg)  # default operation for modified files is same as for files
  mrgchar:MergeOperation = getAnyOfMap({'--add-chars': MergeOperation.INSERT, '--rm-chars': MergeOperation.REMOVE, "--ask-chars": MergeOperation.ASK}, options, mrgline)  # default operation for modified files is same as for lines
  eol:bool = '--eol' in options  # use remote eol style
  m:Metadata = Metadata()  # TODO same is called inside stop on changes - could return both current and designated branch instead
  currentBranch:int? = m.branch
  m, branch, revision, changes_, strict, force, trackingPatterns, untrackingPatterns = exitOnChanges(argument, options, check = False, onlys = onlys, excps = excps)  # don't check for current changes, only parse arguments
  if verbose: info(MARKER + "Integrating changes from '%s/r%02d' into file tree..." % (m.branches[branch].name ?? "b%d" % branch, revision))

  # Determine file changes from other branch over current file tree
  m.computeSequentialPathSet(branch, revision)  # load all commits up to specified revision for branch to integrate
  trackingUnion:FrozenSet[str] = trackingPatterns | m.getTrackingPatterns(branch)
  untrackingUnion:FrozenSet[str] = untrackingPatterns | m.getTrackingPatterns(branch, negative = True)
  changed, _msg = m.findChanges(
    checkContent = strict, inverse = True,
    considerOnly = onlys if not (m.track or m.picky) else pure.conditionalIntersection(onlys, trackingUnion),
    dontConsider = excps if not (m.track or m.picky) else onlys ?? untrackingUnion,
    progress = '--progress' in options)  # determine difference of other branch vs. file tree. "addition" means exists now but not in other, and should be removed unless in tracking mode
  if mrg != MergeOperation.ASK and not changed.modifications and not (mrg.value & MergeOperation.INSERT.value and changed.additions or (mrg.value & MergeOperation.REMOVE.value and changed.deletions)):  # no file ops, TODO ASK handling is clumsy here
    if trackingUnion != trackingPatterns:  # nothing added
      info("No file changes detected, but tracking patterns were merged (run 'sos switch /-1 --meta' to undo)")  # TODO write test to see if this works
    else:
      info("Nothing to update")  # but write back updated branch info below
  else:  # integration required
    add_all:str?; del_all:str?; selection:str  # user input markers to continue to add/delete all remaining
    if changed.deletions.items(): printo("Additions:")
    for path, pinfo in changed.deletions.items():  # file-based update. Deletions mark files not present in current file tree -> needs addition!
      selection = "y" if mrg.value & MergeOperation.INSERT.value else "n"  # default for non-ask case
      if add_all is None and mrg == MergeOperation.ASK:
        selection = user_input("  Restore %r? *[Y]es, [N]o, yes to [A]ll, n[O] to all: " % path, "ynao", "y")
        if selection in "ao": add_all = "y" if selection == "a" else "n"; selection = add_all
      if "y" in (add_all, selection): m.restoreFile(path, branch, revision, pinfo, ensurePath = True)  # deleted in current file tree: restore from branch to reach target
      printo(("ADD " if "y" in (add_all, selection) else "(A) ") + path, color = Fore.GREEN)  # TODO #268 document merge/update output, e.g. (A) as "selected not to add by user choice"
    if changed.additions.items(): printo("Deletions:")
    for path, pinfo in changed.additions.items():
      if m.track or m.picky: Exit("This should never happen. Please create an issue report on Github")  # because untracked files of other branch cannot be detected (which is good)
      selection = "y" if mrg.value & MergeOperation.REMOVE.value else "n"
      if del_all is None and mrg == MergeOperation.ASK:
        selection = user_input("  Delete %r? *[Y]es, [N]o, yes to [A]ll, n[O] to all: " % path, "ynao", "y")
        if selection in "ao": del_all = "y" if selection == "a" else "n"; selection = del_all
      if "y" in (del_all, selection): os.unlink(encode(m.root + os.sep + path.replace(SLASH, os.sep)))
      printo(("DEL " if "y" in (del_all, selection) else "(D) ") + path, color = Fore.RED)  # not contained in other branch, but maybe kept
    if changed.modifications.items(): printo("Modifications:")
    for path, pinfo in changed.modifications.items():
      into:str = os.path.normpath(os.path.join(m.root, path.replace(SLASH, os.sep)))
      binary:bool = not m.isTextType(path)
      op:str = "m"  # merge as default for text files, always asks for binary (TODO unless --theirs or --mine)
      if mrg == MergeOperation.ASK or binary:  # TODO this may ask user even if no interaction was asked for
        printo(("MOD " if not binary else "BIN ") + path, color = Fore.YELLOW)  # TODO print mtime, size differences?
        op = user_input("  Resolve %r: *M[I]ne (skip), [T]heirs" % into + (": " if binary else ", [M]erge: "), "it" if binary else "itm", "i")
      if op == "t":
        printo("THR " + path, color = Fore.MAGENTA); m.readOrCopyVersionedFile(branch, revision, pinfo.nameHash, toFile = into)  # blockwise copy of contents
      elif op == "m":
        with open(encode(into), "rb") as fd: current:bytes = fd.read()  # TODO slurps current file
        file:bytes? = m.readOrCopyVersionedFile(branch, revision, pinfo.nameHash) if pinfo.size > 0 else b''  # parse lines
        if current == file and verbose: info("No difference to versioned file")
        elif file is not None:  # if None, error message was already logged
          merged:bytes; nl:bytes
          merged, nl = merge(file = file, into = current, mergeOperation = mrgline, charMergeOperation = mrgchar, eol = eol)
          if merged != current:
            with open(encode(path), "wb") as fd: fd.write(merged)  # TODO write to temp file first, in case writing fails
          elif verbose: info("No change")  # TODO but update timestamp?
      else:  # mine or wrong input
        printo("MNE " + path, color = Fore.CYAN)  # nothing to do! same as skip
  info(MARKER + "Integrated changes from '%s/r%02d' into file tree" % (m.branches[branch].name ?? "b%d" % branch, revision))
  m.branches[currentBranch] = dataCopy(BranchInfo, m.branches[currentBranch], inSync = False, tracked = list(trackingUnion))
  m.branch = currentBranch  # need to restore setting before saving TODO operate on different objects instead
  m.saveBranches()

def destroy(argument:str, options:str[] = []):
  ''' Remove a branch entirely. '''
  m, branch, revision, changed, strict, force, trackingPatterns, untrackingPatterns = exitOnChanges(None, options)
  if len(m.branches) == 1: Exit("Cannot remove the only remaining branch. Use 'sos online' to leave offline mode")
  branch, revision = m.parseRevisionString(argument)  # not from exitOnChanges, because we have to set argument to None there
  if branch is None or branch not in m.branches: Exit("Cannot delete unknown branch %r" % branch)
  if verbose: info(MARKER + "Removing branch b%d%s..." % (branch, " '%s'" % (m.branches[branch].name ?? "")))
  binfo = m.removeBranch(branch)  # need to keep a reference to removed entry for output below
  info(MARKER + "Branch b%d%s removed" % (branch, " '%s'" % (binfo.name ?? "")))

def add(relPaths:str[], patterns:str[], options:str[] = [], negative:bool = False):
  ''' Add a tracked files pattern to current branch's tracked files. negative means tracking blacklisting. '''
  force:bool = '--force' in options
  m:Metadata = Metadata()
  if not (m.track or m.picky):
    Exit("Repository is in simple mode. Create offline repositories via 'sos offline --track' or 'sos offline --picky' or configure a user-wide default via 'sos config track on'")
  knownpatterns:List[str] = m.branches[m.branch].untracked if negative else m.branches[m.branch].tracked
  for relPath, pattern in zip(relPaths, patterns):
    if pattern in knownpatterns:
      Exit("Pattern '%s' already tracked" % pattern)
    if not force and not os.path.exists(encode(relPath.replace(SLASH, os.sep))):
      Exit("The pattern folder doesn't exist. Use --force to add the file pattern anyway")
    if not force and len(fnmatch.filter(os.listdir(os.path.abspath(relPath.replace(SLASH, os.sep))), os.path.basename(pattern.replace(SLASH, os.sep)))) == 0:  # doesn't match any current file
      Exit("Pattern doesn't match any file in specified folder. Use --force to add it anyway")
    knownpatterns.append(pattern)
  m.saveBranches()
  info(MARKER + "Added tracking pattern '%s' for folder '%s'" % (os.path.basename(pattern.replace(SLASH, os.sep)), relPath if '--relative' in options else os.path.abspath(relPath)))

def remove(relPaths:str[], patterns:str[], options:str[] = [], negative:bool = False):
  ''' Remove a tracked files pattern from current branch's tracked files. '''
  m:Metadata = Metadata()
  if not (m.track or m.picky):
    Exit("Repository is in simple mode. Use 'offline --track' or 'offline --picky' to start repository in tracking or picky mode")
  knownpatterns:List[str] = m.branches[m.branch].untracked if negative else m.branches[m.branch].tracked
  for relPath, pattern in zip(relPaths, patterns):
    if pattern not in knownpatterns:
      suggestion:Set[str] = s{}
      for pat in knownpatterns: if fnmatch.fnmatch(pattern, pat): suggestion.add(pat)
      if suggestion: printo("Do you mean any of the following tracked file patterns? '%s'" % (", ".join(sorted(suggestion))))
      Exit("Tracked pattern '%s' not found" % pattern)
  knownpatterns.remove(pattern)
  m.saveBranches()
  info(MARKER + "Removed tracking pattern '%s' for folder '%s'" % (os.path.basename(pattern), relPath if '--relative' in options else os.path.abspath(relPath.replace(SLASH, os.sep))))

def ls(folder:str? = None, options:str[] = []):
  ''' List specified directory, augmenting with repository metadata. '''
  m:Metadata = Metadata()
  folder = folder ?? os.getcwd()
  if '--all' in options or '-a' in options: folder = m.root  # always start at SOS repo root with --all
  recursive:bool = '--recursive' in options or '-r' in options or '--all' in options
  patterns:bool = '--patterns' in options or '-p' in options
  DOT:str = (DOT_SYMBOL if m.c.useUnicodeFont else " ") * 3  # TODO or "."?
  if verbose: info(MARKER + "Repository is in %s mode" % ("tracking" if m.track else ("picky" if m.picky else "simple")))
  relPath:str = relativize(m.root, os.path.join(folder, "-"))[0]
  if relPath.startswith(os.pardir): Exit("Cannot list contents of folder outside offline repository")
  trackingPatterns:FrozenSet[str]? = m.getTrackingPatterns() if m.track or m.picky else f{}  # for current branch
  untrackingPatterns:FrozenSet[str]? = m.getTrackingPatterns(negative = True) if m.track or m.picky else f{}  # for current branch
  if '--tags' in options:  # TODO this has nothing to do with "ls" - it's an entirely different command. Move if something like "sos tag" has been implemented
    if len(m.tags) > 0: printo(ajoin("TAG ", sorted(m.tags), nl = "\n"))
    return
  for dirpath, dirnames, _filenames in os.walk(folder):
    if not recursive: dirnames.clear()  # avoid recursion
    dirnames[:] = sorted([decode(d) for d in dirnames])
    dirnames[:] = [d for d in dirnames  if len([n for n in m.c.ignoreDirs if fnmatch.fnmatch(d, n)]) == 0 or len([p for p in m.c.ignoreDirsWhitelist if fnmatch.fnmatch(d, p)]) > 0]  # global ignores

    folder = decode(dirpath)
    relPath = relativize(m.root, os.path.join(folder, "-"))[0]
    if patterns:
      out:str = ajoin("TRK ", [os.path.basename(p) for p in trackingPatterns if os.path.dirname(p).replace(os.sep, SLASH) == relPath], nl = "\n")
      if out: printo("DIR %s\n" % relPath + out)
      continue  # with next folder
    files:List[str] = list(sorted(entry for entry in os.listdir(folder) if os.path.isfile(os.path.join(folder, entry))))
    if len(files) > 0: printo("DIR %s" % relPath)
    for file in files:  # for each file list all tracking patterns that match, or none (e.g. in picky mode after commit)
      ignore:str? = None
      for ig in m.c.ignores: if fnmatch.fnmatch(file, ig): ignore = ig; break  # remember first match
      if ignore: for wl in m.c.ignoresWhitelist: if fnmatch.fnmatch(file, wl): ignore = None; break  # found a white list entry for ignored file, undo ignoring it
      matches:List[str] = []
      if not ignore:
        for pattern in (p for p in trackingPatterns if os.path.dirname(p).replace(os.sep, SLASH) == relPath):  # only patterns matching current folder
          if fnmatch.fnmatch(file, os.path.basename(pattern)): matches.append(os.path.basename(pattern))
      matches.sort(key = (element) -> len(element))  # sort in-place
      printo("%s %s%s" % ("IGN" if ignore is not None else ("TRK" if len(matches) > 0 else DOT), file, "  (%s)" % ignore if ignore is not None else ("  (%s)" % ("; ".join(matches)) if len(matches) > 0 else "")))

def log(options:str[] = [], cwd:str? = None):
  ''' List previous commits on current branch. '''
  changes_:bool = "--changes" in options
  diff_:bool = "--diff" in options
  m:Metadata = Metadata()
  m.loadBranch(m.branch)  # knows commit history
  number_:int? = tryOrDefault(-> max(1, int(sys.argv[sys.argv.index("-n") + 1])), m.c.logLines)  # WARN only works because we don't pick a positional argument in parse
  maxi:int = max(m.commits) if m.commits else m.branches[m.branch].revision  # one commit guaranteed for first offline branch, for fast-branched branches a revision in branchinfo
  info(MARKER + "Offline commit history of branch %r" % m.branches[m.branch].name ?? "r%02d" % m.branch)  # TODO also retain info of "from branch/revision" on branching?
  nl:int = len("%d" % maxi)  # determine space needed for revision
  changesetIterator:Iterator[Dict[str,PathInfo]]? = m.computeSequentialPathSetIterator(m.branch, maxi)
  olds:FrozenSet[str] = f{}  # last revision's entries
  last:Dict[str,PathInfo] = {}  # path infos from previous revision
  n:Metadata = Metadata(); commit:CommitInfo  # used for reading parent branch information
  indicator:ProgressIndicator? = ProgressIndicator(PROGRESS_MARKER[1 if m.c.useUnicodeFont else 0]) if '--all' not in options and maxi > number_ else None
  digits:int? = pure.requiredDecimalDigits(maxi) if indicator else None
  lastno:int = max(0, maxi + 1 - number_)
  for no in range(maxi + 1):
    if indicator: printo("  %%s %%0%dd" % digits % (indicator.getIndicator() ?? " ", no), nl = "\r")
    if no in m.commits: commit = m.commits[no]
    else:
      if n.branch != n.getParentBranch(m.branch, no): n.loadBranch(n.getParentBranch(m.branch, no))
      commit = n.commits[no]
    nxts:Dict[str,PathInfo] = next(changesetIterator)
    news:FrozenSet[str] = frozenset(nxts.keys())
    if "--all" in options or no >= lastno:
      if no >= lastno: indicator = None
      _add:FrozenSet[str] = news - olds
      _del:FrozenSet[str] = olds - news
  #    _mod_:Dict[str,PathInfo] = {k: nxts[k] for k in news - _add - _del}
      _mod:FrozenSet[str] = frozenset([_ for _, info in {k: nxts[k] for k in news - _add - _del}.items() if last[_].size != info.size or (last[_].hash != info.hash if m.strict else last[_].mtime != info.mtime)])
  #    _mov:FrozenSet[str] = detectMoves(ChangeSet(nxts, {o: None for o in olds}, m.strict)  # TODO determine moves - can we reuse detectMoves(changes)?
      _txt:int = len([m_ for m_ in _mod if m.isTextType(m_)])
      printo("  %s r%s @%s (%s+%s%02d/%s-%s%02d/%s%s%s%02d/%sT%s%02d) |%s|%s%s%s" % (
          (ARROW_SYMBOL if m.c.useUnicodeFont else "*") if commit.number == maxi else " ",
          ("%%%ds" % nl) % commit.number,
          strftime(commit.ctime),
          Fore.GREEN, Fore.RESET, len(_add),
          Fore.RED,   Fore.RESET, len(_del),
          Fore.YELLOW, PLUSMINUS_SYMBOL if m.c.useUnicodeFont else "~", Fore.RESET, len(_mod),
          Fore.CYAN, Fore.RESET, _txt,
          commit.message ?? "",
          Fore.MAGENTA, "TAG" if (commit.message ?? "") in m.tags else "", Fore.RESET
        )
      )
      if changes_: m.listChanges(ChangeSet({a: None for a in _add}, {d: None for d in _del}, {m: None for m in _mod}, {}), root = cwd if '--relative' in options else None)  # TODO why using None here? to avoid stating files for performance reasons?
      if diff_: pass  #  _diff(m, changes)  # needs from revision diff
    olds = news  # replaces olds for next revision compare
    last = {k: v for k, v in nxts.items()}  # create new reference

def dump(argument:str, options:str[] = []):
  ''' Exported entire repository as archive for easy transfer. '''
  if verbose: info(MARKER + "Dumping repository to archive...")
  m:Metadata = Metadata()  # to load the configuration
  progress:bool = '--progress' in options
  delta:bool = '--full' not in options
  skipBackup:bool = '--skip-backup' in options
  import functools, locale, warnings, zipfile
  try: import zlib; compression = zipfile.ZIP_DEFLATED  # HINT zlib is the library that contains the deflated algorithm
  except: compression = zipfile.ZIP_STORED

  if argument ?? "" == "": Exit("Argument missing (target filename)")
  argument = argument if "." in argument else argument + DUMP_FILE  # TODO this logic lacks a bit, "v1.2" would not receive the suffix
  entries:List[str] = []
  if os.path.exists(encode(argument)) and not skipBackup:
    try:
      if verbose: info("Creating backup...")
      shutil.copy2(encode(argument), encode(argument + BACKUP_SUFFIX))
      if delta: with zipfile.ZipFile(argument, "r") as _zip: entries = _zip.namelist()  # list of pure relative paths without leading dot, normal slashes
    except Exception as E: Exit("Error creating backup copy before dumping. Please resolve and retry. %r" % E)
  if verbose: info("Dumping revisions...")
  if delta: warnings.filterwarnings('ignore', 'Duplicate name.*')  # , UserWarning, "zipfile", 0)  # don't show duplicate entries warnings
  with zipfile.ZipFile(argument, "a" if delta else "w", compression) as _zip:  # create
    _zip.debug = 0  # suppress debugging output
    _zip.comment = ("Repository dump from %r" % strftime()).encode(UTF8)
    repopath:str = os.path.join(os.getcwd(), metaFolder)
    indicator:ProgressIndicator? = ProgressIndicator(PROGRESS_MARKER[1 if m.c.useUnicodeFont else 0]) if progress else None
    totalsize:int = 0
    start_time:float = time.time()
    for dirpath, dirnames, filenames in os.walk(repopath):  # TODO use index knowledge instead of walking to avoid adding stuff not needed?
      dirpath = decode(dirpath)
      if dirpath.endswith(BACKUP_SUFFIX): continue  # don't backup backups
      printo(pure.ljust(dirpath))  # TODO improve progress indicator output to | dir | dumpuing file
      dirnames[:] =  sorted([decode(d) for d in dirnames], key = functools.cmp_to_key((a, b) -> tryOrDefault(() -> locale.strcoll("%8d" % int(a[1:]), "%8d" % int(b[1:])), locale.strcoll(a, b))))  # HINT sort for reproducible delta dumps
      filenames[:] = sorted([decode(f) for f in filenames])
      for filename in filenames:
        abspath:str = os.path.join(dirpath, filename)
        relpath:str = os.path.join(metaFolder, os.path.relpath(abspath, repopath)).replace(os.sep, "/")
        totalsize +=  os.stat(encode(abspath)).st_size
        show:str? =   indicator.getIndicator() if progress else None
        if relpath.endswith(BACKUP_SUFFIX): continue  # don't backup backups
        if not delta or relpath.endswith(metaFile) or relpath not in entries:  # always update metadata, otherwise only add new revision files
          if show: printo("\r" + pure.ljust("Dumping %s @%.2f MiB/s %s" % (show, totalsize / (MEBI * (time.time() - start_time)), filename)), nl = "")
          _zip.write(abspath, relpath)  # write entry into archive
    if delta: _zip.comment = ("Delta dump from %r" % strftime()).encode(UTF8)
  info("\r" + pure.ljust(MARKER + "Finished dumping %s repository @%.2f MiB/s." % ("differential" if delta else "entire", totalsize / (MEBI * (time.time() - start_time)))))  # clean line

def publish(message:str?, cmd:str, options:str[] = [], onlys:FrozenSet[str]? = None, excps:FrozenSet[str]? = None):
  ''' Write changes made to the branch into one commit of the underlying VCS without further checks. '''
  m:Metadata = Metadata()  # TODO SOS only commit whats different from VCS state?
  if not (m.track or m.picky): Exit("Not implemented for simple repository mode yet")  # TODO add manual file picking mode instead (add by extension, recursive, ... see issue for details)
  m, branch, revision, changed, strict, force, trackingPatterns, untrackingPatterns = exitOnChanges(None, options, onlys = onlys, excps = excps)
  maxi:int? = m.getHighestRevision(branch)
  if maxi is None: Exit("No revision to publish on current branch (or any of its parents after fast-branching)")
  m.computeSequentialPathSet(branch, maxi, startwith = 1 if maxi >= 1 and not '--all' in options and not (m.track or m.picky) else 0)  # load all commits up to specified revision
  # HINT logic to only add changed files vs. originating file state - would require in-depth underlying VCS knowledge. We currentöy assume commit 0 as base
  # TODO discuss: only commit changes from r1.. onward vs. r0?, or attempt to add everything in repo, even if unchanged? the problem is that for different branches we might need to switch also underlying branches
  import subprocess  # only required in this section
  # HINT stash/rollback for Git? or implement a global mechanism to revert?
  files:str[] = list(m.paths.keys())
  while files:
    command:str = fitStrings(files, prefix = "%s add" % cmd, process = -> '"%s"' % _.replace("\"", "\\\""))  # considering maximum command-line length, filename quoting, and spaces
    returncode:int = subprocess.Popen(command, shell = False).wait()
#    returncode:int = 0; debug(command)
    if returncode != 0: Exit("Error adding files from SOS revision to underlying VCS. Leaving %s in potentially inconsistent state" % vcsNames[cmd])
  tracked:bool; commitArgs:str?; tracked, commitArgs = vcsCommits[cmd]
  returncode = subprocess.Popen(('%s commit -m "%s" %s' % (cmd, message ?? ("Committed from SOS %s/r%02d on %s" % (m.branches[branch].name ?? ("b%d" % m.branch), revision, strftime())).replace("\"", "\\\""), commitArgs ?? "")))  # TODO quote-escaping on Windows
#  debug(('%s commit -m "%s" %s' % (cmd, message ?? ("Committed from SOS %s/r%02d on %s" % (m.branches[branch].name ?? ("b%d" % m.branch), revision, strftime())).replace("\"", "\\\""), commitArgs ?? "")))
  if returncode != 0: Exit("Error committing files from SOS revision to underlying VCS. Please check current %s state" % cmd)
  if tracked: warn("Please note that all the files added in this commit will continue to be tracked by the underlying VCS")

def config(arguments:List[str?], options:List[str] = []):
  command:str; key:str; value:str; v:str
  command, key, value = (arguments + [None] * 2)[:3]
  if command is None: usage.usage("help", verbose = True)
  if command not in ("set", "unset", "show", "list", "add", "rm"): Exit("Unknown config command %r" % command)
  local:bool = "--local" in options
  m:Metadata = Metadata()  # loads nested configuration (local - global - defaults)
  c:configr.Configr = m.c if local else m.c.__defaults
  if command == "set":
    if None in (key, value): Exit("Key or value not specified")
    if key not in ((([] if local else ONLY_GLOBAL_FLAGS) + CONFIGURABLE_FLAGS + ["defaultbranch"]) + CONFIGURABLE_LISTS + CONFIGURABLE_INTS): Exit("Unsupported key for %s configuration %r" % ("local" if local else "global", key))  # TODO move defaultbranch to configurable_texts?
    if key in (ONLY_GLOBAL_FLAGS + CONFIGURABLE_FLAGS) and value.lower() not in TRUTH_VALUES + FALSE_VALUES: Exit("Cannot set flag to '%s'. Try on/off instead" % value.lower())
    c[key] = value.lower() in TRUTH_VALUES if key in (ONLY_GLOBAL_FLAGS + CONFIGURABLE_FLAGS) else (tryOrIgnore(-> int(value), (E) -> error("Not an integer value: %r" % E)) if key in CONFIGURABLE_INTS else (removePath(key, value.strip()) if key not in CONFIGURABLE_LISTS else [removePath(key, v) for v in safeSplit(value, ";")]))  # TODO sanitize texts?
  elif command == "unset":
    if key is None: Exit("No key specified")
    if key not in c.keys(with_nested = False):
      Exit(("Unknown key %r" % key) if not key in c.keys(with_nested = local, with_defaults = True) else "Key %r not defined in %s scope" % (key, "local" if local else "global"))
    del c[key]
  elif command == "add":  # TODO copy list from defaults if not local/global
    if None in (key, value): Exit("Key or value not specified")
    if key not in CONFIGURABLE_LISTS: Exit("Unsupported key %r for list addition" % key)
    if key not in c.keys(): c[key] = [_ for _ in c.__defaults[key]] if key in c.__defaults[key] else []  # prepare empty list, or copy from underlying, add new value below TODO also allow one more level of underlying?
    elif value in c[key]: Exit("Value already contained, nothing to do")
    if ";" not in value: c[key].append(removePath(key, value.strip()))
    else: c[key].extend([removePath(key, v) for v in safeSplit(value, ";")])
  elif command == "rm":
    if None in (key, value): Exit("Key or value not specified")
    if key not in c.keys(with_nested = False):
      Exit(("Unknown key %r" % key) if not key in c.keys(with_nested = local, with_defaults = True) else "Key %r not defined in %s scope" % (key, "local" if local else "global"))
    if value not in c[key]:  Exit("Unknown value %r" % value)
    c[key].remove(value)
    if local and len(c[key]) == 0 and "--prune" in options: del c[key]  # remove local entry, to fallback to global
  else:  # Show or list
    if   key == "ints":  printo(", ".join(CONFIGURABLE_INTS))  # list valid configuration items
    elif key == "flags": printo(", ".join(ONLY_GLOBAL_FLAGS + CONFIGURABLE_FLAGS))
    elif key == "lists": printo(", ".join(CONFIGURABLE_LISTS))
    elif key == "texts": printo(", ".join([_ for _ in defaults.keys() if _ not in (ONLY_GLOBAL_FLAGS + CONFIGURABLE_FLAGS + CONFIGURABLE_INTS + CONFIGURABLE_LISTS)]))
    else:  # no key: list all
      out:Dict[int,str] = {3: "[default]", 2: "[global] ", 1: "[local]  "}  # in contrast to Git, we don't need (nor want) to support a "system" config scope
      c = m.c  # always use full configuration chain
      try:  # attempt single key
        assert key is not None; c[key]  # force exception if no key specified
        l:bool = key in c.keys(with_nested = False); g:bool = key in c.__defaults.keys(with_nested = False)
        printo(key.rjust(20), color = Fore.WHITE, nl = "")
        printo(" " + (out[3] if not (l or g) else (out[1] if l else out[2])) + " ", color = Fore.CYAN, nl = "")
        printo(repr(c[key]))
      except:  # normal value listing
        vals:Dict[str,Tuple[str,int]] = {k: (repr(v), 3) for k, v in defaults.items()}  # copy-by-value
        vals.update({k: (repr(v), 2) for k, v in c.__defaults.items()})
        vals.update({k: (repr(v), 1) for k, v in c.__map.items()})
        for k, vt in sorted(vals.items()):
          printo(k.rjust(20), color = Fore.WHITE, nl = "")
          printo(" " + out[vt[1]] + " ", color = Fore.CYAN, nl = "")
          printo(vt[0])
        if len(c.keys()) == 0: info("No local configuration stored.")
        if len(c.__defaults.keys()) == 0: info("No global configuration stored.")
    return  # in case of list, no need to store anything
  if local: m.repoConf = c.__map; m.saveBranches(); Exit("OK", code = 0)  # saves changes of repoConfig
  else:  # global config
    f, h = saveConfig(c)  # only saves c.__defaults (nested Configr)
    if f is None: Exit("Error saving user configuration: %r" % h)

def move(relPath:str, pattern:str, newRelPath:str, newPattern:str, options:List[str] = [], negative:bool = False):
  ''' Path differs: Move files, create folder if not existing. Pattern differs: Attempt to rename file, unless exists in target or not unique.
      for "mvnot" don't do any renaming (or do?)
  '''
  if verbose: info(MARKER + "Renaming %r to %r" % (pattern, newPattern))
  force:bool = '--force' in options
  soft:bool = '--soft' in options
  if not os.path.exists(encode(relPath.replace(SLASH, os.sep))) and not force: Exit("Source folder doesn't exist. Use --force to proceed anyway")
  m:Metadata = Metadata()
  patterns:List[str] = m.branches[m.branch].untracked if negative else m.branches[m.branch].tracked
  files:List[str] = os.listdir(relPath.replace(SLASH, os.sep)) if os.path.exists(encode(relPath.replace(SLASH, os.sep))) else []
  files[:] = [f for f in files if len([n for n in m.c.ignores if fnmatch.fnmatch(f, n)]) == 0 or len([p for p in m.c.ignoresWhitelist if fnmatch.fnmatch(f, p)]) > 0]
  matching:List[str] = fnmatch.filter(files, os.path.basename(pattern))  # find matching files in source
  if not matching and not force: Exit("No files match the specified file pattern. Use --force to proceed anyway")
  if not (m.track or m.picky): Exit("Repository is in simple mode. Use basic file operations to modify files, then execute 'sos commit' to version any changes")
  if pattern not in patterns:  # list potential alternatives and exit
    for tracked in (t for t in patterns if t[:t.rindex(SLASH)] == relPath):  # for all patterns of the same source folder HINT was os.path.dirpath before
      alternative:str[] = fnmatch.filter(files, os.path.basename(tracked))  # find if it matches any of the files in the source folder, too
      if alternative: info("  '%s' matches %d file%s" % (tracked, len(alternative), "s" if len(alternative) > 1 else ""))
    Exit("File pattern '%s' is not tracked on current branch. 'sos move' only works on tracked patterns" % pattern)  # HINT removed: "if not (force or soft):""
  basePattern:str = os.path.basename(pattern)  # pure glob without folder
  newBasePattern:str = os.path.basename(newPattern)
  if basePattern.count("*") < newBasePattern.count("*")\
      or (basePattern.count("?") - basePattern.count("[?]")) < (newBasePattern.count("?") - newBasePattern.count("[?]"))\
      or (basePattern.count("[") - basePattern.count("\\[")) < (newBasePattern.count("[") - newBasePattern.count("\\["))\
      or (basePattern.count("]") - basePattern.count("\\]")) < (newBasePattern.count("]") - newBasePattern.count("\\]")):
    Exit("Glob markers from '%s' to '%s' don't match, cannot move/rename tracked matching file(s)" % (basePattern, newBasePattern))
#  oldTokens:GlobBlock[]?; newToken:GlobBlock[]?  # TODO remove optional?, only here to satisfy mypy
  oldTokens, newTokens = tokenizeGlobPatterns(os.path.basename(pattern), os.path.basename(newPattern))
  matches:Tuple[str,str][] = convertGlobFiles(matching, oldTokens, newTokens)  # computes list of source - target filename pairs
  if len(s{st[1] for st in matches}) != len(matches): Exit("Some target filenames are not unique and different move/rename actions would point to the same target file")
  matches = reorderRenameActions(matches, exitOnConflict = not soft)  # attempts to find conflict-free renaming order, or exits
  if os.path.exists(encode(newRelPath)):
    exists:str[] = [filename[1] for filename in matches if os.path.exists(encode(os.path.join(newRelPath, filename[1]).replace(SLASH, os.sep)))]
    if exists and not (force or soft): Exit("%s files would write over existing files in %s cases. Use --force to execute it anyway" % ("Moving" if relPath != newRelPath else "Renaming", "all" if len(exists) == len(matches) else "some"))
  else: os.makedirs(encode(os.path.abspath(newRelPath.replace(SLASH, os.sep))))
  if not soft:  # perform actual renaming
    for (source, target) in matches:
      try: shutil.move(encode(os.path.abspath(os.path.join(relPath, source).replace(SLASH, os.sep))), encode(os.path.abspath(os.path.join(newRelPath, target).replace(SLASH, os.sep))))
      except Exception as E: error("Cannot move/rename file '%s' to '%s'" % (source, os.path.join(newRelPath, target)))  # one error can lead to another in case of delicate renaming order
  patterns[patterns.index(pattern)] = newPattern
  m.saveBranches()

def parse(vcs:str, cwd:str, cmd:str):
  ''' Main operation. root is underlying VCS base dir. main() has already chdir'ed into SOS root folder, cwd is original working directory for add, rm, mv. '''
  debug("Parsing command-line arguments...")
  root = os.getcwd()
  try:
    onlys, excps, remotes = parseArgumentOptions(cwd, sys.argv)  # extracts folder-relative paths (used in changes, commit, diff, switch, update)
    command = sys.argv[1].strip() if len(sys.argv) > 1 else ""
    arguments:List[str] = [c.strip() for c in sys.argv[2:] if not ((len(c) == 2 and c.startswith("-")) or (len(c) > 2 and c[1] == "-"))]
    options:List[str] = [c.strip() for c in sys.argv[2:] if ((len(c) == 2 and c.startswith("-")) or (len(c) > 2 and c[1] == "-"))]  # options *with* arguments have to be parsed directly from sys.argv inside using functions
    debug("Processing command %r with arguments %r and options %r." % (command, [_ for _ in arguments if _ is not None], options))
    if command[:1] in "amr":
      try: relPaths, patterns = unzip([relativize(root, os.path.join(cwd, argument)) for argument in (arguments ?? ["."])])
      except:
        command = "ls"; arguments[0] = None; options.extend(["--patterns", "--all"])  # convert command into ls --patterns
        # Exit("Need one or more file patterns as argument (escape them according to your shell)")
    if command[:1] == "m":
      if len(arguments) < 2: Exit("Need a second file pattern argument as target for move command")
      newRelPath, newPattern = relativize(root, os.path.join(cwd, arguments[1]))
    arguments[:] = (arguments + [None] * 3)[:3]
    if command == "raise": raise Exception("provoked exception")
    elif command[:1] == "a":   add(relPaths, patterns, options, negative = "n" in command)  # e.g. addnot
    elif command[:1] == "b":   branch(arguments[0], arguments[1], options)
    elif command[:3] == "com": commit(arguments[0], options, onlys, excps)
    elif command[:2] == "ch":  changes(arguments[0], options, onlys, excps, cwd)  # "changes" (legacy)
    elif command[:2] == "ci":  commit(arguments[0], options, onlys, excps)
    elif command[:3] == 'con': config(arguments, options)
    elif command[:2] == "de":  destroy(arguments[0] ?? "", options)
    elif command[:2] == "di":  diff(arguments[2 if arguments[0] == '-n' else 0] ?? "/", options, onlys, excps)  # TODO no consistent handling of single dash/characters argument-options
    elif command[:2] == "du":  dump(arguments[0] ?? "", options)
    elif command[:1] == "h":   usage.usage(arguments[0], verbose = verbose)
    elif command[:2] == "lo":  log(options, cwd)
    elif command[:2] == "li":  ls(os.path.relpath(arguments[0] ?? cwd, root), options)
    elif command[:2] == "ls":  ls(os.path.relpath(arguments[0] ?? cwd, root), options)
    elif command[:1] == "m":   move(relPaths[0], patterns[0], newRelPath, newPattern, options, negative = "n" in command)  # e.g. mvnot
    elif command[:2] == "of":  offline(arguments[0], arguments[1], options, remotes)
    elif command[:2] == "on":  online(options)
    elif command[:1] == "p":   publish(arguments[0], cmd, options, onlys, excps)
    elif command[:1] == "r":   remove(relPaths, patterns, options, negative = "n" in command)  # e.g. rmnot
    elif command[:2] == "st":  status(arguments[0], vcs, cmd, options, onlys, excps)
    elif command[:2] == "sw":  switch(arguments[0] ?? "", options, onlys, excps, cwd)
    elif command[:1] == "u":   update(arguments[0] ?? "", options, onlys, excps)
    elif command[:1] == "v":   usage.usage(arguments[0], version = True)
    else: Exit("Unknown command '%s'" % command)
    Exit(code = 0)  # regular exit
  except Exception, RuntimeError as E:
    exception(E)
    Exit("An internal error occurred in SOS\nPlease report above message to the project maintainer at  https://github.com/ArneBachmann/sos/issues  via 'New Issue'.\nPlease state your installed version via 'sos version', and what you were doing.")

def main():
  global debug, info, warn, error  # to modify logger
  logging.basicConfig(level = level, stream = sys.stderr, format = ("%(asctime)-23s %(levelname)-8s %(name)s:%(lineno)d | %(message)s" if '--log' in sys.argv else "%(message)s"))
  _log = Logger(logging.getLogger(__name__)); debug, info, warn, error = _log.debug, _log.info, _log.warn, _log.error
  for option in (o for o in ['--log', '--debug', '--verbose', '-v', '--sos', '--vcs'] if o in sys.argv): sys.argv.remove(option)  # clean up program arguments
  if '--help' in sys.argv or len(sys.argv) < 2: usage.usage(sys.argv[sys.argv.index('--help') + 1] if '--help' in sys.argv and len(sys.argv) > sys.argv.index('--help') + 1 else None, verbose = verbose)
  command:str? = sys.argv[1] if len(sys.argv) > 1 else None
  root, vcs, cmd = findSosVcsBase()  # root is None if no .sos folder exists up the folder tree (still working online); vcs is checkout/repo root folder; cmd is the VCS base command
  debug("Detected SOS root folder: %s" % (root ?? "-"))
  debug("Detected VCS root folder: %s" % (vcs ?? "-"))
  defaults["defaultbranch"] = vcsBranches.get(cmd, vcsBranches[SVN]) ?? "default"  # sets dynamic default with SVN fallback
  defaults["useChangesCommand"] = cmd == "fossil"  # sets dynamic default with SVN fallback
  if (not force_vcs or force_sos) and (root is not None or (command ?? "")[:2] == "of" or (command ?? "_")[:1] in "hv"):  # in offline mode or just going offline
    cwd = os.getcwd()
    os.chdir(cwd if command[:2] == "of" else root ?? cwd)
    parse(vcs, cwd, cmd)
  elif force_vcs or cmd is not None:  # online mode - delegate to VCS
    info("%s: Running '%s %s'" % (usage.COMMAND.upper(), cmd, " ".join(sys.argv[1:])))
    import subprocess  # only required in this section
    process = subprocess.Popen([cmd] + sys.argv[1:], shell = False, stdin = subprocess.PIPE, stdout = sys.stdout, stderr = sys.stderr)
    inp:str = ""
    while True:
      so, se = process.communicate(input = inp)
      if process.returncode is not None: break
      inp = sys.stdin.read()
    if sys.argv[1][:2] == "co" and process.returncode == 0:  # successful commit - assume now in sync again (but leave meta data folder with potential other feature branches behind until "online")
      if root is None: Exit("Cannot determine VCS root folder: Unable to mark repository as synchronized and will show a warning when leaving offline mode")
      m:Metadata = Metadata(root)
      m.branches[m.branch] = dataCopy(BranchInfo, m.branches[m.branch], inSync = True)  # mark as committed
      m.saveBranches()
  else: Exit("No offline repository present, and unable to detect VCS file tree")


# Main part
force_sos:List[None] = [None] if '--sos' in sys.argv else []  # this is a trick allowing to modify the module-level flags from the test suite
force_vcs:List[None] = [None] if '--vcs' in sys.argv else []
level:int = logging.DEBUG if '--debug' in sys.argv else logging.INFO

_log = Logger(logging.getLogger(__name__)); debug, info, warn, error = _log.debug, _log.info, _log.warn, _log.error

if __name__ == '__main__': main()
