# Standard modules
import bz2, codecs, difflib, fnmatch, hashlib, json, logging, mimetypes, os, shutil, sys, time
try:
  from typing import Any, Dict, FrozenSet, IO, List, Set, Tuple, Type, TypeVar, Union  # only required for mypy
  Number = Union[int,float]
except: pass  # typing not available (e.g. Python 2)
try: import sos.version as version
except: import version

# External dependencies
try: import configr  # optional dependency
except: configr = None  # declare as undefined
#from enforce import runtime_validation  # https://github.com/RussBaz/enforce  TODO doesn't work for "data" types
UTF8 = "utf_8"  # early used constant, not defined in standard library
try:
  import chardet  # https://github.com/chardet/chardet
  def detect(binary:bytes) -> str = chardet.detect(binary)["encoding"]
except:  # Python 2 workaround
  def detect(binary:bytes) -> str =  # Guess the encoding
    try: binary.decode(UTF8); return UTF8
    except UnicodeError: pass
    try: binary.decode("utf_16"); return "utf_16"
    except UnicodeError: pass
    try: binary.decode("cp1252"); return "cp1252"
    except UnicodeError: pass
    "ascii"  # this code will never be reached, as above is an 8-bit charset that always matches


data BranchInfo(number:int, ctime:int, name:str? = None, insync:bool = False, tracked:List[str] = [])  # tracked is a list on purpose, as serialization to JSON needs effort and frequent access is not taking place
data CommitInfo(number:int, ctime:int, message:str? = None)
data PathInfo(namehash:str, size:int?, mtime:int, hash:str)  # size == None means deleted in this revision
data ChangeSet(additions:Dict[str,PathInfo], deletions:Dict[str,PathInfo], modifications:Dict[str,PathInfo])  # avoid default assignment of {} as it leads to runtime errors (contains data on init for unknown reason)
data Range(tipe:int, indexes:int[])  # MergeBlockType[1,2,4], line number, length
data MergeBlock(tipe:int, lines:str[], line:int, replaces:MergeBlock? = None, changes:Range? = None)

class ConflictResolution: THEIRS, MINE, ASK, NEXT = range(4)  # prefer their changes, prefer my changes, ask user for each change, go to next deeper level (e.g. from files to lines, characters)
class MergeOperation: INSERT, REMOVE, BOTH = 1, 2, 3  # insert remote changes into current, remove remote deletions from current, do both (replicate remote state) TODO handle inline-operations separate?
class MergeBlockType: KEEP, INSERT, REMOVE, REPLACE, MODIFY, MOVE = range(6)  # modify = intra-line changes

class Accessor(dict):
  ''' Dictionary with attribute access. Writing only supported via dictionary access. '''
  def __init__(_, mapping) -> None: dict.__init__(_, mapping)
  def __getattribute__(_, name:str) -> List[str]:
    try: return _[name]
    except: return dict.__getattribute__(_, name)

# Constants
APPNAME:str = "Subversion Offline Solution  V%s  (C) Arne Bachmann" % version.__release_version__
CONFIGURABLE_FLAGS = ["strict", "track", "picky", "compress"]
CONFIGURABLE_LISTS = ["texttype", "bintype", "ignores", "ignoreDirs", "ignoresWhitelist", "ignoreDirsWhitelist"]
TRUTH_VALUES = ["true", "yes", "on", "1", "enable", "enabled"]  # all lower-case normalized
PROGRESS_MARKER = ["|", "/", "-", "\\"]
metaFolder:str = ".sos"
metaFile:str = ".meta"
bufSize:int = 1 << 20  # 1 MiB
vcsFolders:Dict[str,str] = {".svn": "svn", ".git": "git", ".bzr": "bzr", ".hg": "hg", ".fslckout":" fossil", ".CVS": "cvs"}
vcsBranches:Dict[str,str?] = {"svn": "trunk", "git": "master", "bzr": "trunk", "hg": "default", "fossil": None, "cvs": None}
defaults:Accessor = Accessor({"strict": False, "track": False, "picky": False, "compress": True, "texttype": [], "bintype": [], "ignoreDirs": [".*", "__pycache__"], "ignoreDirsWhitelist": [], "ignores": ["__coconut__.py", "*.bak", "*.py[cdo]", "*.class", ".fslckout"], "ignoresWhitelist": []})

def Exit(message:str = "") -> None: print(message, file = sys.stderr); sys.exit(1)

def user_input(msg:str) -> str = eval("input" if sys.version_info.major >= 3 else "raw_input")(msg)  # dynamic Python2/3. don't simplify, eval must be inside function for unknown reason

try: Splittable = TypeVar("Splittable", str, bytes)
except: pass  # Python 2
def safeSplit(s:Splittable, d:Splittable? = None) -> Splittable[]: return s.split(d ?? ("\n" if isinstance(s, str) else b"\n")) if len(s) > 0 else []

def ajoin(sep:str, seq:str[], nl = "") -> str = sep + (sep + nl).join(seq)
def sjoin(*s:Tuple[Any]) -> str = " ".join([str(e) for e in s if e != ''])

def hashStr(datas:str) -> str = hashlib.sha256(datas.encode(UTF8)).hexdigest()

def hashFile(path:str, compress:bool, saveTo:str? = None) -> str =
  ''' Calculate hash of file contents. '''
  hash = hashlib.sha256()
  to = openIt(saveTo, "w", compress) if saveTo else None
  with open(path, "rb") as fd:
    while True:
      buffer = fd.read(bufSize)
      hash.update(buffer)
      if to: to.write(buffer)
      if len(buffer) < bufSize: break
    if to: to.close()
  hash.hexdigest()

def firstOfMap(map:Dict[str,Any], params:str[], default:Any = None) -> Any =
  ''' Utility. '''
  for k, v in map.items():
    if k in params: return v
  default

def loadConfig() -> Union[configr.Configr,Accessor] =  # Simplifies loading config from file system or returning the defaults
  config:Union[configr.Configr,Accessor]
  if not configr: return defaults  # this only applies for the case that configr is not available, thus no settings will be persisted anyway
  config = configr.Configr("sos", defaults = defaults)  # defaults are used if key is not configured, but won't be saved
  f, g = config.loadSettings(clientCodeLocation = os.path.abspath(__file__), location = os.environ.get("TEST", None))
  if f is None: debug("Encountered a problem while loading the user configuration: %r" % g)
  config

def saveConfig(c:configr.Configr) -> Tuple[str?, Exception?] =
  c.saveSettings(clientCodeLocation = os.path.abspath(__file__), location = os.environ.get("TEST", None))

def strftime(timestamp:int? = None) -> str = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(timestamp / 1000. if timestamp is not None else None))

def isglob(f:str) -> bool: return '*' in f or '?' in f

def diffPathSets(last:Dict[str,PathInfo], diff:Dict[str,PathInfo]) -> ChangeSet =
  ''' Computes a changeset between in-memory and on-disk file lists.
      Additions contains PathInfo for entries in diff
      Deletions contains PathInfo for entries not anymore in diff
      Modifications contains PathInfo for entries changed from last to diff (new state)
  '''
  changes:ChangeSet = ChangeSet({}, {}, {})
  for path, pinfo in last.items():
    if path not in diff: continue  # now change  changes.deletions[path] = pinfo; continue
    vs = diff[path]  # reference to potentially changed path set
    if vs.size is None: changes.deletions[path] = pinfo; continue  # marked for deletion
    if pinfo.size == None: changes.additions[path] = pinfo; continue  # re-added
    if pinfo.size != vs.size or pinfo.mtime != vs.mtime or pinfo.hash != vs.hash: changes.modifications[path] = vs  # not need to make hash comparison optional here
  for path, pinfo in diff.items():  # added loop
    if path not in last: changes.additions[path] = pinfo
  assert not any([path in changes.deletions for path in changes.additions])  # invariant checks
  assert not any([path in changes.additions for path in changes.deletions])
  changes

try: DataType = TypeVar("DataType", MergeBlock, BranchInfo)
except: pass  # Python 2
def dataCopy(_tipe:Type[DataType], _old:DataType, *_args, **_kwargs) -> DataType: r = _old._asdict(); r.update(**_kwargs); return makedata(_tipe, *(list(_args) + [r[field] for field in _old._fields]))

def getIntraLineMarkers(line:str) -> Range =
  ''' Return (type, [affected indices]) of "? "-line diff markers ("? " suffix must be removed). '''
  if "^" in line: return Range(MergeBlockType.MODIFY, [i for i, c in enumerate(line) if c == "^"])
  if "+" in line: return Range(MergeBlockType.INSERT, [i for i, c in enumerate(line) if c == "+"])
  if "-" in line: return Range(MergeBlockType.REMOVE, [i for i, c in enumerate(line) if c == "-"])
  Range(MergeBlockType.KEEP, [])

def detectAndLoad(filename:str? = None, content:bytes? = None) -> Tuple[str,bytes,str[]] =
  encoding:str; eol:bytes; lines:str[] = []
  if filename is not None:
    with open(filename, "rb") as fd: content = fd.read()
  encoding = detect(content) ?? sys.getdefaultencoding()
  eol =  eoldet(content)
  if filename is not None:
    with codecs.open(filename, encoding = encoding) as fd: lines = safeSplit(fd.read(), (eol ?? b"\n").decode(encoding))
  elif content is not None:
    lines = safeSplit(content.decode(encoding), (eol ?? b"\n").decode(encoding))
  else: return (sys.getdefaultencoding(), b"\n", [])
  (encoding, eol, lines)

def openIt(file:str, mode:str, compress:bool) -> IO =
  ''' Open abstraction for both compressed and plain files. '''
  bz2.BZ2File(file, mode) if compress else open(file, mode + "b")

def eoldet(file:bytes) -> bytes? =
  ''' Determine EOL style from a binary string. '''
  lf:int = file.count(b"\n")
  cr:int = file.count(b"\r")
  crlf:int = file.count(b"\r\n")
  if crlf > 0:  # DOS/Windows/Symbian etc.
    if lf != crlf or cr != crlf: warn("Inconsistent CR/NL count. Mixed EOL style detected, may cause problems during merge")
    return b"\r\n"
  if lf != 0 and cr != 0: warn("Inconsistent CR/NL count. Mixed EOL style detected, may cause problems during merge")
  if lf > cr: return b"\n"  # Linux/Unix
  if cr > lf: return b"\r"  # older 8-bit machines
  None  # no new line contained, cannot determine

def usage() -> None:
  print("""/// {appname}

Usage: {cmd} <command> [<argument>] [<option1>, ...]        For command "offline" and when in offline mode
       {cmd} <underlying vcs command and arguments>         Unless working in offline mode

  Available commands:
    offline [<name>]                                      Start working offline, creating a branch (named <name>)
      --track                                               Setup SVN-style mode: users add/remove tracking patterns per branch
      --picky                                               Setup Git-style mode: users pick files for each operation
    online                                                Finish working offline

    branch  [<name>] [--last] [--stay]                    Create a new branch from current file tree and switch to it
      --last                                                Use last revision, not current file tree, but keep file tree unchanged
      --stay                                                Don't switch to new branch, continue on current one
    switch  [<branch>][/<revision>] [--meta]              Continue work on another branch
      --meta                                                Only switch file tracking patterns for current branch, don't update any files
    update  [<branch>][/<revision>]                       Integrate work from another branch TODO add many merge and conflict resolution options
    delete  [<branch>]                                    Remove (current) branch entirely

    commit  [<message>]                                   Create a new revision from current state file tree, with an optional commit message
    changes [<branch>][/<revision>]                       List changed paths vs. last or specified revision
    diff    [<branch>][/<revision>]                       List changes vs. last or specified revision
    add     [<filename or glob pattern>]                  Add a tracking pattern to current branch (path/filename or glob pattern)
    rm      [<filename or glob pattern>]                  Remove a tracking pattern. Only useful after "offline --track" or "offline --picky"

    ls                                                    List file tree and mark changes and tracking status
    status                                                List branches and display repository status
    log                                                   List commits of current branch
    config  [set/unset/show/add/rm] [<param>] [<value>]   Configure user-global defaults.
                                                          Flags (1/0, on/off, true/false, yes/no):
                                                            strict, track, picky, compress
                                                          Lists (semicolon-separated):
                                                            texttype, bintype, ignores, ignoreDirs, ignoresWhitelist, ignoreDirsWhitelist
                                                          Supported texts:
                                                            defaultbranch (dynamic default per discovered VCS)
    help, --help                                          Show this usage information

  Arguments:
    <branch/revision>           Revision string. Branch is optional and may be a label or index
                                Revision is an optional integer and may be negative to reference from the latest commits (-1 is most recent revision)

  Common options:
    --force                     Executes potentially harmful operations
                                  for offline: ignore being already offline, start from scratch (same as online --force; offline)
                                  for online: ignore uncommitted branches
                                  for commit, switch, update, add: ignore uncommitted changes before executing command
    --strict                    Perform full content comparison, don't rely only on file size and timestamp
                                  for offline: persist strict mode in repository
                                  for changes, diff, commit, switch, update, delete: perform operation in strict mode
    --{cmd}                       When executing {CMD} not being offline, pass arguments to {CMD} instead (e.g. {cmd} --{cmd} config set key value.)
    --log                       Enable internals logger
    --verbose                   Enable debugging output""".format(appname = APPNAME, cmd = "sos", CMD = "SOS"))

def merge(file:bytes? = None, into:bytes? = None, filename:str? = None, intoname:str? = None, mergeOperation = MergeOperation.BOTH, conflictResolution = ConflictResolution.ASK) -> bytes =
  ''' Merges binary text contents 'file' into file 'into', returning merged result. '''
  encoding:str; othr:str[]; othreol:bytes?; curr:str[]; curreol:bytes?
  differ = difflib.Differ()
  try:  # load files line-wise and normalize line endings (keep the one of the current file) TODO document
    encoding, othreol, othr = detectAndLoad(filename = filename, content = file)
    encoding, curreol, curr = detectAndLoad(filename = intoname, content = into)
  except Exception as E: Exit("Cannot merge '%s' into '%s': %r" % (filename, intoname, E))
  if None not in [othreol, curreol] and othreol != curreol: warn("Differing EOL-styles detected during merge. Using current file's style for merge output")
  output:List[str] = list(differ.compare(othr, curr))  # from generator expression
  debug("Diff output: " + "".join([o.replace("\n", "\\n") for o in output]))
  blocks:List[MergeBlock] = []  # merged result in blocks
  tmp:List[str] = []  # block lines
  last = " "
  for no, line in enumerate(output + ["X"]):  # EOF marker
    if line[0] == last: tmp.append(line[2:]); continue  # continue filling consecutive block
    if line == "X":  # EOF marker - perform action for remaining block
      if len(tmp) == 0: break  # nothing left to do
    if last == " ":  # block is same in both files
      blocks.append(MergeBlock(MergeBlockType.KEEP, [line for line in tmp], line = no - len(tmp)))
    elif last == "-":  # may be a deletion or replacement, store for later
      blocks.append(MergeBlock(MergeBlockType.REMOVE, [line for line in tmp], line = no - len(tmp)))
    elif last == "+":  # may be insertion or replacement
      blocks.append(MergeBlock(MergeBlockType.INSERT, [line for line in tmp], line = no - len(tmp)))
      if len(blocks) >= 2 and len(blocks[-1].lines) == len(blocks[-2].lines):  # replaces previously removed section entirely if any
        if len(blocks[-1].lines) >= 2 or (blocks[-1].changes is None and blocks[-2].changes is None):  # full block or no intra-line comment
          blocks[-2] = MergeBlock(MergeBlockType.REPLACE, blocks[-1].lines, line = no - len(tmp), replaces = blocks[-2])  # remember replaced stuff
        else:  # may have intra-line modifications
          blocks[-2] = MergeBlock(MergeBlockType.MODIFY, blocks[-1].lines, line = no - len(tmp), replaces = blocks[-2], changes = blocks[-1].changes)
        blocks.pop()  # remove TOS
    elif last == "?":  # intra-line change comment
      ilm = getIntraLineMarkers(tmp[0])  # tipe is one of MergeBlockType 1, 2, 4. # "? " line includes a trailing \n for some reason
      blocks[-1] = dataCopy(MergeBlock, blocks[-1], tipe = MergeBlockType.MODIFY, changes = ilm)  # update to MODIFY, otherwise may be REPLACE instead
    last = line[0]
    tmp[:] = [line[2:]]
  debug("Diff blocks: " + repr(blocks))
  output = []
  for block in blocks:
    if block.tipe == MergeBlockType.KEEP:
      output.extend(block.lines)
    elif block.tipe == MergeBlockType.INSERT and not(mergeOperation & MergeOperation.REMOVE):
      output.extend(block.lines)
    elif block.tipe == MergeBlockType.REPLACE:  # complete block replacement
      if mergeOperation & MergeOperation.INSERT: output.extend(block.replaces.lines)  # replaced stuff TODO allow insertion BEFORE and alternatively AFTER?
      if not (mergeOperation & MergeBlockType.REMOVE): output.extend(block.lines)  # if remove, don't add replaced lines, otherwise do
    elif block.tipe == MergeBlockType.REMOVE and mergeOperation & MergeOperation.INSERT:
      output.extend(block.lines)
    elif block.tipe == MergeBlockType.MODIFY:
      if block.changes is not None and block.changes.tipe == MergeBlockType.INSERT:  # cannot be REMOVE, because it's always "-" then "+"
          output.extend(block.lines if mergeOperation & MergeOperation.INSERT else block.replaces.lines)  # TODO logic?
      elif block.replaces.changes is not None and block.replaces.changes.tipe == MergeBlockType.REMOVE:
          output.extend(block.lines if mergeOperation & MergeOperation.REMOVE else block.replaces.lines)
      elif block.changes is not None and block.changes.tipe == MergeBlockType.MODIFY:  # always both sides modified, but may differ in markers
        if conflictResolution == ConflictResolution.THEIRS:
          output.extend(block.replaces.lines)
        elif conflictResolution == ConflictResolution.MINE:
          output.extend(block.lines)
        elif conflictResolution == ConflictResolution.ASK:
          print(ajoin("THR ", block.replaces.lines, "\n"))
          print(ajoin("MIN ", block.lines, "\n"))
          reso:int? = {"i": ConflictResolution.MINE, "t": ConflictResolution.THEIRS, "m": ConflictResolution.NEXT, "u": None}.get(user_input(" Resolve: *M[I]ne, [T]heirs, [M]erge, [U]ser defined: ").strip().lower(), ConflictResolution.MINE)
          debug("User selected %d" % reso)
          match None in reso:
            warn("Manual input not implemented yet")  # TODO allow multi-line input (CTRL+D?)
          match =ConflictResolution.MINE in reso:
            debug("Using mine")
            output.extend(block.lines)
          match =ConflictResolution.THEIRS in reso:
            debug("Using theirs")
            output.extend(block.replaces.lines)
          match =ConflictResolution.NEXT in reso:
            warn("Intra-line merge not implemented yet, skipping line(s)")
            output.extend(block.replaces.lines)
      else:  # e.g. contains a deletion, but user was asking for insert only??
        warn("Investigate this case")
        output.extend(block.lines)  # default or not .replaces?
  debug("Merge output: " + "; ".join(output))
  nl:bytes = curreol ?? othreol ?? b"\n"
  nl.join([line.encode(encoding) for line in output])
  # TODO handle check for more/less lines in found -/+ blocks to find common section and splitting prefix/suffix out


class Counter:
  def __init__(_, initial:Number = 0) -> None: _.value:Number = initial
  def inc(_, by = 1) -> Number: _.value += by; return _.value
  def inc_old(_, by = 1) -> Number: old:Number = _.value; _.value += by; return old

class Logger:
  ''' Logger that supports many items. '''
  def __init__(_, log): _._log = log
  def debug(_, *s): _._log.debug(sjoin(*s))
  def info(_, *s): _._log.info(sjoin(*s))
  def warn(_, *s): _._log.warning(sjoin(*s))
  def error(_, *s): _._log.error(sjoin(*s))


# Main data class
#@runtime_validation
class Metadata:
  ''' This class doesn't represent the entire repository state in memory,
      but serves as a container for different repo operations,
      using only parts of its attributes at any point in time. Use with care.
  '''

  def __init__(_, path:str) -> None:
    ''' Create empty container object for various repository operations. '''
    _.c = loadConfig()
    _.root:str = path
    _.branches:Dict[int,BranchInfo] = {}  # branch number zero represents the initial state at branching
    _.commits:Dict[int,CommitInfo] = {}  # consecutive numbers per branch, starting at 0
    _.paths:Dict[str,PathInfo] = {}  # utf-8 encoded relative, normalized file system paths
    _.track:bool = _.c.track  # track files in the repository (tracked patterns are stored for each branch separately)
    _.picky:bool = _.c.picky  # pick files on each operation
    _.strict:bool = _.c.strict  # be always strict (regarding file contents comparsion)
    _.compress:bool = _.c.compress  # these flags are stored per branch, therefor not part of the (default) configuration
    _.branch:int? = None  # current branch number
    _.commit:int? = None  # current revision number

  def isTextType(_, filename:str) -> bool = ((mimetypes.guess_type(filename)[0] ?? "").startswith("text/") or any([fnmatch.fnmatch(filename, pattern) for pattern in _.c.texttype])) and not any([fnmatch.fnmatch(filename, pattern) for pattern in _.c.bintype])

  def listChanges(_, changes:ChangeSet, diffmode:bool = False, textglobs:str[] = []) -> None:
    ''' In diffmode, don't list modified files, because the diff is displayed elsewhere. '''
    if len(changes.additions) > 0:     print(ajoin("ADD ", sorted(changes.additions.keys()), "\n"))
    if len(changes.deletions) > 0:     print(ajoin("DEL ", sorted(changes.deletions.keys()), "\n"))
    if len(changes.modifications) > 0: print(ajoin("MOD ", sorted(k for k in changes.modifications.keys() if not _.isTextType(k) or not diffmode), "\n"))  # only list binary files

  def loadBranches(_) -> None:
    ''' Load list of branches and current branch info from metadata file. '''
    try:  # fails if not yet created (on initial branch/commit)
      branches:List[Tuple]
      with codecs.open(os.path.join(_.root, metaFolder, metaFile), "r", encoding = UTF8) as fd:
        flags, branches = json.load(fd)
      _.branch = flags["branch"]
      _.track = flags["track"]
      _.picky = flags["picky"]
      _.strict = flags["strict"]
      _.branches = {i.number: i for i in (BranchInfo(*item) for item in branches)}  # re-create type info
    except Exception as E:  # if not found, create metadata folder
      _.branches = {}
      warn("Couldn't read branches metadata: %r" % E)

  def saveBranches(_) -> None:
    ''' Save list of branches and current branch info to metadata file. '''
    with codecs.open(os.path.join(_.root, metaFolder, metaFile), "w", encoding = UTF8) as fd:
      json.dump(({"branch": _.branch, "track": _.track, "picky": _.picky, "strict": _.strict, "compress": _.compress}, list(_.branches.values())), fd, ensure_ascii = False)

  def getBranchByName(_, name:Union[str,int]) -> int? =
    ''' Convenience accessor for named branches. '''
    if isinstance(name, int): return name  # if type(name) is int: return name
    try: return int(name)  # attempt to parse integer string
    except ValueError: pass
    found = [number for number, branch in _.branches.items() if name == branch.name]
    found[0] if found else None

  def loadBranch(_, branch:int) -> None:
    ''' Load all commit information from a branch meta data file. '''
    with codecs.open(os.path.join(_.root, metaFolder, "b%d" % branch, metaFile), "r", encoding = UTF8) as fd:
      commits:List[List[Any]] = json.load(fd)  # list of CommitInfo that needs to be unmarshalled into value types
    _.commits = {i.number: i for i in (CommitInfo(*item) for item in commits)}  # re-create type info
    _.branch = branch

  def saveBranch(_, branch:int) -> None:
    ''' Save all commit information to a branch meta data file. '''
    with codecs.open(os.path.join(_.root, metaFolder, "b%d" % branch, metaFile), "w", encoding = UTF8) as fd:
      json.dump(list(_.commits.values()), fd, ensure_ascii = False)

  def duplicateBranch(_, branch:int, name:str?) -> None:
    ''' Create branch from an existing branch/revision. WARN: Caller must have loaded branches information.
        branch: target branch (should not exist yet)
        name: optional name of new branch
        _.branch: current branch
    '''
    debug("Duplicating branch '%s' to '%d'..." % (_.branches[_.branch].name ?? "b%d" % _.branch, branch))
    tracked = [t for t in _.branches[_.branch].tracked]  # copy
    os.makedirs(os.path.join(_.root, metaFolder, "b%d" % branch, "r0"))
    _.loadBranch(_.branch)
    revision:int = max(_.commits)
    _.computeSequentialPathSet(_.branch, revision)  # full set of files in revision to _.paths
    for path, pinfo in _.paths.items():
      _.copyVersionedFile(_.branch, revision, branch, 0, pinfo)
    _.commits = {0: CommitInfo(0, int(time.time() * 1000), "Branched from '%s'" % (_.branches[_.branch].name ?? "b%d" % _.branch))}  # store initial commit
    _.saveBranch(branch)  # save branch meta data to branch folder
    _.saveCommit(branch, 0)  # save commit meta data to revision folder
    _.branches[branch] = BranchInfo(branch, _.commits[0].ctime, name, _.branches[_.branch].insync, tracked)  # save branch info, before storing repo state at caller

  def createBranch(_, branch:int, name:str? = None, initialMessage:str? = None):
    ''' Create a new branch from current file tree. This clears all known commits and modifies the file system.
        branch: target branch (should not exist yet)
        name: optional name of new branch
        _.branch: current branch, must exist already
    '''
    simpleMode = not (_.track or _.picky)
    tracked = [t for t in _.branches[_.branch].tracked] if _.track and len(_.branches) > 0 else []  # in case of initial branch creation
    debug("Creating branch '%s'..." % name ?? "b%d" % branch)
    _.paths:Dict[str, PathInfo] = {}
    if simpleMode:
      changes:ChangeSet = _.findChanges(branch, 0, progress = simpleMode)  # creates revision folder and versioned files
      _.listChanges(changes)
      _.paths.update(changes.additions.items())
    else:  # tracking or picky mode
      os.makedirs(os.path.join(_.root, metaFolder, "b%d" % branch, "r0"))
      if _.branch is not None:  # not immediately after "offline" - copy files from current branch
        _.loadBranch(_.branch)
        revision:int = max(_.commits)  # TODO what if last switch was to an earlier revision? no persisting of last checkout
        _.computeSequentialPathSet(_.branch, revision)  # full set of files in revision to _.paths
        for path, pinfo in _.paths.items():
          _.copyVersionedFile(_.branch, revision, branch, 0, pinfo)
    ts = int(time.time() * 1000)
    _.commits = {0: CommitInfo(0, ts, initialMessage ?? "Branched on %s" % strftime(ts))}  # store initial commit for new branch
    _.saveBranch(branch)  # save branch meta data (revisions) to branch folder
    _.saveCommit(branch, 0)  # save commit meta data to revision folder
    _.branches[branch] = BranchInfo(branch, _.commits[0].ctime, name, True if len(_.branches) == 0 else _.branches[_.branch].insync, tracked)  # save branch info, in case it is needed

  def removeBranch(_, branch:int) -> BranchInfo =
    ''' Entirely remove a branch and all its revisions from the file system. '''
    shutil.rmtree(os.path.join(_.root, metaFolder, "b%d" % branch))
    binfo = _.branches[branch]
    del _.branches[branch]
    _.branch = max(_.branches)
    _.saveBranches()
    _.commits.clear()
    binfo

  def loadCommit(_, branch:int, revision:int) -> None:
    ''' Load all file information from a commit meta data. '''
    with codecs.open(os.path.join(_.root, metaFolder, "b%d" % branch, "r%d" % revision, metaFile), "r", encoding = UTF8) as fd:
      _.paths = json.load(fd)
    _.paths = {path: PathInfo(*item) for path, item in _.paths.items()}  # re-create type info
    _.branch = branch

  def saveCommit(_, branch:int, revision:int):
    ''' Save all file information to a commit meta data file. '''
    target = os.path.join(_.root, metaFolder, "b%d" % branch, "r%d" % revision)
    try: os.makedirs(target)
    except: pass
    with codecs.open(os.path.join(target, metaFile), "w", encoding = UTF8) as fd:
      json.dump(_.paths, fd, ensure_ascii = False)

  def findChanges(_, branch:int? = None, revision:int? = None, checkContent:bool = False, inverse:bool = False, considerOnly:FrozenSet[str]? = None, progress:bool = False) -> ChangeSet =
    ''' Find changes on the file system vs. in-memory paths (which should reflect the latest commit state).
        Only if both branch and revision are *not* None, write modified/added files to the specified revision folder (thus creating a new revision)
        The function returns the state of file tree *differences*, unless "inverse" is True -> then return original data
        checkContent: also computes file content hashes
        inverse: retain original state (size, mtime, hash) instead of updated one
        considerOnly: set of tracking patterns. For update operation, union of other and current branch
        progress: Show file names during processing
    '''
    write = branch is not None and revision is not None
    if write: os.makedirs(os.path.join(_.root, metaFolder, "b%d" % branch, "r%d" % revision))
    changes:ChangeSet = ChangeSet({}, {}, {})
    counter:Counter = Counter(); timer = time.time()
    for path, dirnames, filenames in os.walk(_.root):
      dirnames[:]  = [f for f in dirnames  if len([n for n in _.c.ignoreDirs if fnmatch.fnmatch(f, n)]) == 0 or len([p for p in _.c.ignoreDirsWhitelist if fnmatch.fnmatch(f, p)]) > 0]
      filenames[:] = [f for f in filenames if len([n for n in _.c.ignores    if fnmatch.fnmatch(f, n)]) == 0 or len([p for p in _.c.ignoresWhitelist    if fnmatch.fnmatch(f, p)]) > 0]
      dirnames.sort(); filenames.sort()
      relpath = os.path.relpath(path, _.root).replace(os.sep, "/")
      for file in (filenames if considerOnly is None else list(reduce((last, pattern) -> last | set(fnmatch.filter(filenames, os.path.basename(pattern))), (p for p in considerOnly if os.path.dirname(p) == relpath), s{}))):  # if m.track or m.picky: only files that match any path-relevant tracking patterns
        filename = relpath + "/" + file
        filepath = os.path.join(path, file)
        stat = os.stat(filepath)
        size, mtime, newtime = stat.st_size, int(stat.st_mtime * 1000), time.time()
        if progress and newtime - timer > .1:
          outstring = "\r%s  %s" % (PROGRESS_MARKER[counter.inc_old() % 4], filename)
          sys.stdout.write(outstring + " " * max(0, 80 - len(outstring))); timer = newtime  # TODO could write to new line instead of carriage return, also needs terminal width
        if filename not in _.paths:  # detected file not present (or untracked) in other branch
          namehash = hashStr(filename)
          changes.additions[filename] = PathInfo(namehash, size, mtime, hashFile(filepath, _.compress, saveTo = os.path.join(_.root, metaFolder, "b%d" % branch, "r%d" % revision, namehash) if write else None) if size > 0 else None)
          continue
        last = _.paths[filename]  # filename is known
        if last.size is None:  # was removed before but is now added back - does not apply for tracking mode (which never marks files for removal in the history)
          changes.additions[filename] = PathInfo(last.namehash, size, mtime, hashFile(filepath, _.compress, saveTo = os.path.join(_.root, metaFolder, "b%d" % branch, "r%d" % revision, last.namehash) if write else None) if size > 0 else None); continue
        elif size != last.size or mtime != last.mtime or (checkContent and hashFile(filepath, _.compress) == last.hash):  # detected a modification
          changes.modifications[filename] = PathInfo(last.namehash, last.size if inverse else size, last.mtime if inverse else mtime, last.hash if inverse else hashFile(filepath, _.compress, saveTo = os.path.join(_.root, metaFolder, "b%d" % branch, "r%d" % revision, last.namehash) if write else None) if (last.size if inverse else size) > 0 else None)
      # Detect deletions. Files no longer being tracked should not be found here
      for folderPath in (p for p, pinfo in _.paths.items() if p[:p.rindex("/")] == relpath and pinfo.size is not None):  # only versioned (and tracked) files that match currently visited folder. TODO don't check for removal just added entries
        if folderPath[len(relpath) + 1:] not in filenames: changes.deletions[folderPath] = _.paths[folderPath]  # filename no longer in file tree TODO use basename and dirname instead of slicing?
    changes

  def integrateChangeset(_, changes:ChangeSet, clear = False) -> None:
    ''' In-memory update from a changeset, marking deleted files with size=None. Use clear = True to start on an empty path set. '''
    if clear: _.paths.clear()
    else:
      rm = [p for p, info in _.paths.items() if info.size is None]  # remove files deleted in earlier change sets (revisions)
      for old in rm: del _.paths[old]  # remove previously removed entries completely
    for d, info in changes.deletions.items(): _.paths[d] = PathInfo(info.namehash, None, info.mtime, None)  # mark now removed entries as deleted
    _.paths.update(changes.additions)
    _.paths.update(changes.modifications)

  def computeSequentialPathSet(_, branch:int, revision:int) -> None:
    ''' In-memory computation of current list of valid PathInfo entries for specified branch and until specified revision (inclusively) by traversing revision on the file system. '''
    _.loadCommit(branch, 0)  # load initial paths
    n:Metadata = Metadata(_.root)  # next changes
    for revision in range(1, revision + 1):
      n.loadCommit(branch, revision)
      changes:ChangeSet = diffPathSets(_.paths, n.paths)
      _.integrateChangeset(changes)

  def parseRevisionString(_, argument:str) -> Tuple[int?,int?]:
    ''' Commit identifiers can be str or int for branch, and int for revision.
        Revision identifiers can be negative, with -1 being last commit.
    '''
    if argument is None: return (_.branch, -1)  # no branch/revision specified
    argument = argument.strip()
    if argument.startswith("/"): return (_.branch, int(argument[1:]))  # current branch
    if argument.endswith("/"):
      try: return (_.getBranchByName(argument[:-1]), -1)
      except ValueError: Exit("Unknown branch label")
    if "/" in argument:
      b, r = argument.split("/")[:2]
      try: return (_.getBranchByName(b), int(r))
      except ValueError: Exit("Unknown branch label or wrong number format")
    branch:int = _.getBranchByName(argument)  # returns number if given (revision) integer
    if branch not in _.branches: branch = None
    try: return (branch ?? _.branch, int(argument) if branch is None else -1)  # either branch name/number or reverse/absolute revision number
    except: Exit("Unknown branch label or wrong number format")
    return (None, None)  # should never be reached TODO raise exception instead?

  def copyVersionedFile(_, branch:int, revision:int, tobranch:int, torevision:int, pinfo:PathInfo) -> None:
    ''' Copy versioned file to other branch/revision. '''
    target:str = os.path.join(_.root, metaFolder, "b%d" % tobranch, "r%d" % torevision, pinfo.namehash)
    while True:
      source:str = os.path.join(_.root, metaFolder, "b%d" % branch, "r%d" % revision, pinfo.namehash)
      if os.path.exists(source): break
      revision -= 1
      if revision < 0: Exit("Cannot copy file '%s' from 'b%d/r%d' to 'b%d/r%d" % (pinfo.namehash, branch, revision, tobranch, torevision))  # should never happen
    shutil.copy2(source, target)

  def readOrCopyVersionedFile(_, branch:int, revision:int, namehash:str, toFile:str? = None) -> bytes? =
    ''' Return file contents, or copy contents into file path provided. '''
    source:str = os.path.join(_.root, metaFolder, "b%d" % branch, "r%d" % revision, namehash)
    try:
      with openIt(source, "r", _.compress) as fd:
        if toFile is None: return fd.read()  # read bytes into memory and return
        with open(toFile, "wb") as to:
          while True:
            buffer = fd.read(bufSize)
            to.write(buffer)
            if len(buffer) < bufSize: break
          return None
    except Exception as E: warn("Cannot read versioned file: %r (%d/%d/%s)" % (E, branch, revision, namehash))
    None

  def restoreFile(_, relpath:str?, branch:int, revision:int, pinfo:PathInfo) -> bytes? =
    ''' Recreate file for given revision, or return contents if path is None. '''
    if relpath is None: return _.readOrCopyVersionedFile(branch, revision, pinfo.namehash) if pinfo.size > 0 else b''  # just return contents as split decoded lines
    target:str = os.path.join(_.root, relpath.replace("/", os.sep))
    if pinfo.size == 0:
      with open(target, "wb"): pass
      try: os.utime(target, (-1, pinfo.mtime / 1000.))  # update access/modification timestamps on file system
      except Exception as E: error("Cannot update file's timestamp after restoration '%r'" % E)
      return None
    while True:  # find latest revision that contained the file physically
      source:str = os.path.join(_.root, metaFolder, "b%d" % branch, "r%d" % revision, pinfo.namehash)
      if os.path.exists(source): break
      revision -= 1
      if revision < 0: Exit("Cannot restore file '%s' from specified branch '%d'" % (pinfo.namehash, branch))
    # Restore file by copying buffer-wise
    with (openIt(source, "r", _.compress) as fd, open(target, "wb") as to):  # using Coconut's Enhanced Parenthetical Continuation
      while True:
        buffer = fd.read(bufSize)
        to.write(buffer)
        if len(buffer) < bufSize: break
    try: os.utime(target, (-1, pinfo.mtime / 1000.))  # update access/modification timestamps on file system
    except Exception as E: error("Cannot update file's timestamp after restoration '%r'" % E)
    None

  def getTrackingPatterns(_, branch:int? = None) -> FrozenSet[str] =
    ''' Returns list of tracking patterns for provided branch or current branch. '''
    f{} if not _.track and not _.picky else frozenset(_.branches[_.branch if branch is None else branch].tracked)


# Main client operations
def offline(argument:str, options:str[] = []) -> None:
  ''' Initial command to start working offline. '''
  if '--force' not in options and os.path.exists(metaFolder):
    Exit("Repository folder is either already offline or older branches and commits were left over. Use 'sos online' or continue working offline")
  m:Metadata = Metadata(os.getcwd())
  if '--picky'   in options or m.c["picky"]:  m.picky =  True  # Git-like
  elif '--track' in options or m.c["track"]:  m.track =  True  # Svn-like
  if '--strict'  in options or m.c["strict"]: m.strict = True  # always hash contents
  debug("Preparing offline repository...")
  m.createBranch(0, argument ?? str(m.c["defaultbranch"]), initialMessage = "Offline repository created on %s" % strftime())  # main branch's name may be None (e.g. for fossil)
  m.branch = 0
  m.saveBranches()  # no change immediately after going offline, going back online won't issue a warning
  info("Offline repository prepared. Use 'sos online' to finish offline work")

def online(options:str[] = []) -> None:
  ''' Finish working offline. '''
  force:bool = '--force' in options
  if not force:
    m = Metadata(os.getcwd())
    m.loadBranches()
    if any([not b.insync for b in m.branches.values()]) and not force: Exit("There are still unsynchronized branches.\nUse 'log' to list them. Commit them to your VCS one by one with 'sos commit' and 'sos switch' before leaving offline mode. Use 'online --force' to erase all aggregated offline revisions.")
  try: shutil.rmtree(metaFolder); info("Left offline modus. Continue work with your online VCS.")
  except Exception as E: Exit("Error removing offline repository: %r" % E)

def branch(argument:str? = None, options:str[] = []) -> None:
  ''' Create a new branch (from file tree or last revision) and (by default) continue working on it. '''
  last:bool = '--last' in options  # use last revision for branching, not current file tree
  stay:bool = '--stay' in options  # continue on current branch after branching
  force:bool = '--force' in options  # branch even with local modifications
  m:Metadata = Metadata(os.getcwd())
  m.loadBranches()
  if argument and m.getBranchByName(argument) is not None: Exit("Branch '%s' already exists. Cannot proceed" % argument)  # create a named branch
  branch = max(m.branches.keys()) + 1  # next branch's key
  debug("Branching to %sbranch b%d%s%s..." % ("unnamed " if argument is None else "", branch, " '%s'" % argument if argument else "", " from last revision" if last else ""))
  if last:
    m.duplicateBranch(branch, argument)  # branch from branch's last revision
  else:  # from file tree state
    m.createBranch(branch, argument)  # branch from current file tree
  if not stay:
    m.branch = branch
    m.saveBranches()
  info("%s new %sbranch b%d%s" % ("Continue work after branching" if stay else "Switched to", "unnamed " if argument is None else "", branch, " '%s'" % argument if argument else ""))

def changes(argument:str = None, options:str[] = []) -> ChangeSet =
  ''' Show changes of file tree vs. (last or specified) revision on current or specified branch. '''
  m:Metadata = Metadata(os.getcwd()); branch:int?; revision:int?
  m.loadBranches()  # knows current branch
  strict:bool = '--strict' in options or m.strict
  branch, revision = m.parseRevisionString(argument)
  if branch not in m.branches: Exit("Unknown branch")
  m.loadBranch(branch)  # knows commits
  revision = revision if revision >= 0 else len(m.commits) + revision  # negative indexing
  if revision < 0 or revision > max(m.commits): Exit("Unknown revision r%d" % revision)
  debug("Checking file tree vs. commit '%s/r%d'..." % (m.branches[branch].name ?? "b%d" % branch, revision))
  m.computeSequentialPathSet(branch, revision)  # load all commits up to specified revision
  changes:ChangeSet = m.findChanges(checkContent = strict, considerOnly = None if not m.track else m.getTrackingPatterns() | m.getTrackingPatterns(branch))
  m.listChanges(changes)
  changes

def diff(argument:str, options:str[] = []) -> None:
  ''' Show text file differences of file tree vs. (last or specified) revision on current or specified branch. '''
  m:Metadata = Metadata(os.getcwd()); branch:int?; revision:int?
  m.loadBranches()  # knows current branch
  strict:bool = '--strict' in options or m.strict
  branch, revision = m.parseRevisionString(argument)
  if branch not in m.branches: Exit("Unknown branch")
  m.loadBranch(branch)  # knows commits
  revision = revision if revision >= 0 else len(m.commits) + revision  # negative indexing
  if revision < 0 or revision > max(m.commits): Exit("Unknown revision r%d" % revision)
  debug("Diffing file tree vs. commit '%s/r%d'..." % (m.branches[branch].name ?? "b%d" % branch, revision))
  m.computeSequentialPathSet(branch, revision)  # load all commits up to specified revision
  changes:ChangeSet = m.findChanges(checkContent = strict, inverse = True, considerOnly = None if not m.track else m.getTrackingPatterns() | m.getTrackingPatterns(branch))
  info("File changes:")
  m.listChanges(changes, diffmode = True)  # only list modified binary files

  info("Text file modifications:")  # TODO only text files, not binary
  differ = difflib.Differ()
  for path, pinfo in changes.modifications.items():  # only consider modified files TODO also show A/D here?
    print("\nDIF " + path)
    content:bytes?; othr:str[]; curr:str[]
    if pinfo.size == 0: content = b""
    else: content = m.restoreFile(None, branch, revision, pinfo); assert content is not None
    abspath = os.path.join(m.root, path.replace("/", os.sep))
    encoding, othreol, othr = detectAndLoad(content = content)
    encoding, curreol, curr = detectAndLoad(filename = abspath)
    currcount, othrcount = Counter(), Counter()  # TODO shows empty new line although none in file. also counting is messed up
    last = ""
    for no, line in enumerate(differ.compare(othr, curr)):
      if line[0] == " ": continue  # no change in line
      print("%04d/%04d %s" % (no + othrcount.inc(-1 if line[0] == "+" or (line[0] == "?" and last == "+") else 0), no + currcount.inc(-1 if line[0] == "-" or (line[0] == "?" and last == "-") else 0), line))  # TODO counting this is definitely wrong and also lists \n as new diff lines. Could reuse block detection from merge instead
      last = line[0]

def commit(argument:str? = None, options:str[] = []) -> None:
  ''' Create new revision from file tree changes vs. last commit. '''
  changes:ChangeSet
  m, branch, revision, changes, strict, force, trackingPatterns = stopOnChanges(None, options, commit = True)  # special flag creates new revision for detected changes, but abort if no changes
  debug("Committing changes to branch '%s'..." % m.branches[m.branch].name ?? "b%d" % m.branch)
  m.integrateChangeset(changes, clear = True)  # update pathset to changeset only
  m.saveCommit(m.branch, revision)  # revision has already been incremented
  m.commits[revision] = CommitInfo(revision, int(time.time() * 1000), argument)  # comment can be None
  m.saveBranch(m.branch)
  if m.picky:
    m.loadBranches()  # TODO is this necessary?
    m.branches[m.branch] = dataCopy(BranchInfo, m.branches[m.branch], tracked = [], insync = False)  # remove tracked patterns after commit in picky mode
    m.saveBranches()
  info("Created new revision r%2d%s (+%d/-%d/~%d)" % (revision, ((" '%s'" % argument) if argument is not None else ""), len(changes.additions), len(changes.deletions), len(changes.modifications)))

def status() -> None:
  ''' Show branches and current repository state. '''
  m:Metadata = Metadata(os.getcwd())
  m.loadBranches()  # knows current branch
  current:int = m.branch
  info("Offline repository status:")
  sl:int = max([len(b.name ?? "") for b in m.branches.values()])
  for branch in sorted(m.branches.values(), key = (b) -> b.number):
    m.loadBranch(branch.number)  # knows commit history
    print("  %s b%d%s @%s (%s) with %d commits%s" % ("*" if current == branch.number else " ", branch.number, ((" %%%ds" % (sl + 2)) % ("'%s'" % branch.name)) if branch.name else "", strftime(branch.ctime), "in sync" if branch.insync else "dirty", len(m.commits), ". Last comment: '%s'" % m.commits[max(m.commits)].message if m.commits[max(m.commits)].message else ""))
  if m.track or m.picky and len(m.branches[m.branch].tracked) > 0:
    info("\nTracked file patterns:")
    print(ajoin("  | ", m.branches[m.branch].tracked, "\n"))

def stopOnChanges(argument:str? = None, options:str[] = [], check:bool = True, commit:bool = False) -> Tuple[Metadata,int?,int,ChangeSet,bool,bool,FrozenSet[str]] =
  ''' Common behavior for switch, update, delete, commit.
      check: stop program on detected change
      commit: don't stop on changes, because that's what we need in the operation
      Returns (Metadata, (current or target) branch, revision, set of changes vs. last commit on current branch, strict, force flags. '''
  m:Metadata = Metadata(os.getcwd())
  m.loadBranches()  # knows current branch
  trackingPatterns:FrozenSet[str] = m.getTrackingPatterns()  # SVN-like mode
  force:bool = '--force' in options
  strict:bool = '--strict' in options or m.strict
  if argument is not None:
    branch, revision = m.parseRevisionString(argument)  # for early abort
    if branch is None: Exit("Branch '%s' doesn't exist. Cannot proceed" % argument)
  m.loadBranch(m.branch)  # knows last commits of *current* branch

  # Determine current changes
  m.computeSequentialPathSet(m.branch, max(m.commits))  # load all commits up to specified revision
  changes:ChangeSet = m.findChanges(checkContent = strict, considerOnly = None if not m.track and not m.picky else trackingPatterns) if not commit else m.findChanges(m.branch, max(m.commits) + 1, checkContent = strict, considerOnly = None if not m.track and not m.picky else trackingPatterns)
  if (changes.additions or changes.deletions or changes.modifications) and not force:  # and check?
    m.listChanges(changes)
    if check and not commit: Exit("File tree contains changes. Use --force to proceed")
  elif commit and not force: Exit("Nothing to commit. Aborting")  #  and not check

  if argument is not None:  # branch/revision specified
    m.loadBranch(branch)  # knows commits of target branch
    revision = revision if revision >= 0 else len(m.commits) + revision  # negative indexing
    if revision < 0 or revision > max(m.commits): Exit("Unknown revision r%2d" % revision)
    return (m, branch, revision, changes, strict, force, m.getTrackingPatterns(branch))
  (m, m.branch, max(m.commits) + (1 if commit else 0), changes, strict, force, trackingPatterns)

def switch(argument:str, options:str[] = []) -> None:
  ''' Continue work on another branch, replacing file tree changes. '''
  changes:ChangeSet
  m, branch, revision, changes, strict, force, trackingPatterns = stopOnChanges(argument, options)
  debug("Switching to branch %sb%d/r%d..." % ("'%s' " % m.branches[branch].name if m.branches[branch].name else "", branch, revision))

  # Determine file changes from other branch to current file tree
  if '--meta' in options:  # only switch meta data
    m.branches[m.branch] = dataCopy(BranchInfo, m.branches[m.branch], tracked = m.branches[branch].tracked)
  else:  # full file switch
    m.computeSequentialPathSet(branch, revision)  # load all commits up to specified revision for target branch into memory
    changes = m.findChanges(checkContent = strict, inverse = True, considerOnly = None if not m.track else trackingPatterns | m.getTrackingPatterns(branch))  # determine difference of other branch vs. file tree (forced or in sync with current branch; "addition" means exists now and should be removed)
    if not (changes.additions or changes.deletions or changes.modifications):
      info("No changes to current file tree")
    else:  # integration required
      for path, pinfo in changes.deletions.items():
        m.restoreFile(path, branch, revision, pinfo)  # is deleted in current file tree: restore from branch to reach target
        debug("ADD " + path)
      for path, pinfo in changes.additions.items():
        os.unlink(os.path.join(m.root, path.replace("/", os.sep)))  # is added in current file tree: remove from branch to reach target
        debug("DEL " + path)
      for path, pinfo in changes.modifications.items():
        m.restoreFile(path, branch, revision, pinfo)  # is modified in current file tree: restore from branch to reach target
        debug("MOD " + path)
  m.branch = branch
  m.saveBranches()  # store switched path info
  info("Switched to branch %sb%d/r%d" % ("'%s' " % (m.branches[branch].name if m.branches[branch].name else ""), branch, revision))

def update(argument:str, options:str[] = []) -> None:
  ''' Load and integrate a specified other branch/revision into current life file tree.
      In tracking mode, this also updates the set of tracked patterns.
      User options for merge operation: --add (don't remove), --rm (don't insert), --add-lines/--rm-lines (inside each file)
      User options for conflict resolution: --theirs/--mine/--ask
  '''
  mrg:int = firstOfMap({"--add": MergeOperation.INSERT, "--rm": MergeOperation.REMOVE}, options, MergeOperation.BOTH)  # default operation is replicate remove state for non-conflicting cases (insertions/deletions)
  res:int = firstOfMap({'--theirs': ConflictResolution.THEIRS, '--mine': ConflictResolution.MINE}, options, ConflictResolution.NEXT)  # NEXT means deeper level
  mrgline:int = firstOfMap({'--add-lines': MergeOperation.INSERT, '--rm-lines': MergeOperation.REMOVE}, options, mrg)  # default operation for modified files is same as for files
  resline:int = firstOfMap({'--theirs-lines': ConflictResolution.THEIRS, '--mine-lines': ConflictResolution.MINE}, options, ConflictResolution.ASK)
  m:Metadata = Metadata(os.getcwd())  # TODO same is called inside stop on changes - could return both current and designated branch instead
  m.loadBranches(); changes:ChangeSet
  currentBranch:int? = m.branch
  m, branch, revision, changes, strict, force, trackingPatterns = stopOnChanges(argument, options, check = False)  # don't check for current changes, only parse arguments
  debug("Integrating changes from '%s/r%d' into file tree..." % (m.branches[branch].name ?? "b%d" % branch, revision))

  # Determine file changes from other branch over current file tree
  m.computeSequentialPathSet(branch, revision)  # load all commits up to specified revision for branch to integrate
  trackingUnion:FrozenSet[str] = trackingPatterns | m.getTrackingPatterns(branch)
  changes = m.findChanges(checkContent = strict, inverse = True, considerOnly = None if not m.track else trackingUnion)  # determine difference of other branch vs. file tree. "addition" means exists now but not in other, and should be removed unless in tracking mode
  if not (mrg & MergeOperation.INSERT and changes.additions or (mrg & MergeOperation.REMOVE and changes.deletions) or changes.modifications):
    if trackingUnion == trackingPatterns:  # nothing added
      info("No file changes detected, but tracking patterns were merged (run 'sos switch /-1 --meta' to undo)")  # TODO write test to see if this works
    else:
      info("Nothing to update")  # but write back updated branch info below
  else:  # integration required
    for path, pinfo in changes.deletions.items():  # deletions mark files not present in current file tree -> needs additon
      if mrg & MergeOperation.INSERT: m.restoreFile(path, branch, revision, pinfo)  # deleted in current file tree: restore from branch to reach target
      print("ADD " + path if mrg & MergeOperation.INSERT else "(A) " + path)
    for path, pinfo in changes.additions.items():
      if m.track or m.picky: Exit("This should never happen")  # because untracked files of other branch cannot be detected (which is good)
      if mrg & MergeOperation.REMOVE: os.unlink(m.root + os.sep + path.replace("/", os.sep))
      print("DEL " if mrg & MergeOperation.REMOVE else "(D) " + path)  # not contained in other branch, but maybe kept
    for path, pinfo in changes.modifications.items():
      into:str = os.path.join(m.root, path.replace("/", os.sep))
      binary = not m.isTextType(path)
      if res & ConflictResolution.ASK or binary:
        print(("MOD " if not binary else "BIN ") + path)
        reso = {"i": ConflictResolution.MINE, "t": ConflictResolution.THEIRS, "m": ConflictResolution.NEXT}.get(user_input(" Resolve: *M[I]ne, [T]heirs, [M]erge: (I)").strip().lower(), ConflictResolution.MINE)
        debug("User selected %d" % reso)
      else: reso = res
      if reso & ConflictResolution.THEIRS:
        m.readOrCopyVersionedFile(branch, revision, pinfo.namehash, into)  # blockwise copy of contents
        print("THR " + path)
      elif reso & ConflictResolution.MINE:
        print("MNE " + path)  # nothing to do! same as skip
      else:  # NEXT: line-based merge
        file:str = m.readOrCopyVersionedFile(branch, revision, pinfo.namehash) if pinfo.size > 0 else b'' # parse lines TODO decode etc.
        if file is not None:  # if None, error message was already logged
          contents:bytes = merge(filename = file, intoname = into, mergeOperation = mrgline, conflictResolution = resline)
          with open(path, "wb") as fd: fd.write(contents)  # TODO write to temp file first
  info("Integrated changes from '%s/r%d' into file tree" % (m.branches[branch].name ?? "b%d" % branch, revision))
  m.branches[currentBranch] = dataCopy(BranchInfo, m.branches[currentBranch], insync = False, tracked = list(trackingUnion))  # TODO really? it's a change that cannot be undone easily by the user
  m.branch = currentBranch  # need to restore setting before saving TODO operate on different objects instead
  m.saveBranches()

def delete(argument:str, options:str[] = []) -> None:
  ''' Remove a branch entirely. '''
  m, branch, revision, changes, strict, force, trackingPatterns = stopOnChanges(argument, options)
  if len(m.branches) == 1: Exit("Cannot remove the only remaining branch. Use 'sos online' to leave offline mode")
  debug("Removing branch %d%s..." % (branch, " '%s'" % m.branches[branch].name if m.branches[branch].name else ""))
  binfo = m.removeBranch(branch)  # need to keep a reference to removed entry for output below
  info("Branch b%d%s removed" % (branch, " '%s'" % binfo.name if binfo.name else ""))

def add(argument:str, options:str[] = []) -> None:
  ''' Add a tracked files pattern to current branch's tracked files. '''
  force:bool = '--force' in options
  m:Metadata = Metadata(os.getcwd())
  m.loadBranches()
  if not m.track and not m.picky: Exit("Repository is in simple mode. Needs 'offline --track' or 'offline --picky' instead")
  relpath = os.path.relpath(os.path.dirname(os.path.abspath(argument)), m.root)  # for tracking list
  pattern = os.path.join(relpath, os.path.basename(argument)).replace(os.sep, "/")
  if pattern in m.branches[m.branch].tracked:
    Exit("%s '%s' already tracked" % ("Glob" if isglob(pattern) else "File", pattern))
  if not force and len(fnmatch.filter(os.listdir(os.path.abspath(relpath)), os.path.basename(pattern.replace("/", os.sep)))) == 0:  # doesn't match any current file
    Exit("Pattern doesn't match any file in specified folder. Use --force to add it anyway")
  m.branches[m.branch].tracked.append(pattern)  # TODO set insync flag to False? same for rm
  m.saveBranches()
  info("Added tracking pattern '%s' for folder '%s'" % (os.path.basename(pattern.replace("/", os.sep)), os.path.abspath(relpath)))

def rm(argument:str) -> None:
  ''' Remove a tracked files pattern from current branch's tracked files. '''
  m:Metadata = Metadata(os.getcwd())
  m.loadBranches()
  if not m.track and not m.picky: Exit("Repository is in simple mode. Needs 'offline --track' or 'offline --picky' instead")
  relpath:str = os.path.relpath(os.path.dirname(os.path.abspath(argument)), m.root)
  pattern:str = os.path.join(relpath, os.path.basename(argument)).replace(os.sep, "/")
  if pattern not in m.branches[m.branch].tracked:
    suggestion:Set[str] = s{}
    for pat in m.branches[m.branch].tracked:
      if fnmatch.fnmatch(pattern, pat): suggestion.add(pat)
    if suggestion: print("Do you mean any of the following tracked globs? '%s'" % (", ".join(sorted(suggestion))))
    Exit("Tracked pattern '%s' not found" % pattern)
  m.branches[m.branch].tracked.remove(pattern)
  m.saveBranches()
  info("Removed tracking pattern '%s' for folder '%s'" % (os.path.basename(pattern.replace("/", os.sep)), os.path.abspath(relpath)))

def ls(argument:str? = None) -> None:
  ''' List specified directory, augmenting with repository metadata. '''
  cwd:str = os.getcwd() if argument is None else argument
  m:Metadata = Metadata(cwd)
  m.loadBranches()
  relpath:str = os.path.relpath(cwd, m.root).replace(os.sep, "/")
  files:List[str] = list(sorted(entry for entry in os.listdir(cwd) if os.path.isfile(entry)))
  trackingPatterns:FrozenSet[str] = m.getTrackingPatterns() if m.track or m.picky else f{}  # for current branch
  for file in files:
    ignore:str? = None
    for ig in m.c.ignores:
      if fnmatch.fnmatch(file, ig): ignore = ig; break  # remember first match TODO document this
    if ig:
      for wl in m.c.ignoresWhitelist:
        if fnmatch.fnmatch(file, wl): ignore = None; break  # found a white list entry for ignored file, undo ignoring it
    if ignore is None:
      matches:List[str] = []
      for pattern in (p for p in trackingPatterns if os.path.dirname(p) == relpath):  # only patterns matching current folder
        if fnmatch.fnmatch(file, os.path.basename(pattern)): matches.append(pattern)  # TODO or only file basename?
    print("%s %s%s" % ("IGN" if ignore is not None else ("TRK" if len(matches) > 0 else "   "), file, ' by "%s"' % ignore if ignore is not None else (" by " + ";".join(['"%s"' % match for match in matches]) if len(matches) > 0 else "")))

def log() -> None:
  ''' List previous commits on current branch. '''  # TODO --verbose for changesets
  m:Metadata = Metadata(os.getcwd())
  m.loadBranches()  # knows current branch
  m.loadBranch(m.branch)  # knows commit history
  info("Offline commit history of branch '%s':" % m.branches[m.branch].name ?? "r%2d" % m.branch)  # TODO also retain "from branch/revision" on branching?
  nl = len("%d" % max(m.commits))  # determine space needed for revision
  for commit in sorted(m.commits.values(), key = (co) -> co.number):
    print("  %s r%s @%s: %s" % ("*" if commit.number == max(m.commits) else " ", ("%%%ds" % nl) % commit.number, strftime(commit.ctime), commit.message ?? ""))
    # TODO list number of files and binary/text

def config(argument, options) -> None:
  if argument not in ["set", "unset", "show", "add", "rm"]: Exit("Unknown config command")
  if not configr: Exit("Cannot execute config command. 'configr' module not installed")
  c:Union[configr.Configr,Accessor] = loadConfig()
  if argument == "set":
    if len(options) < 2: Exit("No key nor value specified")
    if options[0] not in (["defaultbranch"] + CONFIGURABLE_FLAGS + CONFIGURABLE_LISTS): Exit("Unsupported key %r" % options[0])
    c[options[0]] = options[1].lower() in TRUTH_VALUES if options[0] in CONFIGURABLE_FLAGS else (options[1].strip() if options[0] not in CONFIGURABLE_LISTS else [options[1]])  # TODO sanitize texts?
    f, g = saveConfig(c)
    if f is None: error("Error saving user configuration: %r" % g)
  elif argument == "unset":
    if len(options) < 1: Exit("No key specified")
    if options[0] not in c.keys(): Exit("Unknown key")
    try:
      del c[options[0]]
      f, g = saveConfig(c)
      if f is None: error("Error saving user configuration: %r" % g)
    except Exception as E: Exit("Unknown key specified: %r (%r)" % (options[0], E))
  elif argument == "add":
    if len(options) < 2: Exit("No key nor value specified")
    if options[0] not in CONFIGURABLE_LISTS: Exit("Unsupported key for add %r" % options[0])
    if options[0] not in c.keys(): c[options[0]] = [options[1]]  # add list
    elif options[1] in c[options[0]]: Exit("Value already contained")
    c[options[0]].append(options[1])
    f, g = saveConfig(c)
    if f is None: error("Error saving user configuration: %r" % g)
  elif argument == "rm":
    if len(options) < 2: Exit("No key nor value specified")
    if options[0] not in c.keys(): Exit("Unknown key specified: %r" % options[0])
    del c[options[0]][options[0]]
    f, g = saveConfig(c)
    if f is None: error("Error saving user configuration: %r" % g)
  else:  # Show
    for k, v in sorted(c.items()): print("%s => %s" % (k, v))

def parse(root:str):
  ''' Main operation. '''
  debug("Parsing command-line arguments...")
  command = sys.argv[1].strip() if len(sys.argv) > 1 else ""
  argument = sys.argv[2].strip() if len(sys.argv) > 2 else None
  options = sys.argv[3:] if command == "config" else [c for c in sys.argv[2:] if c.startswith("--")]  # consider second parameter for no-arg command, otherwise from third on
  debug("Processing command %r with argument '%s' and options %r." % (command ?? "", argument ?? "", options))
  if   command[:1] == "a":   add(argument, options)      # a
  elif command[:1] == "b":   branch(argument, options)   # b
  elif command[:2] == "ch":  changes(argument, options)  # ch
  elif command[:3] == "com" or command[:2] == "ci": commit(argument, options)   # com, ci
  elif command[:3] == 'con': config(argument, options)   # con
  elif command[:2] == "de":  delete(argument, options)   # de
  elif command[:2] == "di":  diff(argument, options)     # di
  elif command[:1] == "h":   usage()                     # h
  elif command[:2] == "lo":  log()                       # lo
  elif command[:2] in ["li", "ls"]:  ls(argument)        # li, ls
  elif command[:2] == "of":  offline(argument, options)  # of
  elif command[:2] == "on":  online(options)             # on
  elif command[:1] == "r":   rm(argument)                # r
  elif command[:2] == "st":  status()                    # st
  elif command[:2] == "sw":  switch(argument, options)   # sw
  elif command[:2] == "up":  update(argument, options)   # up
  else: Exit("Unknown command '%s'" % command)
  sys.exit(0)

def findSosVcsBase() -> Tuple[str?,str?,str?] =
  ''' Attempts to find sos and legacy VCS base folders. '''
  debug("Detecting root folders...")
  path:str = os.getcwd()  # start in current folder, check parent until found or stopped
  vcs:Tuple[str?,str?] = (None, None)
  while not os.path.exists(os.path.join(path, metaFolder)):
    contents = set(os.listdir(path))
    vcss:str[] = [executable for folder, executable in vcsFolders.items() if folder in contents]  # determine VCS type from dot folder
    choice:str? = None
    if len(vcss) > 1:
      choice = "svn" if "svn" in vcss else vcss[0]
      warn("Detected more than one parallel VCS checkouts %r. Falling back to '%s'" % (vcss, choice))
    elif len(vcss) > 0: choice = vcss[0]
    if not vcs[0] and choice: vcs = (path, choice)  # memorize current repo root
    new = os.path.dirname(path)  # get parent path
    if new == path: break  # avoid infinite loop
    path = new
  if os.path.exists(os.path.join(path, metaFolder)):  # found something
    if vcs[0]: return (path, vcs[0], vcs[1])  # already detected vcs base and command
    sos = path
    while True:  # continue search for VCS base
      new = os.path.dirname(path)  # get parent path
      if new == path: return (sos, None, None)  # no VCS folder found
      path = new
      contents = set(os.listdir(path))
      vcss = [executable for folder, executable in vcsFolders.items() if folder in contents]  # determine VCS type
      choice = None
      if len(vcss) > 1:
        choice = "svn" if "svn" in vcss else vcss[0]
        warn("Detected more than one parallel VCS checkouts %r. Falling back to '%s'" % (vcss, choice))
      elif len(vcss) > 0: choice = vcss[0]
      if choice: return (sos, path, choice)
  (None, vcs[0], vcs[1])

def main() -> None:
  global debug, info, warn, error
  logging.basicConfig(level = level, stream = sys.stderr, format = ("%(asctime)-23s %(levelname)-8s %(name)s:%(lineno)d | %(message)s" if '--log' in sys.argv else "%(message)s"))
  _log = Logger(logging.getLogger(__name__)); debug, info, warn, error = _log.debug, _log.info, _log.warn, _log.error
  for option in (o for o in ['--log', '--verbose', '-v', '--sos'] if o in sys.argv): sys.argv.remove(option)  # clean up program arguments
  if '--help' in sys.argv or len(sys.argv) < 2: usage(); Exit()
  command:str? = sys.argv[1] if len(sys.argv) > 1 else None
  root, vcs, cmd = findSosVcsBase()  # root is None if no .sos folder exists up the folder tree (still working online); vcs is checkout/repo root folder; cmd is the VCS base command
  debug("Found root folders for SOS/VCS: %s/%s" % (root ?? "", vcs ?? ""))
  defaults["defaultbranch"] = vcsBranches.get(cmd, "trunk")  # sets dynamic default with SVN fallback
  if force_sos or root is not None or (command ?? "")[:2] == "of" or (command ?? "")[:1] == "h":  # in offline mode or just going offline TODO what about git config?
    os.chdir(os.getcwd() if command[:2] == "of" else root ?? os.getcwd())  # since all operatiosn use os.getcwd() and we save one argument to each function
    parse(root)
  elif cmd is not None:  # online mode - delegate to VCS
    info("SOS: Running '%s %s'" % (cmd, " ".join(sys.argv[1:])))
    import subprocess  # only requuired in this section
    process = subprocess.Popen([cmd] + sys.argv[1:], shell = False, stdin = subprocess.PIPE, stdout = sys.stdout, stderr = sys.stderr)
    inp:str = ""
    while True:
      so, se = process.communicate(input = inp)
      if process.returncode is not None: break
      inp = sys.stdin.read()
    if sys.argv[1][:2] == "co" and process.returncode == 0:  # successful commit - assume now in sync again (but leave meta data folder with potential other feature branches behind until "online")
      if root is None: Exit("Cannot determine VCS root folder: Unable to mark repository as synchronized and will show a warning when leaving offline mode")
      m = Metadata(root)
      m.loadBranches()  # read repo
      m.branches[m.branch] = dataCopy(BranchInfo, m.branches[m.branch], insync = True)  # mark as committed
      m.saveBranches()
  else: Exit("No offline repository present, and unable to detect VCS file tree")


# Main part
level = logging.DEBUG if os.environ.get("DEBUG", "False").lower() == "true" or '--verbose' in sys.argv or '-v' in sys.argv else logging.INFO
force_sos = '--sos' in sys.argv
_log = Logger(logging.getLogger(__name__)); debug, info, warn, error = _log.debug, _log.info, _log.warn, _log.error
if __name__ == '__main__': main()
